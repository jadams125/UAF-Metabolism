#DATA PREP SYNTHESIS


###################### DO DATA ##############################################
### Jacob Adams
### Full DoD DO Record Script
### 7/6/2022

#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)
library(data.table)

#calculate mg/L DO from Psat

# Identify which records do not have proper DO data for METAB run




########POKE ########

### 2019 ###
#Read cleaned CSVs from DoD 2019 Script 

SondeData2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/processed_sensor_dat/SUNA.EXO.int.corr.csv")

SondeData2019$datetimeAK <- force_tz(as.POSIXct(SondeData2019$datetimeAK), "America/Anchorage")

# Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is cleaned.

SondeData2019.renamed <- SondeData2019 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)


POKE_EXO_cl.2019.renamed <- SondeData2019.renamed %>% filter(site.ID == "POKE")

# 
# 
# POKE_EXO_cl.2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/EXO_processed/POKE.EXO.cl.csv")
# 
# POKE_EXO_cl.2019$datetimeAK <- force_tz(as.POSIXct(POKE_EXO_cl.2019$datetimeAK), "America/Anchorage")
# # Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is not cleaned.
# 
# POKE_EXO_cl.2019.renamed <- POKE_EXO_cl.2019 %>%
#   dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)
# 


#ROUGHLY convert %LOC to mg/L with Air pressure at time of install
poke.2019.air.P.url <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
poke_19.ap <- drive_get(as_id(poke.2019.air.P.url))
poke_19.ap_glist <- drive_ls(poke_19.ap, pattern = "191017_20005936_POKE_ATM.csv")
walk(poke_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.ap.2019.Data <- read.csv("191017_20005936_POKE_ATM.csv",
                              skip = 1, header = TRUE)
poke.ap.2019.Data$DateTime <- as.POSIXct(strptime(poke.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

poke.ap.2019.Data$DateTime <- lubridate::round_date(poke.ap.2019.Data$DateTime, "15 minutes") 

#row 2 is not a real row
poke.ap.2019.Data <- poke.ap.2019.Data[-c(2), ]


#convert to mmHg
poke.ap.2019.Data$pressure.mmHg <- poke.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..20005936..SEN.S.N..20005936..LBL..P. * 7.50062

#air pressure at start time: may 10, 2019 at 12:30
airPressureInstall <- poke.ap.2019.Data %>% filter(DateTime == "2019-05-10 12:30:00")


# #Get missed out of water point
# POKE_EXO_cl.2019.renamed.1 <- POKE_EXO_cl.2019.renamed %>% filter(datetimeAK <= "2019-08-22 14:15:00")
# 
# 
# POKE_EXO_cl.2019.renamed.2 <- POKE_EXO_cl.2019.renamed %>% filter(datetimeAK >= "2019-08-22 16:00:00")
# 
# POKE_EXO_cl.2019.renamed <- rbind(POKE_EXO_cl.2019.renamed.1,POKE_EXO_cl.2019.renamed.2)




poke.exo.telemFilled.2019 <- POKE_EXO_cl.2019.renamed %>% filter(datetimeAK >= "2019-08-22 15:00:00" & datetimeAK <= "2019-09-11 11:30:00")

#change pressure to match current record
poke.exo.telemFilled.2019$ODO.Psat <-  758.85 / 760 *  poke.exo.telemFilled.2019$ODO.Ploc


#convert from PSAT to mg/L using the formula the EXO uses
poke.exo.telemFilled.2019$ODO.mgL <- as.numeric(poke.exo.telemFilled.2019$ODO.Psat) * (0.01* exp(
  (-862194900000*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))^4+12438000000*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))^3-66423080*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))^2+157570.1*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))-139.344)
  -0* (2140.7*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))^2-10.754*(1/(poke.exo.telemFilled.2019$Temp.C+273.15))+0.017674 )))




#combine

#Plot It

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/poke19filled.pdf")

plot(POKE_EXO_cl.2019.renamed$datetimeAK, POKE_EXO_cl.2019.renamed$ODO.Psat ,type="l",col="black", xlab = "date", ylab = "ODO %Sat",  ylim=c(93,107),)

lines(poke.exo.telemFilled.2019$datetimeAK, poke.exo.telemFilled.2019$ODO.Psat ,col="blue")

legend(2, 4, legend=c("Equation 1", "Equation 2"),
       fill = c("blue","red")
)

dev.off()

#Put it together

POKE_EXO_cl.2019.renamed.3 <- POKE_EXO_cl.2019.renamed %>% filter(datetimeAK <= "2019-08-22 14:45:00")
POKE_EXO_cl.2019.renamed.4 <- POKE_EXO_cl.2019.renamed %>% filter(datetimeAK >= "2019-09-11 11:45:00")

final.Poke.DO.2019 <- rbind(POKE_EXO_cl.2019.renamed.3,POKE_EXO_cl.2019.renamed.4, poke.exo.telemFilled.2019)

final.Poke.DO.2019 <- dplyr::arrange(final.Poke.DO.2019, datetimeAK)

plot(final.Poke.DO.2019$datetimeAK,final.Poke.DO.2019$ODO.Psat, type="l",col="black")
# 
# # Poke:
# 
# #download flowmeter data
# WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
# WR.19.1 <- drive_get(as_id(WR_19.url))
# poke.wr19_glist <- drive_ls(WR.19.1, pattern = "poke_2019_flowmeter_Q_for_R_JAA.csv")
# walk(poke.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# poke_WR_19.Data <- read.csv("poke_2019_flowmeter_Q_for_R_JAA.csv",
#                             skip = 1, header = TRUE, na.strings=c("","NA","blank"))
# 
# poke_WR_19.Data <- poke_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# poke_WR_19.Data <- poke_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# poke_WR_19.Data$datetimeAK <- as.POSIXct(paste(poke_WR_19.Data$Date, poke_WR_19.Data$Time), format="%m/%d/%Y %H:%M")
# 
# 
# poke_WR_19.Data <- poke_WR_19.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Poke_depth_19 <- ddply(na.omit(poke_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_19)
# 
# 
# Poke_depth_19 <- setDT(Poke_depth_19)
# 
# Poke_depth_19 <- Poke_depth_19 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# final.Poke.DO.2019 <- setDT(final.Poke.DO.2019)
# 
# setDT(Poke_depth_19)
# setDT(final.Poke.DO.2019)
# 
# final.Poke.DO.2019$datetimeAK1 <- final.Poke.DO.2019$datetimeAK
# 
# setkey( final.Poke.DO.2019, datetimeAK )
# setkey( Poke_depth_19, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_poke19 <- final.Poke.DO.2019[ Poke_depth_19, roll = "nearest" ]
# 
# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   select(meanDepth, datetimeAK)
# 
# Poke.2019.DO.Depth <- merge(final.Poke.DO.2019, rounded.dates_poke19, by = "datetimeAK", all = TRUE)
# Poke.2019.DO.Depth$meanDepth1 <- Poke.2019.DO.Depth$meanDepth
# 
# testmod <- lm(meanDepth ~ datetimeAK, Poke.2019.DO.Depth)
# 
# summary(testmod)
# 
# Poke.2019.DO.Depth <- Poke.2019.DO.Depth %>% 
#   mutate(predictedDepth = predict(testmod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))


final.Poke.DO.2019 <- final.Poke.DO.2019 %>% filter(datetimeAK < "2019-10-17 11:45:00")




### 2020 ###
# exo.all.2020.url <- "https://drive.google.com/drive/u/1/folders/1nNKoIdgP-fdCNRGUbGca_zVujF_16QEM"
# exo.all.2020.prt1 <- drive_get(as_id(exo.all.2020.url))
# exo.all.2020.glist <- drive_ls(exo.all.2020.prt1, pattern = "EXO.ALL.csv")
# walk(exo.all.2020.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# exo.all.2020 <- read.csv("EXO.ALL.csv",)

poke.exo.2020 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2020/EXO_processed/POKE.EXO.cl.csv")


poke.exo.2020 <- poke.exo.2020 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn.adj, ODO.Psat = ODO.Psat.mn.adj, ODO.Ploc = ODO.Ploc.mn.adj, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)

poke.exo.2020$datetimeAK <- force_tz(as.POSIXct(poke.exo.2020$datetimeAK), "America/Anchorage")

# poke.exo.2020$ODO.mgL <- 
#   
#   #calc from YSI %Sat to MGL spreadsheet
#   as.numeric(poke.exo.2020$ODO.Psat) * (0.01* exp(
#     (-862194900000*(1/(poke.exo.2020$Temp.C+273.15))^4+12438000000*(1/(poke.exo.2020$Temp.C+273.15))^3-66423080*(1/(poke.exo.2020$Temp.C+273.15))^2+157570.1*(1/(poke.exo.2020$Temp.C+273.15))-139.344)
#       -0* (2140.7*(1/(poke.exo.2020$Temp.C+273.15))^2-10.754*(1/(poke.exo.2020$Temp.C+273.15))+0.017674 )))

# 
# poke.exo.2020$datetimeAK <- as.POSIXct(strptime(poke.exo.2020$datetimeAK, "%m/%e/%y %H:%M"))


plot(poke.exo.2020$datetimeAK, poke.exo.2020$ODO.mgL)

# salinity temp and do percent value 


# 
# 
#  DEPTH #
# 
# 
# # Poke:
# 
# #download flowmeter data
# WR_20.url <- "https://drive.google.com/drive/u/1/folders/1S2L8Qg08AIhQo1ZdKdaxlJliz4bi1ttr"
# WR.20.1 <- drive_get(as_id(WR_20.url))
# poke.wr20_glist <- drive_ls(WR.20.1, pattern = "R_Flowmeter Q calculation_POKE_for_R_JAA.csv")
# walk(poke.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# poke_WR_20.Data <- read.csv("R_Flowmeter Q calculation_POKE_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# poke_WR_20.Data <- poke_WR_20.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# poke_WR_20.Data <- poke_WR_20.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# poke_WR_20.Data <- poke_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# poke_WR_20.Data$datetimeAK <- as.POSIXct(paste(poke_WR_20.Data$Date, poke_WR_20.Data$Time), format="%y%m%d %H:%M")
# 
# 
# poke_WR_20.Data <- poke_WR_20.Data %>%
#   select(Depth, datetimeAK)
# 
# Poke_depth_20 <- ddply(na.omit(poke_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth)))
# 
# # poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_20)
# 
# 
# Poke_depth_20 <- setDT(Poke_depth_20)
# 
# Poke_depth_20 <- Poke_depth_20 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# poke.exo.2020 <- setDT(poke.exo.2020)
# 
# setDT(Poke_depth_20)
# setDT(poke.exo.2020)
# 
# poke.exo.2020$datetimeAK1 <- poke.exo.2020$datetimeAK
# 
# setkey( poke.exo.2020, datetimeAK )
# setkey( Poke_depth_20, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_poke20 <- poke.exo.2020[ Poke_depth_20, roll = "nearest" ]
# 
# rounded.dates_poke20 <- rounded.dates_poke20 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_poke20 <- rounded.dates_poke20 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_poke20 <- rounded.dates_poke20 %>%
#   select(meanDepth, datetimeAK)
# 
# Poke.2020.DO.Depth <- merge(poke.exo.2020, rounded.dates_poke20, by = "datetimeAK", all = TRUE)
# Poke.2020.DO.Depth$meanDepth1 <- Poke.2020.DO.Depth$meanDepth
# 
# poke20mod <- lm(meanDepth ~ datetimeAK, Poke.2020.DO.Depth)
# 
# summary(poke20mod)
# 
# Poke.2020.DO.Depth <- Poke.2020.DO.Depth %>% 
#   mutate(predictedDepth = predict(poke20mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 
# 





### 2021 ###

#Read processed CSV from DoD 2021 Script 
exo.processed.2021 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2021/EXO_data/from_internal_harddrive/processed/EXO.processed.csv")

poke.exo.2021 <- exo.processed.2021 %>% filter(site.ID == "POKE")
poke.exo.2021 <- as.data.frame(poke.exo.2021)


#mean to when burst was taken

#mean bursts
poke.exo.2021$datetimeAK <- lubridate::round_date(as.POSIXct( poke.exo.2021$datetimeAK), "15 minutes")

pokemean2021odoMGL <- aggregate( ODO.mgL ~ datetimeAK, poke.exo.2021, mean)
pokemean2021odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, poke.exo.2021, mean)
pokemean2021odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, poke.exo.2021, mean)
pokemean2021odoTEMPC <- aggregate( Temp.C ~ datetimeAK, poke.exo.2021, mean)

pokemeans2021ODO <- plyr::join(pokemean2021odoMGL, pokemean2021odoPSAT, by = "datetimeAK")
pokemeans2021ODO <- plyr::join(pokemeans2021ODO, pokemean2021odoPLOC, by = "datetimeAK")
pokemeans2021ODO <- plyr::join(pokemeans2021ODO, pokemean2021odoTEMPC, by = "datetimeAK")




# 
# DEPTH #
# 
# 
# # Poke:
# 
# #download flowmeter data
# WR_21.url <- "https://drive.google.com/drive/u/1/folders/18z6vSz6SE3DEvUVDyfM8I3gqkGaxQqOl" 
# WR.21.1 <- drive_get(as_id(WR_21.url))
# poke.wr21_glist <- drive_ls(WR.21.1, pattern = "R_Flowmeter Q calculation_POKE_for_R_JAA_2021.csv")
# walk(poke.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# poke_WR_21.Data <- read.csv("R_Flowmeter Q calculation_POKE_for_R_JAA_2021.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# 
# poke_WR_21.Data <- poke_WR_21.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# poke_WR_21.Data <- poke_WR_21.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# poke_WR_21.Data <- poke_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# poke_WR_21.Data$datetimeAK <- as.POSIXct(paste(poke_WR_21.Data$Date, poke_WR_21.Data$Time), format="%y%m%d %H:%M")
# 
# 
# poke_WR_21.Data <- poke_WR_21.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Poke_depth_21 <- ddply(na.omit(poke_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_21)
# 
# 
# Poke_depth_21 <- setDT(Poke_depth_21)
# 
# Poke_depth_21 <- Poke_depth_21 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# pokemeans2021ODO <- setDT(pokemeans2021ODO)
# 
# setDT(Poke_depth_21)
# setDT(pokemeans2021ODO)
# 
# pokemeans2021ODO$datetimeAK1 <- pokemeans2021ODO$datetimeAK
# 
# setkey( pokemeans2021ODO, datetimeAK )
# setkey( Poke_depth_21, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_poke21 <- pokemeans2021ODO[Poke_depth_21, roll = "nearest" ]
# 
# rounded.dates_poke21 <- rounded.dates_poke21 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_poke21 <- rounded.dates_poke21 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_poke21 <- rounded.dates_poke21 %>%
#   select(meanDepth, datetimeAK)
# 
# Poke.2021.DO.Depth <- merge(pokemeans2021ODO, rounded.dates_poke21, by = "datetimeAK", all = TRUE)
# Poke.2021.DO.Depth$meanDepth1 <- Poke.2021.DO.Depth$meanDepth
# 
# poke21mod <- lm(meanDepth ~ datetimeAK, Poke.2021.DO.Depth)
# 
# summary(poke21mod)
# 
# Poke.2021.DO.Depth <- Poke.2021.DO.Depth %>% 
#   mutate(predictedDepth = predict(poke21mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 




#Put together
final.Poke.DO.2019 <- final.Poke.DO.2019 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

poke.exo.2020 <- poke.exo.2020 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

pokemeans2021ODO <- pokemeans2021ODO %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


All.years.poke.MESSY <- rbind(final.Poke.DO.2019, poke.exo.2020, pokemeans2021ODO)

All.years.poke.MESSY <- All.years.poke.MESSY %>%
  dplyr::rename(DO.obs = ODO.mgL)

All.years.poke.MESSY <- All.years.poke.MESSY %>%
  dplyr::rename(temp.water = Temp.C)


#plot all

#keep in mind 2019 and 2020 is clean data and 2021 is not.
pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/PokerODO.pdf")

testPlotPoke <- ggplot(data = All.years.poke.MESSY,
                       mapping = aes(x = datetimeAK, y = as.numeric(ODO.Psat))) + geom_point() + labs(x = "Date", y = "Percent Saturation")
testPlotPoke
dev.off()













###### STUART ######

#### 2019 ####

SondeData2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/processed_sensor_dat/SUNA.EXO.int.corr.csv")

SondeData2019$datetimeAK <- force_tz(as.POSIXct(SondeData2019$datetimeAK), "America/Anchorage")

# Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is cleaned.

SondeData2019.renamed <- SondeData2019 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)


STRT_EXO_cl.2019.renamed <- SondeData2019.renamed %>% filter(site.ID == "STRT")


# 
# 
# ########## DEPTH ############ 
# 
# 
# # Strt:
# 
# #download flowmeter data
# WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
# WR.19.1 <- drive_get(as_id(WR_19.url))
# strt.wr19_glist <- drive_ls(WR.19.1, pattern = "STRT_2019_flowmeter_Q_for_R_JAA.csv")
# walk(strt.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# strt_WR_19.Data <- read.csv("STRT_2019_flowmeter_Q_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank","can't read note here, image 190807_2"))
# 
# strt_WR_19.Data <- strt_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# strt_WR_19.Data <- strt_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# strt_WR_19.Data$datetimeAK <- as.POSIXct(paste(strt_WR_19.Data$Date, strt_WR_19.Data$Time), format="%m/%d/%Y %H:%M")
# 
# 
# strt_WR_19.Data <- strt_WR_19.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Strt_depth_19 <- ddply(na.omit(strt_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_19)
# 
# 
# Strt_depth_19 <- setDT(Strt_depth_19)
# 
# Strt_depth_19 <- Strt_depth_19 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# STRT_EXO_cl.2019.renamed <- setDT(STRT_EXO_cl.2019.renamed)
# 
# setDT(Strt_depth_19)
# setDT(STRT_EXO_cl.2019.renamed)
# 
# STRT_EXO_cl.2019.renamed$datetimeAK1 <- STRT_EXO_cl.2019.renamed$datetimeAK
# 
# setkey( STRT_EXO_cl.2019.renamed, datetimeAK )
# setkey( Strt_depth_19, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_strt19 <- STRT_EXO_cl.2019.renamed[ Strt_depth_19, roll = "nearest" ]
# 
# rounded.dates_strt19 <- rounded.dates_strt19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_strt19 <- rounded.dates_strt19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_strt19 <- rounded.dates_strt19 %>%
#   select(meanDepth, datetimeAK)
# 
# Strt.2019.DO.Depth <- merge(STRT_EXO_cl.2019.renamed, rounded.dates_strt19, by = "datetimeAK", all = TRUE)
# Strt.2019.DO.Depth$meanDepth1 <- Strt.2019.DO.Depth$meanDepth
# 
# strt19mod <- lm(meanDepth ~ datetimeAK, Strt.2019.DO.Depth)
# 
# summary(strt19mod)
# 
# Strt.2019.DO.Depth <- Strt.2019.DO.Depth %>% 
#   mutate(predictedDepth = predict(strt19mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))


#USE TELEM FILLED DATA TO CALCULATE MG/L 


#calc from YSI %Sat to MGL spreadsheet

# # DO data collected as concentrations can be 
# converted to percent saturation using temperature and salinity data collected in conjunction with 
# the DO measurements using the equations as provided in APHA, 1989:


# DOsat = (Exp((-139.34411 + (157570.1/Temp) - (66423080/Temp2
# ) + (12438000000/Temp3
# ) - 
#   (862194900000/Temp4
#   )) - (Sal * (0.017674-(10.754/Temp)+(2140.7/Temp2
#   )))))
# % DO = (DOmeasure/ DOsat)*100 


# Where:
#   DOsat = DO concentration in mg/L at 100 % saturation, 
# Temp = water temperature in Â°K (Â°C + 273.15 = Â°K) 
# DOmeasure = Measured DO concentration in mg/L.
# Sal = Salinity in part per thousand (ppt)

#Constants: 
# 862194900000
# 12438000000
# 66423080
# 157570.1
# 139.344
#

#We change this according to how YSI does it in the EXO



#in this case, we are finding the DO mg/L per percent saturation, and multiplying it by our percent sat from telem. This percent sat accounts for pressure as well I believe. 


STRT_EXO_cl.2019.renamed$ODO.mgL.Calc <-as.numeric(STRT_EXO_cl.2019.renamed$ODO.Psat) * 
  #DO mg/L per sat
  (0.01* exp(
    #p1
    (-862194900000*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))^4+12438000000*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))^3-66423080*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))^2+157570.1*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))-139.344)
    #salinity
    -0* 
      #p2
      (2140.7*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))^2-10.754*(1/(STRT_EXO_cl.2019.renamed$Temp.C+273.15))+0.017674 )))


#fill missing rows with calculated MGL
STRT_EXO_cl.2019.renamed <- STRT_EXO_cl.2019.renamed %>% 
  mutate(ODO.mgL = coalesce(ODO.mgL,ODO.mgL.Calc))






#### 2020 ####


#### 2020 ####
# exo.all.2020.url <- "https://drive.google.com/drive/u/1/folders/1nNKoIdgP-fdCNRGUbGca_zVujF_16QEM"
# exo.all.2020.prt1 <- drive_get(as_id(exo.all.2020.url))
# exo.all.2020.glist <- drive_ls(exo.all.2020.prt1, pattern = "EXO.ALL.csv")
# walk(exo.all.2020.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# exo.all.2020 <- read.csv("EXO.ALL.csv",)

strt.exo.2020 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2020/EXO_processed/STRT.EXO.cl.csv")


strt.exo.2020 <- strt.exo.2020 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn.adj, ODO.Psat = ODO.Psat.mn.adj, ODO.Ploc = ODO.Ploc.mn.adj, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)

strt.exo.2020$datetimeAK <- force_tz(as.POSIXct(strt.exo.2020$datetimeAK), "America/Anchorage")













# strt.exo.2020 <- exo.all.2020 %>% filter(site.ID == "STRT")
# 
# #convert Bursts to means
# 
# 
# 
# strt.exo.2020$datetimeAK <- as.POSIXct(strptime(strt.exo.2020$datetimeAK, "%m/%e/%y %H:%M"))
# 
# 
# 
# strt.exo.2020$Temp.C <- as.numeric(strt.exo.2020$Temp.C)
# strt.exo.2020$ODO.Psat <- as.numeric(strt.exo.2020$ODO.Psat)
# strt.exo.2020$ODO.mgL <- as.numeric(strt.exo.2020$ODO.mgL)
# strt.exo.2020$ODO.Ploc <- as.numeric(strt.exo.2020$ODO.Ploc)
# 
# 
# 
# #mean bursts
# STRTmean2020odoMGL <- aggregate( ODO.mgL ~ datetimeAK, strt.exo.2020, mean)
# STRTmean2020odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, strt.exo.2020, mean)
# STRTmean2020odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, strt.exo.2020, mean)
# STRTmean2020odoTEMPC <- aggregate( Temp.C ~ datetimeAK, strt.exo.2020, mean)
# 
# STRTmeans2020ODO <- plyr::join(STRTmean2020odoMGL, STRTmean2020odoPSAT, by = "datetimeAK")
# STRTmeans2020ODO <- plyr::join(STRTmeans2020ODO, STRTmean2020odoPLOC, by = "datetimeAK")
# STRTmeans2020ODO <- plyr::join(STRTmeans2020ODO, STRTmean2020odoTEMPC, by = "datetimeAK")



########## DEPTH ############ 

# 
# # Strt:
# 
# #download flowmeter data
# WR_20.url <- "https://drive.google.com/drive/u/1/folders/1x_E4gaPvjRLDcrM8lN2ao4_o0bzdMBrb"
# WR.20.1 <- drive_get(as_id(WR_20.url))
# strt.wr20_glist <- drive_ls(WR.20.1, pattern = "R_Flowmeter Q calculation_STRT_for_R_JAA.csv")
# walk(strt.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# strt_WR_20.Data <- read.csv("R_Flowmeter Q calculation_STRT_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# strt_WR_20.Data <- strt_WR_20.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# strt_WR_20.Data <- strt_WR_20.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# strt_WR_20.Data <- strt_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# strt_WR_20.Data$datetimeAK <- as.POSIXct(paste(strt_WR_20.Data$Date, strt_WR_20.Data$Time), format="%y%m%d %H:%M")
# 
# 
# strt_WR_20.Data <- strt_WR_20.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Strt_depth_20 <- ddply(na.omit(strt_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_20)
# 
# 
# Strt_depth_20 <- setDT(Strt_depth_20)
# 
# Strt_depth_20 <- Strt_depth_20 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# STRTmeans2020ODO <- setDT(STRTmeans2020ODO)
# 
# setDT(Strt_depth_20)
# setDT(STRTmeans2020ODO)
# 
# STRTmeans2020ODO$datetimeAK1 <- STRTmeans2020ODO$datetimeAK
# 
# setkey( STRTmeans2020ODO, datetimeAK )
# setkey( Strt_depth_20, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_strt20 <- STRTmeans2020ODO[ Strt_depth_20, roll = "nearest" ]
# 
# rounded.dates_strt20 <- rounded.dates_strt20 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_strt20 <- rounded.dates_strt20 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_strt20 <- rounded.dates_strt20 %>%
#   select(meanDepth, datetimeAK)
# 
# Strt.2020.DO.Depth <- merge(STRTmeans2020ODO, rounded.dates_strt20, by = "datetimeAK", all = TRUE)
# Strt.2020.DO.Depth$meanDepth1 <- Strt.2020.DO.Depth$meanDepth
# 
# strt20mod <- lm(meanDepth ~ datetimeAK, Strt.2020.DO.Depth)
# 
# summary(strt20mod)
# 
# Strt.2020.DO.Depth <- Strt.2020.DO.Depth %>% 
#   mutate(predictedDepth = predict(strt20mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))




#### 2021 ####
strt.exo.2021 <- exo.processed.2021 %>% filter(site.ID == "STRT")


strt.exo.2021$datetimeAK <- lubridate::round_date(strt.exo.2021$datetimeAK, "15 minutes")
strt.exo.2021$datetimeAK <- force_tz(strt.exo.2021$datetimeAK, "America/Anchorage")

strt.exo.2021$Temp.C <- as.numeric(strt.exo.2021$Temp.C)
strt.exo.2021$ODO.Psat <- as.numeric(strt.exo.2021$ODO.Psat)
strt.exo.2021$ODO.mgL <- as.numeric(strt.exo.2021$ODO.mgL)
strt.exo.2021$ODO.Ploc <- as.numeric(strt.exo.2021$ODO.Ploc)



#mean bursts
STRTmean2021odoMGL <- aggregate( ODO.mgL ~ datetimeAK, strt.exo.2021, mean)
STRTmean2021odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, strt.exo.2021, mean)
STRTmean2021odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, strt.exo.2021, mean)
STRTmean2021odoTEMPC <- aggregate( Temp.C ~ datetimeAK, strt.exo.2021, mean)

STRTmeans2021ODO <- plyr::join(STRTmean2021odoMGL, STRTmean2021odoPSAT, by = "datetimeAK")
STRTmeans2021ODO <- plyr::join(STRTmeans2021ODO, STRTmean2021odoPLOC, by = "datetimeAK")
STRTmeans2021ODO <- plyr::join(STRTmeans2021ODO, STRTmean2021odoTEMPC, by = "datetimeAK")

# ########## DEPTH ############ 
# 
# 
# # Strt:
# 
# #download flowmeter data
# WR_21.url <- "https://drive.google.com/drive/u/1/folders/1LTD4EFX3_Yas0ZCF8rKLl6dxSeZDvkDY"
# WR.21.1 <- drive_get(as_id(WR_21.url))
# strt.wr21_glist <- drive_ls(WR.21.1, pattern = "R_Flowmeter Q calculation_STRT_for_R_JAA_2021.csv")
# walk(strt.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# strt_WR_21.Data <- read.csv("R_Flowmeter Q calculation_STRT_for_R_JAA_2021.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# strt_WR_21.Data <- strt_WR_21.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# strt_WR_21.Data <- strt_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# strt_WR_21.Data$datetimeAK <- as.POSIXct(paste(strt_WR_21.Data$Date, strt_WR_21.Data$Time), format="%y%m%d %H:%M")
# 
# 
# strt_WR_21.Data <- strt_WR_21.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Strt_depth_21 <- ddply(na.omit(strt_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_21)
# 
# 
# Strt_depth_21 <- setDT(Strt_depth_21)
# 
# Strt_depth_21 <- Strt_depth_21 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# STRTmeans2021ODO <- setDT(STRTmeans2021ODO)
# 
# setDT(Strt_depth_21)
# setDT(STRTmeans2021ODO)
# 
# STRTmeans2021ODO$datetimeAK1 <- STRTmeans2021ODO$datetimeAK
# 
# setkey( STRTmeans2021ODO, datetimeAK )
# setkey( Strt_depth_21, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_strt21 <- STRTmeans2021ODO[ Strt_depth_21, roll = "nearest" ]
# 
# rounded.dates_strt21 <- rounded.dates_strt21 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_strt21 <- rounded.dates_strt21 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_strt21 <- rounded.dates_strt21 %>%
#   select(meanDepth, datetimeAK)
# 
# Strt.2021.DO.Depth <- merge(STRTmeans2021ODO, rounded.dates_strt21, by = "datetimeAK", all = TRUE)
# Strt.2021.DO.Depth$meanDepth1 <- Strt.2021.DO.Depth$meanDepth
# 
# strt21mod <- lm(meanDepth ~ datetimeAK, Strt.2021.DO.Depth)
# 
# summary(strt21mod)
# 
# Strt.2021.DO.Depth <- Strt.2021.DO.Depth %>% 
#   mutate(predictedDepth = predict(strt21mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))



#Put together
STRT_EXO_cl.2019.renamed <- STRT_EXO_cl.2019.renamed %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

strt.exo.2020 <- strt.exo.2020 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

STRTmeans2021ODO <- STRTmeans2021ODO %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


All.years.strt.MESSY <- rbind(STRT_EXO_cl.2019.renamed, strt.exo.2020, STRTmeans2021ODO)

All.years.strt.MESSY <- All.years.strt.MESSY %>%
  dplyr::rename(DO.obs = ODO.mgL)

All.years.strt.MESSY <- All.years.strt.MESSY %>%
  dplyr::rename(temp.water = Temp.C)



#keep in mind 2019 and 2020 is clean data and 2021 are not.
pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/StuartODO.pdf")

testPlotSTRT <- ggplot(data = All.years.strt.MESSY,
                       mapping = aes(x = datetimeAK, y = as.numeric(ODO.Psat))) + geom_point() + labs(x = "Date", y = "Dissolved Oxygen (%Sat)")
testPlotSTRT
dev.off()




####### VAULT #######

### 2019 ###
#Read cleaned CSVs from DoD 2019 Script 

SondeData2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/processed_sensor_dat/SUNA.EXO.int.corr.csv")

SondeData2019$datetimeAK <- force_tz(as.POSIXct(SondeData2019$datetimeAK), "America/Anchorage")

# Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is cleaned.

SondeData2019.renamed <- SondeData2019 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)


VAUL_EXO_cl.2019.renamed <- SondeData2019.renamed %>% filter(site.ID == "VAUL")




# 
# #### 2019 ####
# VAUL_EXO_cl.2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/EXO_processed/VAUL.EXO.cl.csv")
# 
# VAUL_EXO_cl.2019$datetimeAK <- force_tz(as.POSIXct(VAUL_EXO_cl.2019$datetimeAK), "America/Anchorage")
# 
# # Have to rename rows so they done have "mean" in them so it can be combined for three straight years. Data is not cleaned.
# 
# VAUL_EXO_cl.2019.renamed <- VAUL_EXO_cl.2019 %>%
#   dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

# 
# #########DEPTH ################
# # Vaul:
# 
# #download flowmeter data
# WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
# WR.19.1 <- drive_get(as_id(WR_19.url))
# vaul.wr19_glist <- drive_ls(WR.19.1, pattern = "vaul_2019_flowmeter_Q_for_R_JAA.csv")
# walk(vaul.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# vaul_WR_19.Data <- read.csv("vaul_2019_flowmeter_Q_for_R_JAA.csv",
#                             skip = 1, header = TRUE, na.strings=c("","NA","blank"))
# 
# vaul_WR_19.Data <- vaul_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# vaul_WR_19.Data <- vaul_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# vaul_WR_19.Data$datetimeAK <- as.POSIXct(paste(vaul_WR_19.Data$Date, vaul_WR_19.Data$Time), format="%m/%d/%Y %H:%M")
# 
# 
# vaul_WR_19.Data <- vaul_WR_19.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Vaul_depth_19 <- ddply(na.omit(vaul_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_19)
# 
# 
# Vaul_depth_19 <- setDT(Vaul_depth_19)
# 
# Vaul_depth_19 <- Vaul_depth_19 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# VAUL_EXO_cl.2019.renamed <- setDT(VAUL_EXO_cl.2019.renamed)
# 
# setDT(Vaul_depth_19)
# setDT(VAUL_EXO_cl.2019.renamed)
# 
# VAUL_EXO_cl.2019.renamed$datetimeAK1 <- VAUL_EXO_cl.2019.renamed$datetimeAK
# 
# setkey( VAUL_EXO_cl.2019.renamed, datetimeAK )
# setkey( Vaul_depth_19, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_vaul19 <- VAUL_EXO_cl.2019.renamed[ Vaul_depth_19, roll = "nearest" ]
# 
# rounded.dates_vaul19 <- rounded.dates_vaul19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_vaul19 <- rounded.dates_vaul19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_vaul19 <- rounded.dates_vaul19 %>%
#   select(meanDepth, datetimeAK)
# 
# Vaul.2019.DO.Depth <- merge(VAUL_EXO_cl.2019.renamed, rounded.dates_vaul19, by = "datetimeAK", all = TRUE)
# Vaul.2019.DO.Depth$meanDepth1 <- Vaul.2019.DO.Depth$meanDepth
# 
# vaul19mod <- lm(meanDepth ~ datetimeAK, Vaul.2019.DO.Depth)
# 
# summary(vaul19mod)
# 
# Vaul.2019.DO.Depth <- Vaul.2019.DO.Depth %>% 
#   mutate(predictedDepth = predict(vaul19mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 






#USE TELEM FILLED DATA TO CALCULATE MG/L 


#calc from YSI %Sat to MGL spreadsheet

# # DO data collected as concentrations can be 
# converted to percent saturation using temperature and salinity data collected in conjunction with 
# the DO measurements using the equations as provided in APHA, 1989:


# DOsat = (Exp((-139.34411 + (157570.1/Temp) - (66423080/Temp2
# ) + (12438000000/Temp3
# ) - 
#   (862194900000/Temp4
#   )) - (Sal * (0.017674-(10.754/Temp)+(2140.7/Temp2
#   )))))
# % DO = (DOmeasure/ DOsat)*100 


# Where:
#   DOsat = DO concentration in mg/L at 100 % saturation, 
# Temp = water temperature in Â°K (Â°C + 273.15 = Â°K) 
# DOmeasure = Measured DO concentration in mg/L.
# Sal = Salinity in part per thousand (ppt)

#Constants: 
# 862194900000
# 12438000000
# 66423080
# 157570.1
# 139.344
#

#We change this according to how YSI does it in the EXO



#in this case, we are finding the DO mg/L per percent saturation, and multiplying it by our percent sat from telem. This percent sat accounts for pressure as well I believe. 


VAUL_EXO_cl.2019.renamed$ODO.mgL.Calc <-as.numeric(VAUL_EXO_cl.2019.renamed$ODO.Psat) * 
  #DO mg/L per sat
  (0.01* exp(
    #p1
    (-862194900000*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))^4+12438000000*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))^3-66423080*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))^2+157570.1*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))-139.344)
    #salinity
    -0* 
      #p2
      (2140.7*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))^2-10.754*(1/(VAUL_EXO_cl.2019.renamed$Temp.C+273.15))+0.017674 )))


VAUL_EXO_cl.2019.renamed <- VAUL_EXO_cl.2019.renamed %>% 
  mutate(ODO.mgL = coalesce(ODO.mgL,ODO.mgL.Calc))



### 2020 ####


# exo.all.2020.url <- "https://drive.google.com/drive/u/1/folders/1nNKoIdgP-fdCNRGUbGca_zVujF_16QEM"
# exo.all.2020.prt1 <- drive_get(as_id(exo.all.2020.url))
# exo.all.2020.glist <- drive_ls(exo.all.2020.prt1, pattern = "EXO.ALL.csv")
# walk(exo.all.2020.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# exo.all.2020 <- read.csv("EXO.ALL.csv",)

vaul.exo.2020 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2020/EXO_processed/VAUL.EXO.cl.csv")


vaul.exo.2020 <- vaul.exo.2020 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn.adj, ODO.Psat = ODO.Psat.mn.adj, ODO.Ploc = ODO.Ploc.mn.adj, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)

vaul.exo.2020$datetimeAK <- force_tz(as.POSIXct(vaul.exo.2020$datetimeAK), "America/Anchorage")



# 
# vaul.exo.2020 <- exo.all.2020 %>% filter(site.ID == "VAUL")


# #remove bad data point
# vaul.exo.2020 <- vaul.exo.2020[-c(56619)]


#convert Bursts to means

# 
# 
# vaul.exo.2020$datetimeAK <- as.POSIXct(strptime(vaul.exo.2020$datetimeAK, "%m/%e/%y %H:%M"))
# 
# 
# 
# vaul.exo.2020$Temp.C <- as.numeric(vaul.exo.2020$Temp.C)
# vaul.exo.2020$ODO.Psat <- as.numeric(vaul.exo.2020$ODO.Psat)
# vaul.exo.2020$ODO.mgL <- as.numeric(vaul.exo.2020$ODO.mgL)
# vaul.exo.2020$ODO.Ploc <- as.numeric(vaul.exo.2020$ODO.Ploc)
# 
# 
# 
# #mean bursts
# VAULmean2020odoMGL <- aggregate( ODO.mgL ~ datetimeAK, vaul.exo.2020, mean)
# VAULmean2020odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, vaul.exo.2020, mean)
# VAULmean2020odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, vaul.exo.2020, mean)
# VAULmean2020odoTEMPC <- aggregate( Temp.C ~ datetimeAK, vaul.exo.2020, mean)
# 
# VAULmeans2020ODO <- plyr::join(VAULmean2020odoMGL, VAULmean2020odoPSAT, by = "datetimeAK")
# VAULmeans2020ODO <- plyr::join(VAULmeans2020ODO, VAULmean2020odoPLOC, by = "datetimeAK")
# VAULmeans2020ODO <- plyr::join(VAULmeans2020ODO, VAULmean2020odoTEMPC, by = "datetimeAK")
# 
# #remove outlier point
# VAULmeans2020ODO.1 <- VAULmeans2020ODO %>% filter(datetimeAK <= "2020-08-09 22:30:00")
# VAULmeans2020ODO.2 <- VAULmeans2020ODO %>% filter(datetimeAK > "2020-08-09 23:00:00")
# 
# VAULmeans2020ODO <- rbind(VAULmeans2020ODO.1,VAULmeans2020ODO.2)                                                  
# VAULmeans2020ODO$datetimeAK <-  lubridate::round_date(VAULmeans2020ODO$datetimeAK, "15 minutes") 
# 
# VAULmeans2020ODO <- distinct(VAULmeans2020ODO)
# 
# #duplicate rows meaned
# library(plyr)
# VAULmeans2020ODO = ddply(
#   VAULmeans2020ODO,
#   .(datetimeAK),
#   function(df_section) {
#     res_df = data.frame(datetimeAK=df_section$datetimeAK[1], ODO.mgL=mean(df_section$ODO.mgL), ODO.Ploc = mean(df_section$ODO.Ploc), ODO.Psat = mean(df_section$ODO.Psat), Temp.C = mean(df_section$Temp.C))
#   }
# )
# 
# ########## DEPTH ############ 
# 
# 
# # Vaul:
# 
# #download flowmeter data
# WR_20.url <- "https://drive.google.com/drive/u/1/folders/1l-QIICuviZvugbNGrvoLfkCDgo1HyDMg"
# WR.20.1 <- drive_get(as_id(WR_20.url))
# vaul.wr20_glist <- drive_ls(WR.20.1, pattern = "R_Flowmeter Q calculation_VAUL_for_R_JAA.csv")
# walk(vaul.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# vaul_WR_20.Data <- read.csv("R_Flowmeter Q calculation_VAUL_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# vaul_WR_20.Data <- vaul_WR_20.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# vaul_WR_20.Data <- vaul_WR_20.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# vaul_WR_20.Data <- vaul_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# vaul_WR_20.Data$datetimeAK <- as.POSIXct(paste(vaul_WR_20.Data$Date, vaul_WR_20.Data$Time), format="%y%m%d %H:%M")
# 
# 
# vaul_WR_20.Data <- vaul_WR_20.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Vaul_depth_20 <- ddply(na.omit(vaul_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_20)
# 
# 
# Vaul_depth_20 <- setDT(Vaul_depth_20)
# 
# Vaul_depth_20 <- Vaul_depth_20 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# VAULmeans2020ODO <- setDT(VAULmeans2020ODO)
# 
# setDT(Vaul_depth_20)
# setDT(VAULmeans2020ODO)
# 
# VAULmeans2020ODO$datetimeAK1 <- VAULmeans2020ODO$datetimeAK
# 
# setkey( VAULmeans2020ODO, datetimeAK )
# setkey( Vaul_depth_20, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_vaul20 <- VAULmeans2020ODO[ Vaul_depth_20, roll = "nearest" ]
# 
# rounded.dates_vaul20 <- rounded.dates_vaul20 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_vaul20 <- rounded.dates_vaul20 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_vaul20 <- rounded.dates_vaul20 %>%
#   select(meanDepth, datetimeAK)
# 
# Vaul.2020.DO.Depth <- merge(VAULmeans2020ODO, rounded.dates_vaul20, by = "datetimeAK", all = TRUE)
# Vaul.2020.DO.Depth$meanDepth1 <- Vaul.2020.DO.Depth$meanDepth
# 
# vaul20mod <- lm(meanDepth ~ datetimeAK, Vaul.2020.DO.Depth)
# 
# summary(vaul20mod)
# 
# Vaul.2020.DO.Depth <- Vaul.2020.DO.Depth %>% 
#   mutate(predictedDepth = predict(vaul20mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 





#### 2021 ####
vaul.exo.2021 <- exo.processed.2021 %>% filter(site.ID == "VAUL")


vaul.exo.2021$datetimeAK <- lubridate::round_date(vaul.exo.2021$datetimeAK, "15 minutes")
vaul.exo.2021$datetimeAK <- force_tz(vaul.exo.2021$datetimeAK, "America/Anchorage")

vaul.exo.2021$Temp.C <- as.numeric(vaul.exo.2021$Temp.C)
vaul.exo.2021$ODO.Psat <- as.numeric(vaul.exo.2021$ODO.Psat)
vaul.exo.2021$ODO.mgL <- as.numeric(vaul.exo.2021$ODO.mgL)
vaul.exo.2021$ODO.Ploc <- as.numeric(vaul.exo.2021$ODO.Ploc)



#mean bursts
VAULmean2021odoMGL <- aggregate( ODO.mgL ~ datetimeAK, vaul.exo.2021, mean)
VAULmean2021odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, vaul.exo.2021, mean)
VAULmean2021odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, vaul.exo.2021, mean)
VAULmean2021odoTEMPC <- aggregate( Temp.C ~ datetimeAK, vaul.exo.2021, mean)

VAULmeans2021ODO <- plyr::join(VAULmean2021odoMGL, VAULmean2021odoPSAT, by = "datetimeAK")
VAULmeans2021ODO <- plyr::join(VAULmeans2021ODO, VAULmean2021odoPLOC, by = "datetimeAK")
VAULmeans2021ODO <- plyr::join(VAULmeans2021ODO, VAULmean2021odoTEMPC, by = "datetimeAK")

# 
# ########## DEPTH ############ 
# 
# 
# # Vaul:
# 
# #download flowmeter data
# WR_21.url <- "https://drive.google.com/drive/u/1/folders/13avby555rryYttGDgO8sKE7umZPmo5uB"
# WR.21.1 <- drive_get(as_id(WR_21.url))
# vaul.wr21_glist <- drive_ls(WR.21.1, pattern = "R_Flowmeter Q calculation_VAUL_for_R_JAA_2021.csv")
# walk(vaul.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# vaul_WR_21.Data <- read.csv("R_Flowmeter Q calculation_VAUL_for_R_JAA_2021.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# vaul_WR_21.Data <- vaul_WR_21.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# vaul_WR_21.Data <- vaul_WR_21.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# vaul_WR_21.Data <- vaul_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# vaul_WR_21.Data$datetimeAK <- as.POSIXct(paste(vaul_WR_21.Data$Date, vaul_WR_21.Data$Time), format="%y%m%d %H:%M")
# 
# 
# vaul_WR_21.Data <- vaul_WR_21.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Vaul_depth_21 <- ddply(na.omit(vaul_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_21)
# 
# 
# Vaul_depth_21 <- setDT(Vaul_depth_21)
# 
# Vaul_depth_21 <- Vaul_depth_21 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# VAULmeans2021ODO <- setDT(VAULmeans2021ODO)
# 
# setDT(Vaul_depth_21)
# setDT(VAULmeans2021ODO)
# 
# VAULmeans2021ODO$datetimeAK1 <- VAULmeans2021ODO$datetimeAK
# 
# setkey( VAULmeans2021ODO, datetimeAK )
# setkey( Vaul_depth_21, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_vaul21 <- VAULmeans2021ODO[ Vaul_depth_21, roll = "nearest" ]
# 
# rounded.dates_vaul21 <- rounded.dates_vaul21 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_vaul21 <- rounded.dates_vaul21 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_vaul21 <- rounded.dates_vaul21 %>%
#   select(meanDepth, datetimeAK)
# 
# Vaul.2021.DO.Depth <- merge(VAULmeans2021ODO, rounded.dates_vaul21, by = "datetimeAK", all = TRUE)
# Vaul.2021.DO.Depth$meanDepth1 <- Vaul.2021.DO.Depth$meanDepth
# 
# vaul21mod <- lm(meanDepth ~ datetimeAK, Vaul.2021.DO.Depth)
# 
# summary(vaul21mod)
# 
# Vaul.2021.DO.Depth <- Vaul.2021.DO.Depth %>% 
#   mutate(predictedDepth = predict(vaul21mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))



#Put together
VAUL_EXO_cl.2019.renamed <- VAUL_EXO_cl.2019.renamed %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

vaul.exo.2020 <- vaul.exo.2020 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


VAULmeans2021ODO <- VAULmeans2021ODO %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


All.years.vaul.MESSY <- rbind(VAUL_EXO_cl.2019.renamed, vaul.exo.2020, VAULmeans2021ODO)

All.years.vaul.MESSY <- All.years.vaul.MESSY %>%
  dplyr::rename(DO.obs = ODO.mgL)

All.years.vaul.MESSY <- All.years.vaul.MESSY %>%
  dplyr::rename(temp.water = Temp.C)


# All.years.vaul.MESSY <- All.years.vaul.MESSY[-c(19166)]


#keep in mind 2019 and 2020 is clean data and 2021 is not.
pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/VaultODO.pdf")

testPlotVAUL <- ggplot(data = All.years.vaul.MESSY,
                       mapping = aes(x = datetimeAK, y = as.numeric(ODO.Psat))) + geom_point() + labs(x = "Date", y = "Dissolved Oxygen (%Sat)")
testPlotVAUL
dev.off()





####### MOOS #######

#### 2019 ####

SondeData2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/processed_sensor_dat/SUNA.EXO.int.corr.csv")

SondeData2019$datetimeAK <- force_tz(as.POSIXct(SondeData2019$datetimeAK), "America/Anchorage")

# Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is cleaned.

SondeData2019.renamed <- SondeData2019 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)


MOOS_EXO_cl.2019.renamed <- SondeData2019.renamed %>% filter(site.ID == "MOOS")


# 
# MOOS_EXO_cl.2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/EXO_processed/MOOS.EXO.cl.csv")
# 
# MOOS_EXO_cl.2019$datetimeAK <- force_tz(as.POSIXct(MOOS_EXO_cl.2019$datetimeAK), "America/Anchorage")
# 
# # Have to rename rows so they done have "mean" in them so it can be combined for three straight years. Data is not cleaned.
# 
# MOOS_EXO_cl.2019.renamed <- MOOS_EXO_cl.2019 %>%
#   dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)
# 

# 
# ########## DEPTH ############ 
# 
# 
# # Moos:
# 
# #download flowmeter data
# WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
# WR.19.1 <- drive_get(as_id(WR_19.url))
# moos.wr19_glist <- drive_ls(WR.19.1, pattern = "moos_2019_flowmeter_Q_for_R_JAA.csv")
# walk(moos.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# moos_WR_19.Data <- read.csv("moos_2019_flowmeter_Q_for_R_JAA.csv",
#                             skip = 1, header = TRUE, na.strings=c("","NA","blank"))
# 
# moos_WR_19.Data <- moos_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# moos_WR_19.Data <- moos_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# moos_WR_19.Data$datetimeAK <- as.POSIXct(paste(moos_WR_19.Data$Date, moos_WR_19.Data$Time), format="%m/%d/%Y %H:%M")
# 
# 
# moos_WR_19.Data <- moos_WR_19.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Moos_depth_19 <- ddply(na.omit(moos_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_19)
# 
# 
# Moos_depth_19 <- setDT(Moos_depth_19)
# 
# Moos_depth_19 <- Moos_depth_19 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# MOOS_EXO_cl.2019.renamed <- setDT(MOOS_EXO_cl.2019.renamed)
# 
# setDT(Moos_depth_19)
# setDT(MOOS_EXO_cl.2019.renamed)
# 
# MOOS_EXO_cl.2019.renamed$datetimeAK1 <- MOOS_EXO_cl.2019.renamed$datetimeAK
# 
# setkey( MOOS_EXO_cl.2019.renamed, datetimeAK )
# setkey( Moos_depth_19, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_moos19 <- MOOS_EXO_cl.2019.renamed[ Moos_depth_19, roll = "nearest" ]
# 
# rounded.dates_moos19 <- rounded.dates_moos19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_moos19 <- rounded.dates_moos19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_moos19 <- rounded.dates_moos19 %>%
#   select(meanDepth, datetimeAK)
# 
# Moos.2019.DO.Depth <- merge(MOOS_EXO_cl.2019.renamed, rounded.dates_moos19, by = "datetimeAK", all = TRUE)
# Moos.2019.DO.Depth$meanDepth1 <- Moos.2019.DO.Depth$meanDepth
# 
# moos19mod <- lm(meanDepth ~ datetimeAK, Moos.2019.DO.Depth)
# 
# summary(moos19mod)
# 
# Moos.2019.DO.Depth <- Moos.2019.DO.Depth %>% 
#   mutate(predictedDepth = predict(moos19mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))



#USE TELEM FILLED DATA TO CALCULATE MG/L 


#calc from YSI %Sat to MGL spreadsheet

# # DO data collected as concentrations can be 
# converted to percent saturation using temperature and salinity data collected in conjunction with 
# the DO measurements using the equations as provided in APHA, 1989:


# DOsat = (Exp((-139.34411 + (157570.1/Temp) - (66423080/Temp2
# ) + (12438000000/Temp3
# ) - 
#   (862194900000/Temp4
#   )) - (Sal * (0.017674-(10.754/Temp)+(2140.7/Temp2
#   )))))
# % DO = (DOmeasure/ DOsat)*100 


# Where:
#   DOsat = DO concentration in mg/L at 100 % saturation, 
# Temp = water temperature in Â°K (Â°C + 273.15 = Â°K) 
# DOmeasure = Measured DO concentration in mg/L.
# Sal = Salinity in part per thousand (ppt)

#Constants: 
# 862194900000
# 12438000000
# 66423080
# 157570.1
# 139.344
#

#We change this according to how YSI does it in the EXO



#in this case, we are finding the DO mg/L per percent saturation, and multiplying it by our percent sat from telem. This percent sat accounts for pressure as well I believe. 


MOOS_EXO_cl.2019.renamed$ODO.mgL.Calc <-as.numeric(MOOS_EXO_cl.2019.renamed$ODO.Psat) * 
  #DO mg/L per sat
  (0.01* exp(
    #p1
    (-862194900000*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))^4+12438000000*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))^3-66423080*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))^2+157570.1*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))-139.344)
    #salinity
    -0* 
      #p2
      (2140.7*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))^2-10.754*(1/(MOOS_EXO_cl.2019.renamed$Temp.C+273.15))+0.017674 )))

#fill missing rows with calculated MGL
MOOS_EXO_cl.2019.renamed <- MOOS_EXO_cl.2019.renamed %>% 
  mutate(ODO.mgL = coalesce(ODO.mgL,ODO.mgL.Calc))





### 2020 ####

# exo.all.2020.url <- "https://drive.google.com/drive/u/1/folders/1nNKoIdgP-fdCNRGUbGca_zVujF_16QEM"
# exo.all.2020.prt1 <- drive_get(as_id(exo.all.2020.url))
# exo.all.2020.glist <- drive_ls(exo.all.2020.prt1, pattern = "EXO.ALL.csv")
# walk(exo.all.2020.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# exo.all.2020 <- read.csv("EXO.ALL.csv",)

moos.exo.2020 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2020/EXO_processed/MOOS.EXO.cl.csv")


moos.exo.2020 <- moos.exo.2020 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn.adj, ODO.Psat = ODO.Psat.mn.adj, ODO.Ploc = ODO.Ploc.mn.adj, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)

moos.exo.2020$datetimeAK <- force_tz(as.POSIXct(moos.exo.2020$datetimeAK), "America/Anchorage")
# 
# moos.exo.2020 <- exo.all.2020 %>% filter(site.ID == "MOOS")
# 
# #convert Bursts to means
# 
# 
# 
# moos.exo.2020$datetimeAK <- as.POSIXct(strptime(moos.exo.2020$datetimeAK, "%m/%e/%y %H:%M"))
# 
# 
# 
# moos.exo.2020$Temp.C <- as.numeric(moos.exo.2020$Temp.C)
# moos.exo.2020$ODO.Psat <- as.numeric(moos.exo.2020$ODO.Psat)
# moos.exo.2020$ODO.mgL <- as.numeric(moos.exo.2020$ODO.mgL)
# moos.exo.2020$ODO.Ploc <- as.numeric(moos.exo.2020$ODO.Ploc)
# 
# 
# 
# #mean bursts
# MOOSmean2020odoMGL <- aggregate( ODO.mgL ~ datetimeAK, moos.exo.2020, mean)
# MOOSmean2020odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, moos.exo.2020, mean)
# MOOSmean2020odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, moos.exo.2020, mean)
# MOOSmean2020odoTEMPC <- aggregate( Temp.C ~ datetimeAK, moos.exo.2020, mean)
# 
# MOOSmeans2020ODO <- plyr::join(MOOSmean2020odoMGL, MOOSmean2020odoPSAT, by = "datetimeAK")
# MOOSmeans2020ODO <- plyr::join(MOOSmeans2020ODO, MOOSmean2020odoPLOC, by = "datetimeAK")
# MOOSmeans2020ODO <- plyr::join(MOOSmeans2020ODO, MOOSmean2020odoTEMPC, by = "datetimeAK")
# 
# 
# 
# ########## DEPTH ############ 
# 
# 
# # Moos:
# 
# #download flowmeter data
# WR_20.url <- "https://drive.google.com/drive/u/1/folders/1O28nv-6gsmC_xsAwUFRjjouY9hS29FtK"
# WR.20.1 <- drive_get(as_id(WR_20.url))
# moos.wr20_glist <- drive_ls(WR.20.1, pattern = "R_Flowmeter Q calculation_MOOS_for_R_JAA.csv")
# walk(moos.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# moos_WR_20.Data <- read.csv("R_Flowmeter Q calculation_MOOS_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# moos_WR_20.Data <- moos_WR_20.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# moos_WR_20.Data <- moos_WR_20.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# moos_WR_20.Data <- moos_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# moos_WR_20.Data$datetimeAK <- as.POSIXct(paste(moos_WR_20.Data$Date, moos_WR_20.Data$Time), format="%y%m%d %H:%M")
# 
# 
# moos_WR_20.Data <- moos_WR_20.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Moos_depth_20 <- ddply(na.omit(moos_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_20)
# 
# 
# Moos_depth_20 <- setDT(Moos_depth_20)
# 
# Moos_depth_20 <- Moos_depth_20 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# MOOSmeans2020ODO <- setDT(MOOSmeans2020ODO)
# 
# setDT(Moos_depth_20)
# setDT(MOOSmeans2020ODO)
# 
# MOOSmeans2020ODO$datetimeAK1 <- MOOSmeans2020ODO$datetimeAK
# 
# setkey( MOOSmeans2020ODO, datetimeAK )
# setkey( Moos_depth_20, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_moos20 <- MOOSmeans2020ODO[ Moos_depth_20, roll = "nearest" ]
# 
# rounded.dates_moos20 <- rounded.dates_moos20 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_moos20 <- rounded.dates_moos20 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_moos20 <- rounded.dates_moos20 %>%
#   select(meanDepth, datetimeAK)
# 
# Moos.2020.DO.Depth <- merge(MOOSmeans2020ODO, rounded.dates_moos20, by = "datetimeAK", all = TRUE)
# Moos.2020.DO.Depth$meanDepth1 <- Moos.2020.DO.Depth$meanDepth
# 
# moos20mod <- lm(meanDepth ~ datetimeAK, Moos.2020.DO.Depth)
# 
# summary(moos20mod)
# 
# Moos.2020.DO.Depth <- Moos.2020.DO.Depth %>% 
#   mutate(predictedDepth = predict(moos20mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 




#### 2021 ####
moos.exo.2021 <- exo.processed.2021 %>% filter(site.ID == "MOOS")


moos.exo.2021$datetimeAK <- lubridate::round_date(moos.exo.2021$datetimeAK, "15 minutes")
moos.exo.2021$datetimeAK <- force_tz(moos.exo.2021$datetimeAK, "America/Anchorage")

moos.exo.2021$Temp.C <- as.numeric(moos.exo.2021$Temp.C)
moos.exo.2021$ODO.Psat <- as.numeric(moos.exo.2021$ODO.Psat)
moos.exo.2021$ODO.mgL <- as.numeric(moos.exo.2021$ODO.mgL)
moos.exo.2021$ODO.Ploc <- as.numeric(moos.exo.2021$ODO.Ploc)



#mean bursts
MOOSmean2021odoMGL <- aggregate( ODO.mgL ~ datetimeAK, moos.exo.2021, mean)
MOOSmean2021odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, moos.exo.2021, mean)
MOOSmean2021odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, moos.exo.2021, mean)
MOOSmean2021odoTEMPC <- aggregate( Temp.C ~ datetimeAK, moos.exo.2021, mean)

MOOSmeans2021ODO <- plyr::join(MOOSmean2021odoMGL, MOOSmean2021odoPSAT, by = "datetimeAK")
MOOSmeans2021ODO <- plyr::join(MOOSmeans2021ODO, MOOSmean2021odoPLOC, by = "datetimeAK")
MOOSmeans2021ODO <- plyr::join(MOOSmeans2021ODO, MOOSmean2021odoTEMPC, by = "datetimeAK")
# 
# ########## DEPTH ############ 
# 
# 
# # Moos:
# 
# #download flowmeter data
# WR_21.url <- "https://drive.google.com/drive/u/1/folders/1-S_ixEutlA7RKfrvhi15aIBLrjYjg5O_"
# WR.21.1 <- drive_get(as_id(WR_21.url))
# moos.wr21_glist <- drive_ls(WR.21.1, pattern = "R_Flowmeter Q calculation_MOOS_for_R_JAA_2021.csv")
# walk(moos.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# moos_WR_21.Data <- read.csv("R_Flowmeter Q calculation_MOOS_for_R_JAA_2021.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# moos_WR_21.Data <- moos_WR_21.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# moos_WR_21.Data <- moos_WR_21.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# moos_WR_21.Data <- moos_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# moos_WR_21.Data$datetimeAK <- as.POSIXct(paste(moos_WR_21.Data$Date, moos_WR_21.Data$Time), format="%y%m%d %H:%M")
# 
# 
# moos_WR_21.Data <- moos_WR_21.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Moos_depth_21 <- ddply(na.omit(moos_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_21)
# 
# 
# Moos_depth_21 <- setDT(Moos_depth_21)
# 
# Moos_depth_21 <- Moos_depth_21 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# MOOSmeans2021ODO <- setDT(MOOSmeans2021ODO)
# 
# setDT(Moos_depth_21)
# setDT(MOOSmeans2021ODO)
# 
# MOOSmeans2021ODO$datetimeAK1 <- MOOSmeans2021ODO$datetimeAK
# 
# setkey( MOOSmeans2021ODO, datetimeAK )
# setkey( Moos_depth_21, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_moos21 <- MOOSmeans2021ODO[ Moos_depth_21, roll = "nearest" ]
# 
# rounded.dates_moos21 <- rounded.dates_moos21 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_moos21 <- rounded.dates_moos21 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_moos21 <- rounded.dates_moos21 %>%
#   select(meanDepth, datetimeAK)
# 
# Moos.2021.DO.Depth <- merge(MOOSmeans2021ODO, rounded.dates_moos21, by = "datetimeAK", all = TRUE)
# Moos.2021.DO.Depth$meanDepth1 <- Moos.2021.DO.Depth$meanDepth
# 
# moos21mod <- lm(meanDepth ~ datetimeAK, Moos.2021.DO.Depth)
# 
# summary(moos21mod)
# 
# Moos.2021.DO.Depth <- Moos.2021.DO.Depth %>% 
#   mutate(predictedDepth = predict(moos21mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 



#Put together
MOOS_EXO_cl.2019.renamed <- MOOS_EXO_cl.2019.renamed %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

moos.exo.2020 <- moos.exo.2020 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

MOOSmeans2021ODO <- MOOSmeans2021ODO %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


All.years.moos.MESSY <- rbind(MOOS_EXO_cl.2019.renamed, moos.exo.2020, MOOSmeans2021ODO)

All.years.moos.MESSY <- All.years.moos.MESSY %>%
  dplyr::rename(DO.obs = ODO.mgL)

All.years.moos.MESSY <- All.years.moos.MESSY %>%
  dplyr::rename(temp.water = Temp.C)



#keep in mind 2019 and 2020 is clean data and 2021 are not.
pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/MoosODO.pdf")

testPlotMOOS <- ggplot(data = All.years.moos.MESSY,
                       mapping = aes(x = datetimeAK, y = as.numeric(ODO.Psat))) + geom_point() + labs(x = "Date", y = "Dissolved Oxygen (%Sat)")
testPlotMOOS
dev.off()







####### FRCH #######

#### 2019 ####

#Read cleaned CSVs from DoD 2019 Script 

SondeData2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/processed_sensor_dat/SUNA.EXO.int.corr.csv")

SondeData2019$datetimeAK <- force_tz(as.POSIXct(SondeData2019$datetimeAK), "America/Anchorage")

# Have to rename rows so they dont have "mean" in them so it can be combined for three straight years. Data is cleaned.

SondeData2019.renamed <- SondeData2019 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)


FRCH_EXO_cl.2019.renamed <- SondeData2019.renamed %>% filter(site.ID == "FRCH")




# 
# 
# FRCH_EXO_cl.2019 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2019/EXO_processed/FRCH.EXO.cl.csv")
# 
# FRCH_EXO_cl.2019$datetimeAK <- force_tz(as.POSIXct(FRCH_EXO_cl.2019$datetimeAK), "America/Anchorage")
# 
# # Have to rename rows so they done have "mean" in them so it can be combined for three straight years. Data is not cleaned.
# 
# FRCH_EXO_cl.2019.renamed <- FRCH_EXO_cl.2019 %>%
#   dplyr::rename(ODO.mgL = ODO.mgL.mn, ODO.Psat = ODO.Psat.mn, ODO.Ploc = ODO.Ploc.mn, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)
# 
# 
# ########## DEPTH ############ 
# 
# 
# # Frch:
# 
# #download flowmeter data
# WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
# WR.19.1 <- drive_get(as_id(WR_19.url))
# frch.wr19_glist <- drive_ls(WR.19.1, pattern = "Frch_2019_flowmeter_Q_for_R_JAA.csv")
# walk(frch.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# frch_WR_19.Data <- read.csv("Frch_2019_flowmeter_Q_for_R_JAA.csv",
#                             skip = 1, header = TRUE, na.strings=c("","NA","blank"))
# 
# frch_WR_19.Data <- frch_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# frch_WR_19.Data <- frch_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# frch_WR_19.Data$datetimeAK <- as.POSIXct(paste(frch_WR_19.Data$Date, frch_WR_19.Data$Time), format="%m/%d/%Y %H:%M")
# 
# 
# frch_WR_19.Data <- frch_WR_19.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Frch_depth_19 <- ddply(na.omit(frch_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_19)
# 
# 
# Frch_depth_19 <- setDT(Frch_depth_19)
# 
# Frch_depth_19 <- Frch_depth_19 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# FRCH_EXO_cl.2019.renamed <- setDT(FRCH_EXO_cl.2019.renamed)
# 
# setDT(Frch_depth_19)
# setDT(FRCH_EXO_cl.2019.renamed)
# 
# FRCH_EXO_cl.2019.renamed$datetimeAK1 <- FRCH_EXO_cl.2019.renamed$datetimeAK
# 
# setkey( FRCH_EXO_cl.2019.renamed, datetimeAK )
# setkey( Frch_depth_19, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_frch19 <- FRCH_EXO_cl.2019.renamed[ Frch_depth_19, roll = "nearest" ]
# 
# rounded.dates_frch19 <- rounded.dates_frch19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_frch19 <- rounded.dates_frch19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_frch19 <- rounded.dates_frch19 %>%
#   select(meanDepth, datetimeAK)
# 
# Frch.2019.DO.Depth <- merge(FRCH_EXO_cl.2019.renamed, rounded.dates_frch19, by = "datetimeAK", all = TRUE)
# Frch.2019.DO.Depth$meanDepth1 <- Frch.2019.DO.Depth$meanDepth
# 
# frch19mod <- lm(meanDepth ~ datetimeAK, Frch.2019.DO.Depth)
# 
# summary(frch19mod)
# 
# Frch.2019.DO.Depth <- Frch.2019.DO.Depth %>% 
#   mutate(predictedDepth = predict(frch19mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))



#USE TELEM FILLED DATA TO CALCULATE MG/L 


#calc from YSI %Sat to MGL spreadsheet

# # DO data collected as concentrations can be 
# converted to percent saturation using temperature and salinity data collected in conjunction with 
# the DO measurements using the equations as provided in APHA, 1989:


# DOsat = (Exp((-139.34411 + (157570.1/Temp) - (66423080/Temp2
# ) + (12438000000/Temp3
# ) - 
#   (862194900000/Temp4
#   )) - (Sal * (0.017674-(10.754/Temp)+(2140.7/Temp2
#   )))))
# % DO = (DOmeasure/ DOsat)*100 


# Where:
#   DOsat = DO concentration in mg/L at 100 % saturation, 
# Temp = water temperature in Â°K (Â°C + 273.15 = Â°K) 
# DOmeasure = Measured DO concentration in mg/L.
# Sal = Salinity in part per thousand (ppt)

#Constants: 
# 862194900000
# 12438000000
# 66423080
# 157570.1
# 139.344
#

#We change this according to how YSI does it in the EXO



#in this case, we are finding the DO mg/L per percent saturation, and multiplying it by our percent sat from telem. This percent sat accounts for pressure as well I believe. 


FRCH_EXO_cl.2019.renamed$ODO.mgL.Calc <-as.numeric(FRCH_EXO_cl.2019.renamed$ODO.Psat) * 
  #DO mg/L per sat
  (0.01* exp(
    #p1
    (-862194900000*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))^4+12438000000*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))^3-66423080*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))^2+157570.1*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))-139.344)
    #salinity
    -0* 
      #p2
      (2140.7*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))^2-10.754*(1/(FRCH_EXO_cl.2019.renamed$Temp.C+273.15))+0.017674 )))

#fill missing rows with calculated MGL
FRCH_EXO_cl.2019.renamed <- FRCH_EXO_cl.2019.renamed %>% 
  mutate(ODO.mgL = coalesce(ODO.mgL,ODO.mgL.Calc))





### 2020 ####

frch.exo.2020 <- read_csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_2020/EXO_processed/FRCH.EXO.cl.csv")


frch.exo.2020 <- frch.exo.2020 %>%
  dplyr::rename(ODO.mgL = ODO.mgL.mn.adj, ODO.Psat = ODO.Psat.mn.adj, ODO.Ploc = ODO.Ploc.mn.adj, Temp.C = Temp.C.mn) %>% select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc, site.ID)

frch.exo.2020$datetimeAK <- force_tz(as.POSIXct(frch.exo.2020$datetimeAK), "America/Anchorage")


# frch.exo.2020 <- exo.all.2020 %>% filter(site.ID == "FRCH")
# 
# #convert Bursts to means
# 
# frch.exo.2020$Temp.C <- as.numeric(frch.exo.2020$Temp.C)
# frch.exo.2020$ODO.Psat <- as.numeric(frch.exo.2020$ODO.Psat)
# frch.exo.2020$ODO.mgL <- as.numeric(frch.exo.2020$ODO.mgL)
# frch.exo.2020$ODO.Ploc <- as.numeric(frch.exo.2020$ODO.Ploc)
# 
# frch.exo.2020$datetimeAK <- lubridate::round_date(frch.exo.2020$DateTime, "15 minutes") 
# 
# #mean bursts
# frch.exo.2020$datetimeAK <- as.POSIXct(paste(frch.exo.2020$Date, frch.exo.2020$Time), format="%m/%e/%y %H:%M:%S")
# frch.exo.2020$datetimeAK <- lubridate::round_date(frch.exo.2020$datetimeAK, "15 minutes") 
# 
# FRCHmean2020odoMGL <- aggregate( ODO.mgL ~ datetimeAK, frch.exo.2020, mean)
# FRCHmean2020odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, frch.exo.2020, mean)
# FRCHmean2020odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, frch.exo.2020, mean)
# FRCHmean2020odoTEMPC <- aggregate( Temp.C ~ datetimeAK, frch.exo.2020, mean)
# 
# FRCHmeans2020ODO <- plyr::join(FRCHmean2020odoMGL, FRCHmean2020odoPSAT, by = "datetimeAK")
# FRCHmeans2020ODO <- plyr::join(FRCHmeans2020ODO, FRCHmean2020odoPLOC, by = "datetimeAK")
# FRCHmeans2020ODO <- plyr::join(FRCHmeans2020ODO, FRCHmean2020odoTEMPC, by = "datetimeAK")
# 
# 
# FRCHmeans2020ODO.1 <- FRCHmeans2020ODO %>% filter(datetimeAK < "2020-06-13 18:45:00" & datetimeAK > "2020-06-11 13:45:00)")
# 
# FRCHmeans2020ODO.2 <- FRCHmeans2020ODO %>% filter(datetimeAK >= "2020-09-02 13:00:00")
# 
# FRCHmeans2020ODO <- rbind(FRCHmeans2020ODO.1, FRCHmeans2020ODO.2)
# 
# 
# 
# ########## DEPTH ############ 
# 
# 
# # Frch:
# 
# #download flowmeter data
# WR_20.url <- "https://drive.google.com/drive/u/1/folders/1tlcGKOm11j4nPqgBeTa1Hj6DFTrbZTvy"
# WR.20.1 <- drive_get(as_id(WR_20.url))
# frch.wr20_glist <- drive_ls(WR.20.1, pattern = "R_Flowmeter Q calculation_FRCH_for_R_JAA.csv")
# walk(frch.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# frch_WR_20.Data <- read.csv("R_Flowmeter Q calculation_FRCH_for_R_JAA.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# frch_WR_20.Data <- frch_WR_20.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# frch_WR_20.Data <- frch_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# frch_WR_20.Data$datetimeAK <- as.POSIXct(paste(frch_WR_20.Data$Date, frch_WR_20.Data$Time), format="%y%m%d %H:%M")
# 
# 
# frch_WR_20.Data <- frch_WR_20.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Frch_depth_20 <- ddply(na.omit(frch_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_20)
# 
# 
# Frch_depth_20 <- setDT(Frch_depth_20)
# 
# Frch_depth_20 <- Frch_depth_20 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# FRCHmeans2020ODO <- setDT(FRCHmeans2020ODO)
# 
# setDT(Frch_depth_20)
# setDT(FRCHmeans2020ODO)
# 
# FRCHmeans2020ODO$datetimeAK1 <- FRCHmeans2020ODO$datetimeAK
# 
# setkey( FRCHmeans2020ODO, datetimeAK )
# setkey( Frch_depth_20, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_frch20 <- FRCHmeans2020ODO[ Frch_depth_20, roll = "nearest" ]
# 
# rounded.dates_frch20 <- rounded.dates_frch20 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_frch20 <- rounded.dates_frch20 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_frch20 <- rounded.dates_frch20 %>%
#   select(meanDepth, datetimeAK)
# 
# Frch.2020.DO.Depth <- merge(FRCHmeans2020ODO, rounded.dates_frch20, by = "datetimeAK", all = TRUE)
# Frch.2020.DO.Depth$meanDepth1 <- Frch.2020.DO.Depth$meanDepth
# 
# frch20mod <- lm(meanDepth ~ datetimeAK, Frch.2020.DO.Depth)
# 
# summary(frch20mod)
# 
# Frch.2020.DO.Depth <- Frch.2020.DO.Depth %>% 
#   mutate(predictedDepth = predict(frch20mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 



#### 2021 ####
frch.exo.2021 <- exo.processed.2021 %>% filter(site.ID == "FRCH")


frch.exo.2021$datetimeAK <- lubridate::round_date(frch.exo.2021$datetimeAK, "15 minutes")
frch.exo.2021$datetimeAK <- force_tz(frch.exo.2021$datetimeAK, "America/Anchorage")

frch.exo.2021$Temp.C <- as.numeric(frch.exo.2021$Temp.C)
frch.exo.2021$ODO.Psat <- as.numeric(frch.exo.2021$ODO.Psat)
frch.exo.2021$ODO.mgL <- as.numeric(frch.exo.2021$ODO.mgL)
frch.exo.2021$ODO.Ploc <- as.numeric(frch.exo.2021$ODO.Ploc)



#mean bursts
FRCHmean2021odoMGL <- aggregate( ODO.mgL ~ datetimeAK, frch.exo.2021, mean)
FRCHmean2021odoPSAT <- aggregate( ODO.Psat ~ datetimeAK, frch.exo.2021, mean)
FRCHmean2021odoPLOC <- aggregate( ODO.Ploc ~ datetimeAK, frch.exo.2021, mean)
FRCHmean2021odoTEMPC <- aggregate( Temp.C ~ datetimeAK, frch.exo.2021, mean)

FRCHmeans2021ODO <- plyr::join(FRCHmean2021odoMGL, FRCHmean2021odoPSAT, by = "datetimeAK")
FRCHmeans2021ODO <- plyr::join(FRCHmeans2021ODO, FRCHmean2021odoPLOC, by = "datetimeAK")
FRCHmeans2021ODO <- plyr::join(FRCHmeans2021ODO, FRCHmean2021odoTEMPC, by = "datetimeAK")
# 
# ########## DEPTH ############ 
# 
# 
# # Frch:
# 
# #download flowmeter data
# WR_21.url <- "https://drive.google.com/drive/u/1/folders/1MrFabu9Mzuv3v4naPl2-iCFaMj_DjkZG"
# WR.21.1 <- drive_get(as_id(WR_21.url))
# frch.wr21_glist <- drive_ls(WR.21.1, pattern = "R_Flowmeter_Q_calulation_FRCH_for_R_JAA_2021.csv")
# walk(frch.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# frch_WR_21.Data <- read.csv("R_Flowmeter_Q_calulation_FRCH_for_R_JAA_2021.csv",
#                             skip = 0, header = TRUE, na.strings=c("","NA","blank"))
# 
# 
# frch_WR_21.Data <- frch_WR_21.Data %>%
#   dplyr::rename(Date = Ã¯..Date)
# 
# frch_WR_21.Data <- frch_WR_21.Data %>% tidyr::fill(Date, .direction = ("down"))
# 
# frch_WR_21.Data <- frch_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))
# 
# 
# frch_WR_21.Data$datetimeAK <- as.POSIXct(paste(frch_WR_21.Data$Date, frch_WR_21.Data$Time), format="%y%m%d %H:%M")
# 
# 
# frch_WR_21.Data <- frch_WR_21.Data %>%
#   select(Depth..cm., datetimeAK)
# 
# Frch_depth_21 <- ddply(na.omit(frch_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))
# 
# # frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_21)
# 
# 
# Frch_depth_21 <- setDT(Frch_depth_21)
# 
# Frch_depth_21 <- Frch_depth_21 %>%
#   dplyr::rename(datetimeAK = datetimeAK)
# 
# FRCHmeans2021ODO <- setDT(FRCHmeans2021ODO)
# 
# setDT(Frch_depth_21)
# setDT(FRCHmeans2021ODO)
# 
# FRCHmeans2021ODO$datetimeAK1 <- FRCHmeans2021ODO$datetimeAK
# 
# setkey( FRCHmeans2021ODO, datetimeAK )
# setkey( Frch_depth_21, datetimeAK )
# 
# #WR was taken when EXO out of water. round depth point to nearest in data record
# rounded.dates_frch21 <- FRCHmeans2021ODO[ Frch_depth_21, roll = "nearest" ]
# 
# rounded.dates_frch21 <- rounded.dates_frch21 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_frch21 <- rounded.dates_frch21 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_frch21 <- rounded.dates_frch21 %>%
#   select(meanDepth, datetimeAK)
# 
# Frch.2021.DO.Depth <- merge(FRCHmeans2021ODO, rounded.dates_frch21, by = "datetimeAK", all = TRUE)
# Frch.2021.DO.Depth$meanDepth1 <- Frch.2021.DO.Depth$meanDepth
# 
# frch21mod <- lm(meanDepth ~ datetimeAK, Frch.2021.DO.Depth)
# 
# summary(frch21mod)
# 
# Frch.2021.DO.Depth <- Frch.2021.DO.Depth %>% 
#   mutate(predictedDepth = predict(frch21mod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 
# 
# 
# 
#Put together
FRCH_EXO_cl.2019.renamed <- FRCH_EXO_cl.2019.renamed %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

frch.exo.2020 <- frch.exo.2020 %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)

# #outliers
# Frch.2020.DO.Depth.1 <- Frch.2020.DO.Depth %>% filter(datetimeAK < "2020-09-02 13:00:00")
# Frch.2020.DO.Depth.2 <- Frch.2020.DO.Depth %>% filter(datetimeAK >= "2020-09-02 13:30:00") %>% filter(datetimeAK < "2020-09-15 11:30:00")
# Frch.2020.DO.Depth.3 <- Frch.2020.DO.Depth %>% filter(datetimeAK >= "2020-09-15 12:45:00")
# 
# Frch.2020.DO.Depth <- rbind(Frch.2020.DO.Depth.1,Frch.2020.DO.Depth.2,Frch.2020.DO.Depth.3)


FRCHmeans2021ODO <- FRCHmeans2021ODO %>%
  select(datetimeAK, Temp.C, ODO.mgL, ODO.Psat, ODO.Ploc)


All.years.frch.MESSY <- rbind(FRCH_EXO_cl.2019.renamed, frch.exo.2020, FRCHmeans2021ODO)

All.years.frch.MESSY <- All.years.frch.MESSY %>%
  dplyr::rename(DO.obs = ODO.mgL)

All.years.frch.MESSY <- All.years.frch.MESSY %>%
  dplyr::rename(temp.water = Temp.C)

# All.years.frch.MESSY <- All.years.frch.MESSY %>%
#   dplyr::rename(depth = predictedDepth)
# 
# All.years.frch.MESSY$depth <- All.years.frch.MESSY$depth / 100

#keep in mind 2019 and 2020 is clean data and 2021 are not.
pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FrchODO.pdf")

testPlotFRCH <- ggplot(data = All.years.frch.MESSY,
                       mapping = aes(x = datetimeAK, y = as.numeric(ODO.Psat))) + geom_point() + labs(x = "Date", y = "Dissolved Oxygen (%Sat)")
testPlotFRCH
dev.off()









##################### DISCHARGE DATA ####################
#### Combine and stitch discharge ####

#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)
library(here)

#Discharge data cleaned and scripted by Jake in DoD Discharge Repo


####### 2019 #######

Q2019.url <- "https://drive.google.com/drive/u/1/folders/1ww0WENY9u_iHbx5RvVuOp1po9RvtzC7j"
q.2019.prt1 <- drive_get(as_id(Q2019.url))
q.2019.glist <- drive_ls(q.2019.prt1, pattern = "Q_2019.csv")
walk(q.2019.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
Q_2019 <- read.csv("Q_2019.csv",)

#### Breaking up into sites ####
POKE_Q_2019 <- Q_2019 %>% filter(Site == "POKE")
VAUL_Q_2019 <- Q_2019 %>% filter(Site == "VAUL")
STRT_Q_2019 <- Q_2019 %>% filter(Site == "STRT")
MOOS_Q_2019 <- Q_2019 %>% filter(Site == "MOOS")
FRCH_Q_2019 <- Q_2019 %>% filter(Site == "FRCH")


#change poke discharge becuase of gaps
# POKE_Q_2019 <- read.csv("C:/Users/jacob/OneDrive - University of Alaska/GitHub/DoD_Discharge/Predicted_Discharge/2019/POKE/POKE.Q.csv")

#Select needed columns 
POKE.2019.Q <- POKE_Q_2019 %>%
  select(DateTime, Q, Site)

VAUL.2019.Q <- VAUL_Q_2019 %>%
  select(DateTime, Q, Site)

STRT.2019.Q <- STRT_Q_2019 %>%
  select(DateTime, Q, Site)

MOOS.2019.Q <- MOOS_Q_2019 %>%
  select(DateTime, Q, Site)

FRCH.2019.Q <- FRCH_Q_2019 %>%
  select(DateTime, Q, Site)


####### 2020 #######

#### Breaking up into sites ####
### POKE ###

poke_q_2020.url <- "https://drive.google.com/drive/u/1/folders/18UaoUOnZYKXo0Ea7BAyV2Ow7w3ArfS89"
poke_q_2020.prt1 <- drive_get(as_id(poke_q_2020.url))
poke.2020.q.glist <- drive_ls(poke_q_2020.prt1, pattern = "POKE.Q.csv")
walk(poke.2020.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
POKE.2020.Q <- read.csv("POKE.Q.csv",)

### VAUL ###
vaul_q_2020.url <- "https://drive.google.com/drive/u/1/folders/1SCdGe_2MUpoeNcpFI4kZbUa3FK-T4El0"
vaul_q_2020.prt1 <- drive_get(as_id(vaul_q_2020.url))
vaul.2020.q.glist <- drive_ls(vaul_q_2020.prt1, pattern = "VAUL.Q.csv")
walk(vaul.2020.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
VAUL.2020.Q <- read.csv("VAUL.Q.csv",)


### STRT ###

strt_q_2020.url <- "https://drive.google.com/drive/u/1/folders/1A4-Rw0ZQ0kAxKb7WkBm2VnDFT8fa1RsJ"
strt_q_2020.prt1 <- drive_get(as_id(strt_q_2020.url))
strt.2020.q.glist <- drive_ls(strt_q_2020.prt1, pattern = "STRT.Q.csv")
walk(strt.2020.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
STRT.2020.Q <- read.csv("STRT.Q.csv",)

### MOOS ###

moos_q_2020.url <- "https://drive.google.com/drive/u/1/folders/1ArCib8d1B4cBAeit-GBZG2Em8-jTBBmi"
moos_q_2020.prt1 <- drive_get(as_id(moos_q_2020.url))
moos.2020.q.glist <- drive_ls(moos_q_2020.prt1, pattern = "MOOS.Q.csv")
walk(moos.2020.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
MOOS.2020.Q <- read.csv("MOOS.Q.csv",)


### FRCH ###

frch_q_2020.url <- "https://drive.google.com/drive/u/1/folders/1X5ejz_Ia7jwqAk6jT8Xb9a5EknSV8bF-"
frch_q_2020.prt1 <- drive_get(as_id(frch_q_2020.url))
frch.2020.q.glist <- drive_ls(frch_q_2020.prt1, pattern = "FRCH.Q.csv")
walk(frch.2020.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
FRCH.2020.Q <- read.csv("FRCH.Q.csv",)


####### 2021 #######

#### Breaking up into sites ####
### POKE ###

poke_q_2021.url <- "https://drive.google.com/drive/u/1/folders/1KIgfC8CCUW7bj1DcecOtZzf85OYP6lI7"
poke_q_2021.prt1 <- drive_get(as_id(poke_q_2021.url))
poke.2021.q.glist <- drive_ls(poke_q_2021.prt1, pattern = "POKE.Q.csv")
walk(poke.2021.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
POKE.2021.Q <- read.csv("POKE.Q.csv",)

### VAUL ###
vaul_q_2021.url <- "https://drive.google.com/drive/u/1/folders/1USPfRoW9Pc_7-CWd6PDTQ2sYHBSUkvjI"
vaul_q_2021.prt1 <- drive_get(as_id(vaul_q_2021.url))
vaul.2021.q.glist <- drive_ls(vaul_q_2021.prt1, pattern = "VAUL.Q.csv")
walk(vaul.2021.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
VAUL.2021.Q <- read.csv("VAUL.Q.csv",)


### STRT ###

strt_q_2021.url <- "https://drive.google.com/drive/u/1/folders/1CUb8n8lmhRt4-Z0iiuWB9rcd-TRBJ1mI"
strt_q_2021.prt1 <- drive_get(as_id(strt_q_2021.url))
strt.2021.q.glist <- drive_ls(strt_q_2021.prt1, pattern = "STRT.Q.csv")
walk(strt.2021.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
STRT.2021.Q <- read.csv("STRT.Q.csv",)

### MOOS ###

moos_q_2021.url <- "https://drive.google.com/drive/u/1/folders/1IJ_l63IM_L7-5o1gZ_TbY-a1t52OoZXn"
moos_q_2021.prt1 <- drive_get(as_id(moos_q_2021.url))
moos.2021.q.glist <- drive_ls(moos_q_2021.prt1, pattern = "MOOS.Q.csv")
walk(moos.2021.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
MOOS.2021.Q <- read.csv("MOOS.Q.csv",)


### FRCH ###

frch_q_2021.url <- "https://drive.google.com/drive/u/1/folders/1tB71qTZa8Eq1W4lnVsHl-NWSKtRr5eZ4"
frch_q_2021.prt1 <- drive_get(as_id(frch_q_2021.url))
frch.2021.q.glist <- drive_ls(frch_q_2021.prt1, pattern = "FRCH.Q.csv")
walk(frch.2021.q.glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
FRCH.2021.Q <- read.csv("FRCH.Q.csv",)




########## Combine ##########
getwd()

#Poke
POKE.ALL.Q <- rbind(POKE.2019.Q, POKE.2020.Q, POKE.2021.Q)
POKE.ALL.Q$DateTime <-  as.POSIXct(POKE.ALL.Q$DateTime)


write.csv(POKE.ALL.Q, here("Predicted_Discharge/Combined after 2019/POKE.ALL.Q.csv"), row.names = FALSE)

tiff("Q_Plots/PokeQ_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(POKE.ALL.Q$DateTime, POKE.ALL.Q$Q, main = "Poke Discharge", xlab = "Date", ylab = "Predicted Discahrge (m^3/s)")
dev.off()


#Vaul
VAUL.ALL.Q <- rbind(VAUL.2019.Q, VAUL.2020.Q, VAUL.2021.Q)
VAUL.ALL.Q$DateTime <-  as.POSIXct(VAUL.ALL.Q$DateTime)

write.csv(VAUL.ALL.Q,here("Predicted_Discharge/Combined after 2019/VAUL.ALL.Q.csv"), row.names = FALSE)

tiff("Q_Plots/VaulQ_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(VAUL.ALL.Q$DateTime, VAUL.ALL.Q$Q, main = "Vaul Discharge", xlab = "Date", ylab = "Predicted Discahrge (m^3/s)")
dev.off()


#Strt
STRT.ALL.Q <- rbind(STRT.2019.Q, STRT.2020.Q, STRT.2021.Q)
STRT.ALL.Q$DateTime <-  as.POSIXct(STRT.ALL.Q$DateTime)

write.csv(STRT.ALL.Q,here("Predicted_Discharge/Combined after 2019/STRT.ALL.Q.csv"), row.names = FALSE)

tiff("Q_Plots/StrtQ_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(STRT.ALL.Q$DateTime, STRT.ALL.Q$Q, main = "Strt Discharge", xlab = "Date", ylab = "Predicted Discahrge (m^3/s)")
dev.off()


#Moos
MOOS.ALL.Q <- rbind(MOOS.2019.Q, MOOS.2020.Q, MOOS.2021.Q)
MOOS.ALL.Q$DateTime <-  as.POSIXct(MOOS.ALL.Q$DateTime)

write.csv(MOOS.ALL.Q,here("Predicted_Discharge/Combined after 2019/MOOS.ALL.Q.csv"), row.names = FALSE)

tiff("Q_Plots/MoosQ_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(MOOS.ALL.Q$DateTime, MOOS.ALL.Q$Q, main = "Moos Discharge", xlab = "Date", ylab = "Predicted Discahrge (m^3/s)")
dev.off()


#Frch
FRCH.ALL.Q <- rbind(FRCH.2019.Q, FRCH.2020.Q, FRCH.2021.Q)
FRCH.ALL.Q$DateTime <-  as.POSIXct(FRCH.ALL.Q$DateTime)

write.csv(FRCH.ALL.Q,here("Predicted_Discharge/Combined after 2019/FRCH.ALL.Q.csv"), row.names = FALSE)

tiff("Q_Plots/FrchQ_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(FRCH.ALL.Q$DateTime, FRCH.ALL.Q$Q, main = "Frch Discharge", xlab = "Date", ylab = "Predicted Discahrge (m^3/s)")
dev.off()






##################### AIR PRESSURE #######################
### Jacob Adams
### Full DoD Air Pressure Record Script
### 7/20/2022

#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)

dev.off()
##### 2019 #####

#STRT 2019
strt.2019.air.P <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
strt_19.ap <- drive_get(as_id(strt.2019.air.P))
strt_19.ap_glist <- drive_ls(strt_19.ap, pattern = "191016_20005934_STRT_ATM_0.csv")
walk(strt_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.ap.2019.Data <- read.csv("191016_20005934_STRT_ATM_0.csv",
                              skip = 1, header = TRUE)
strt.ap.2019.Data$DateTime <- strptime(strt.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p")

strt.ap.2019.Data$air.pressure.mbar <- strt.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..20005934..SEN.S.N..20005934..LBL..P. * 10





#MOOS
moos.2019.air.P.url <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
moos_19.ap <- drive_get(as_id(moos.2019.air.P.url))
moos_19.ap_glist <- drive_ls(moos_19.ap, pattern = "191022_10710340_MOOS_ATM.csv")
walk(moos_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos.ap.2019.Data <- read.csv("191022_10710340_MOOS_ATM.csv",
                              skip = 1, header = TRUE)
moos.ap.2019.Data$DateTime <- as.POSIXct(strptime(moos.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

moos.ap.2019.Data$air.pressure.mbar <- moos.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..10710340..SEN.S.N..10710340..LBL..P. * 10


#POKE
poke.2019.air.P.url <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
poke_19.ap <- drive_get(as_id(poke.2019.air.P.url))
poke_19.ap_glist <- drive_ls(poke_19.ap, pattern = "191017_20005936_POKE_ATM.csv")
walk(poke_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.ap.2019.Data <- read.csv("191017_20005936_POKE_ATM.csv",
                              skip = 1, header = TRUE)
poke.ap.2019.Data$DateTime <- as.POSIXct(strptime(poke.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

poke.ap.2019.Data$DateTime <- lubridate::round_date(poke.ap.2019.Data$DateTime, "15 minutes") 


poke.ap.2019.Data$air.pressure.mbar <- poke.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..20005936..SEN.S.N..20005936..LBL..P. * 10



#FRCH
frch.2019.air.P.url <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
frch_19.ap <- drive_get(as_id(frch.2019.air.P.url))
frch_19.ap_glist <- drive_ls(frch_19.ap, pattern = "191010_10710335_FRCH_ATM.csv")
walk(frch_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch.ap.2019.Data <- read.csv("191010_10710335_FRCH_ATM.csv",
                              skip = 1, header = TRUE)
frch.ap.2019.Data$DateTime <- as.POSIXct(strptime(frch.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

frch.ap.2019.Data$DateTime <- lubridate::round_date(frch.ap.2019.Data$DateTime, "15 minutes")

frch.ap.2019.Data$air.pressure.mbar <- frch.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..10710335..SEN.S.N..10710335..LBL..P. * 10



#VAUL
vaul.2019.air.P.url <- "https://drive.google.com/drive/u/1/folders/12-av--A9_rqcyvwOl9EiB0MSZdmWnPcj"
vaul_19.ap <- drive_get(as_id(vaul.2019.air.P.url))
vaul_19.ap_glist <- drive_ls(vaul_19.ap, pattern = "191017_20574425_VAUL_ATM.csv")
walk(vaul_19.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul.ap.2019.Data <- read.csv("191017_20574425_VAUL_ATM.csv",
                              skip = 1, header = TRUE)
vaul.ap.2019.Data$DateTime <- as.POSIXct(strptime(vaul.ap.2019.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

vaul.ap.2019.Data$DateTime <- lubridate::round_date(vaul.ap.2019.Data$DateTime, "15 minutes")

vaul.ap.2019.Data$air.pressure.mbar <- vaul.ap.2019.Data$Abs.Pres..kPa..LGR.S.N..20574425..SEN.S.N..20574425. * 10


###### 2020 #####

#MOOS 2020
moos.2020.air.P <- "https://drive.google.com/drive/u/1/folders/10iEEQn5LhX3sxD2rcwozzAjuxmSuWKuh"
moos_20.ap <- drive_get(as_id(moos.2020.air.P))
moos_20.ap_glist <- drive_ls(moos_20.ap, pattern = "20574421_MOOS_atmo.csv")
walk(moos_20.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos.ap.2020.Data <- read.csv("20574421_MOOS_atmo.csv",
                              skip = 1, header = TRUE)
moos.ap.2020.Data$DateTime <- as.POSIXct(strptime(moos.ap.2020.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

moos.ap.2020.Data$air.pressure.mbar <- moos.ap.2020.Data$Abs.Pres..kPa..LGR.S.N..20574421..SEN.S.N..20574421. * 10

#STRT 2020
####### 2020 data looks BAD, dates all wrong and pressure does not line up with other sites. ######

# strt.2020.air.P <- "https://drive.google.com/drive/u/1/folders/1TWj16hvYu78dTk_aiSKyu2f0yl0KlibI"
# strt_20.ap <- drive_get(as_id(strt.2020.air.P))
# strt_20.ap_glist <- drive_ls(strt_20.ap, pattern = "20005934_STRT_ATMO.csv")
# walk(strt_20.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
# strt.ap.2020.Data <- read.csv("20005934_STRT_ATMO.csv",
#                               skip = 1, header = TRUE)
# strt.ap.2020.Data$DateTime <- as.POSIXct(strptime(strt.ap.2020.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))
# 
# #already in Mbar
# strt.ap.2020.Data$air.pressure.mbar <- strt.ap.2020.Data$Abs.Pres..mbar..LGR.S.N..20005934..SEN.S.N..20005934..LBL..P. * 1






#######


#STRT 2020
#bad atmo in 2021... Go off MOOS and adjust for elevation

#strt elevation: 250 meters, 820 feet
#Moos elevation: 175 meters, 574 feet

#calc pressure at sea level



#air pressure at sea level in mmHg
#formula from https://keisan.casio.com/exec/system/1224575267

moos.ap.2020.Data$mmHg.sea.level <- 10 * moos.ap.2020.Data$Abs.Pres..kPa..LGR.S.N..20574421..SEN.S.N..20574421.*((1-(0.0065*175)/(moos.ap.2020.Data$Temp..Ã.C..LGR.S.N..20574421..SEN.S.N..20574421. + (0.0065*175) +273.15))^(-5.257)) / 1.33322387415

#air pressure at moos elevation

moos.ap.2020.Data$strt.air.pressure.mbar <- (moos.ap.2020.Data$mmHg.sea.level -(2.5* 820/100))* 1.33322 









#FRCH 2020
frch.2020.air.P <- "https://drive.google.com/drive/u/1/folders/1-xZLou63OJTvw23xhWPO26x8VcZuv-xK"
frch_20.ap <- drive_get(as_id(frch.2020.air.P))
frch_20.ap_glist <- drive_ls(frch_20.ap, pattern = "20005933_FRCH_atmo.csv")
walk(frch_20.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch.ap.2020.Data <- read.csv("20005933_FRCH_atmo.csv",
                              skip = 1, header = TRUE)
frch.ap.2020.Data$DateTime <- as.POSIXct(strptime(frch.ap.2020.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

frch.ap.2020.Data$air.pressure.mbar <- frch.ap.2020.Data$Abs.Pres..kPa..LGR.S.N..20005933..SEN.S.N..20005933..LBL..P. * 10



#VAUL 2020
vaul.2020.air.P <- "https://drive.google.com/drive/u/1/folders/1nZzsTzSxZFCWF2GYsH6_HnRdi2iiLofK"
vaul_20.ap <- drive_get(as_id(vaul.2020.air.P))
vaul_20.ap_glist <- drive_ls(vaul_20.ap, pattern = "20574425_VAUL_atmo.csv")
walk(vaul_20.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul.ap.2020.Data <- read.csv("20574425_VAUL_atmo.csv",
                              skip = 1, header = TRUE)
vaul.ap.2020.Data$DateTime <- as.POSIXct(strptime(vaul.ap.2020.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

vaul.ap.2020.Data$air.pressure.mbar <- vaul.ap.2020.Data$Abs.Pres..kPa..LGR.S.N..20574425..SEN.S.N..20574425. * 10



#POKE 2020
poke.2020.air.P <- "https://drive.google.com/drive/u/1/folders/1CrINE0O9s7ILAUZkc9jguxHAvvTOD2NR"
poke_20.ap <- drive_get(as_id(poke.2020.air.P))
poke_20.ap_glist <- drive_ls(poke_20.ap, pattern = "20005936_POKE_atmo.csv")
walk(poke_20.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.ap.2020.Data <- read.csv("20005936_POKE_atmo.csv",
                              skip = 1, header = TRUE)
poke.ap.2020.Data$DateTime <- as.POSIXct(strptime(poke.ap.2020.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

poke.ap.2020.Data$air.pressure.mbar <- poke.ap.2020.Data$Abs.Pres..kPa..LGR.S.N..20005936..SEN.S.N..20005936..LBL..P. * 10


###### 2021 #####

#STRT 2021
strt.2021.air.P <- "https://drive.google.com/drive/u/1/folders/1-om0nU42U8fNmeWtBrhM8WQTbGqBW8RN"
strt_21.ap <- drive_get(as_id(strt.2021.air.P))
strt_21.ap_glist <- drive_ls(strt_21.ap, pattern = "20005934_STRT_ATMO_210930.csv")
walk(strt_21.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.ap.2021.Data <- read.csv("20005934_STRT_ATMO_210930.csv",
                              skip = 1, header = TRUE)
strt.ap.2021.Data$DateTime <- as.POSIXct(strptime(strt.ap.2021.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

#already in Mbar
strt.ap.2021.Data$air.pressure.mbar <- strt.ap.2021.Data$Abs.Pres..mbar..LGR.S.N..20005934..SEN.S.N..20005934..LBL..P. * 1


#MOOS 2021
#No atmo in 2021... Go off strt and adjust for elevation

#strt elevation: 250 meters
#Moos elevation: 175 meters, 574 feet

#calc pressure at sea level

#air pressure at sea level in mmHg

strt.ap.2021.Data$mmHg.sea.level <- strt.ap.2021.Data$Abs.Pres..mbar..LGR.S.N..20005934..SEN.S.N..20005934..LBL..P.*((1-(0.0065*250)/(strt.ap.2021.Data$Temp..Ã.C..LGR.S.N..20005934..SEN.S.N..20005934..LBL..T. + (0.0065*250) +273.15))^(-5.257)) / 1.33322387415

#air pressure at moos elevation

strt.ap.2021.Data$moos.air.pressure.mbar <- (strt.ap.2021.Data$mmHg.sea.level -(2.5* 574/100))* 1.33322



#FRCH 2021
#File online only has one point... might not exist
#Lets calculate from STRT as well

#air pressure at f erchlevation

strt.ap.2021.Data$frch.air.pressure.mbar <- (strt.ap.2021.Data$mmHg.sea.level -(2.5* 601/100)) * 1.33322



#VAUL 2021
vaul.2021.air.P <- "https://drive.google.com/drive/u/1/folders/1F80dynCpIo87e5EalwjNprze5UnLiomX"
vaul_21.ap <- drive_get(as_id(vaul.2021.air.P))
vaul_21.ap_glist <- drive_ls(vaul_21.ap, pattern = "20574425_VAUL_atmo.csv")
walk(vaul_21.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul.ap.2021.Data <- read.csv("20574425_VAUL_atmo.csv",
                              skip = 1, header = TRUE)
vaul.ap.2021.Data$DateTime <- as.POSIXct(strptime(vaul.ap.2021.Data$Date.Time..GMT.08.00, "%m/%d/%y %I:%M:%S %p"))

vaul.ap.2021.Data$air.pressure.mbar <- vaul.ap.2021.Data$Abs.Pres..kPa..LGR.S.N..20574425..SEN.S.N..20574425. * 10



#POKE 2021
#going off of caribou pressure 

poke.2021.air.P <- "https://drive.google.com/drive/u/1/folders/1rOGiMGGMYzOoDcNQoJATxHARqR8Y1F1m"
poke_21.ap <- drive_get(as_id(poke.2021.air.P))
poke_21.ap_glist <- drive_ls(poke_21.ap, pattern = "caribou.2021.atmo.csv")
walk(poke_21.ap_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.ap.2021.Data <- read.csv("caribou.2021.atmo.csv",
                              skip = 1, header = TRUE)
poke.ap.2021.Data$DateTime <- as.POSIXct(poke.ap.2021.Data$X2021.06.01.00.01.00)

poke.ap.2021.Data$air.pressure.mbar <- poke.ap.2021.Data$X99.90622* 10


#Stitch them together

# Poke:
poke.ap.2019.Data.2 <- na.omit(poke.ap.2019.Data) %>%
  select(DateTime, air.pressure.mbar)

poke.ap.2020.Data.2 <- na.omit(poke.ap.2020.Data) %>%
  select(DateTime, air.pressure.mbar)

poke.ap.2021.Data.2 <- na.omit(poke.ap.2021.Data) %>%
  select(DateTime, air.pressure.mbar)

poke.ap.2021.Data.2$DateTime <- lubridate::round_date(poke.ap.2021.Data.2$DateTime, "15 minutes")
poke.ap.2021.Data.2 <- aggregate( air.pressure.mbar ~ DateTime, poke.ap.2021.Data.2, mean)

poke.ap.data <- rbind(poke.ap.2019.Data.2,poke.ap.2020.Data.2, poke.ap.2021.Data.2)

poke.ap.data$air.pressure.mbar <- as.numeric(poke.ap.data$air.pressure.mbar)


# Vaul: 

vaul.ap.2019.Data.2 <- na.omit(vaul.ap.2019.Data) %>%
  select(DateTime, air.pressure.mbar)

vaul.ap.2020.Data.2 <- na.omit(vaul.ap.2020.Data) %>%
  select(DateTime, air.pressure.mbar)

vaul.ap.2021.Data.2 <- na.omit(vaul.ap.2021.Data) %>%
  select(DateTime, air.pressure.mbar)

vaul.ap.data <- rbind(vaul.ap.2019.Data.2, vaul.ap.2020.Data.2, vaul.ap.2021.Data.2)

vaul.ap.data$air.pressure.mbar <- as.numeric(vaul.ap.data$air.pressure.mbar)

plot(vaul.ap.data$DateTime, vaul.ap.data$air.pressure.mbar)


# Moos:

moos.ap.2019.Data.2 <- na.omit(moos.ap.2019.Data) %>%
  select(DateTime, air.pressure.mbar)

moos.ap.2020.Data.2 <- na.omit(moos.ap.2020.Data) %>%
  select(DateTime, air.pressure.mbar)

moos.ap.2021.Data.2 <- na.omit(strt.ap.2021.Data) %>%
  select(DateTime, moos.air.pressure.mbar) 

moos.ap.2021.Data.2 <- moos.ap.2021.Data.2 %>% dplyr::rename(air.pressure.mbar = moos.air.pressure.mbar)


moos.ap.data <- rbind(moos.ap.2019.Data.2,moos.ap.2020.Data.2, moos.ap.2021.Data.2)

moos.ap.data$air.pressure.mbar <- as.numeric(moos.ap.data$air.pressure.mbar)

plot(moos.ap.data$DateTime, moos.ap.data$air.pressure.mbar)


# Frch:

frch.ap.2019.Data.2 <- na.omit(frch.ap.2019.Data) %>%
  select(DateTime, air.pressure.mbar)

frch.ap.2020.Data.2 <- na.omit(frch.ap.2020.Data) %>%
  select(DateTime, air.pressure.mbar)

frch.ap.2021.Data.2 <- na.omit(strt.ap.2021.Data) %>%
  select(DateTime, frch.air.pressure.mbar) 

frch.ap.2021.Data.2 <- frch.ap.2021.Data.2 %>% dplyr::rename(air.pressure.mbar = frch.air.pressure.mbar)


frch.ap.data <- rbind(frch.ap.2019.Data.2,frch.ap.2020.Data.2, frch.ap.2021.Data.2)

frch.ap.data$air.pressure.mbar <- as.numeric(frch.ap.data$air.pressure.mbar)

plot(frch.ap.data$DateTime, frch.ap.data$air.pressure.mbar)



# Strt:
# 2020 data looks BAD, dates all wrong and pressure does not line up with other sites. use pressure convereted from MOOS

strt.ap.2019.Data.2 <- na.omit(strt.ap.2019.Data) %>%
  select(DateTime, air.pressure.mbar)


strt.ap.2020.Data.2 <- na.omit(moos.ap.2020.Data) %>%
  select(DateTime, strt.air.pressure.mbar)

strt.ap.2021.Data.2 <- na.omit(strt.ap.2021.Data) %>%
  select(DateTime, air.pressure.mbar) 

strt.ap.2020.Data.2 <- strt.ap.2020.Data.2 %>% dplyr::rename(air.pressure.mbar = strt.air.pressure.mbar)



strt.ap.data <- rbind(strt.ap.2019.Data.2,strt.ap.2020.Data.2, strt.ap.2021.Data.2)

strt.ap.data$datetimeAK <- as.POSIXct(strt.ap.data$DateTime)

strt.ap.data$air.pressure.mbar <- as.numeric(strt.ap.data$air.pressure.mbar)

plot(strt.ap.data$DateTime, strt.ap.data$air.pressure.mbar)



#################### LIGHT ###############################

##### Stitch Light Data #####
#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)


#### POKE 2019 ####
PAR.2019.url <- "https://drive.google.com/drive/u/1/folders/11kWuwCF6pTXYolwYnxcsX6OcYyQeF35z"
PAR_19.prt1 <- drive_get(as_id(PAR.2019.url))
poke_par_glist <- drive_ls(PAR_19.prt1, pattern = "191017_11619_POKE.CSV")
walk(poke_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.par.2019.Data <- read.csv("191017_11619_POKE.CSV",
                               skip = 8, header = FALSE)
poke.par.2019.Data <- poke.par.2019.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
poke.par.2019.Data$DateTime <- paste(poke.par.2019.Data$Date, poke.par.2019.Data$Time, sep="")

poke.par.2019.Data$DateTime <-  dmy_hms(poke.par.2019.Data$DateTime)
poke.par.2019.Data$DateTime <- force_tz(poke.par.2019.Data$DateTime, "America/Anchorage")

#Calibrate logger 11619 to LICOR
poke.par.2019.Data$CalibratedValue <- poke.par.2019.Data$CalibratedValue * 0.035


#### VAUL 2019 ####
PAR.2019.url <- "https://drive.google.com/drive/u/1/folders/11kWuwCF6pTXYolwYnxcsX6OcYyQeF35z"
PAR_19.prt1 <- drive_get(as_id(PAR.2019.url))
vaul_par_glist <- drive_ls(PAR_19.prt1, pattern = "191017_11616_VAUL.CSV")
walk(vaul_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul.par.2019.Data <- read.csv("191017_11616_VAUL.CSV",
                               skip = 8, header = FALSE)
vaul.par.2019.Data <- vaul.par.2019.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
vaul.par.2019.Data$DateTime <- paste(vaul.par.2019.Data$Date, vaul.par.2019.Data$Time, sep="")

vaul.par.2019.Data$DateTime <-  dmy_hms(vaul.par.2019.Data$DateTime)
vaul.par.2019.Data$DateTime <- force_tz(vaul.par.2019.Data$DateTime, "America/Anchorage")

#Calibrate logger 11616 to LICOR
vaul.par.2019.Data$CalibratedValue <- vaul.par.2019.Data$CalibratedValue * 0.032



#### MOOS 2019 ####
PAR.2019.url <- "https://drive.google.com/drive/u/1/folders/11kWuwCF6pTXYolwYnxcsX6OcYyQeF35z"
PAR_19.prt1 <- drive_get(as_id(PAR.2019.url))
moos_par_glist <- drive_ls(PAR_19.prt1, pattern = "191022_11617_MOOS.CSV")
walk(moos_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos.par.2019.Data <- read.csv("191022_11617_MOOS.CSV",
                               skip = 8, header = FALSE)
moos.par.2019.Data <- moos.par.2019.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
moos.par.2019.Data$DateTime <- paste(moos.par.2019.Data$Date, moos.par.2019.Data$Time, sep="")

moos.par.2019.Data$DateTime <-  dmy_hms(moos.par.2019.Data$DateTime)
moos.par.2019.Data$DateTime <- force_tz(moos.par.2019.Data$DateTime, "America/Anchorage")

#Calibrate logger 11617 to LICOR
moos.par.2019.Data$CalibratedValue <- moos.par.2019.Data$CalibratedValue * 0.037 



#### STRT 2019 ####
PAR.2019.url <- "https://drive.google.com/drive/u/1/folders/11kWuwCF6pTXYolwYnxcsX6OcYyQeF35z"
PAR_19.prt1 <- drive_get(as_id(PAR.2019.url))
strt_par_glist <- drive_ls(PAR_19.prt1, pattern = "191016_11620_PAR_STRT.CSV")
walk(strt_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.par.2019.Data <- read.csv("191016_11620_PAR_STRT.CSV",
                               skip = 8, header = FALSE)
strt.par.2019.Data <- strt.par.2019.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
strt.par.2019.Data$DateTime <- paste(strt.par.2019.Data$Date, strt.par.2019.Data$Time, sep="")

strt.par.2019.Data$DateTime <-  dmy_hms(strt.par.2019.Data$DateTime)
strt.par.2019.Data$DateTime <- force_tz(strt.par.2019.Data$DateTime, "America/Anchorage")

#Calibrate logger 11620 to LICOR
strt.par.2019.Data$CalibratedValue <- strt.par.2019.Data$CalibratedValue * 0.036


#early data
strt_par_glist2 <- drive_ls(PAR_19.prt1, pattern = "190829_11620_PAR_STRT.CSV")
walk(strt_par_glist2$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.par.2019.Data2 <- read.csv("190829_11620_PAR_STRT.CSV",
                                skip = 8, header = FALSE)
strt.par.2019.Data2 <- strt.par.2019.Data2 %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
strt.par.2019.Data2$DateTime <- paste(strt.par.2019.Data2$Date, strt.par.2019.Data2$Time, sep="")

strt.par.2019.Data2$DateTime <-  dmy_hms(strt.par.2019.Data2$DateTime)
strt.par.2019.Data2$DateTime <- force_tz(strt.par.2019.Data2$DateTime, "America/Anchorage")

#Calibrate logger 11620 to LICOR
strt.par.2019.Data2$CalibratedValue <- strt.par.2019.Data2$CalibratedValue * 0.036



#other data / EXTRA
strt_par_glist3 <- drive_ls(PAR_19.prt1, pattern = "190829_11618_PAR_STRT_EXTRA.CSV")
walk(strt_par_glist3$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.par.2019.Data3 <- read.csv("190829_11618_PAR_STRT_EXTRA.CSV",
                                skip = 8, header = FALSE)
strt.par.2019.Data3 <- strt.par.2019.Data3 %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
strt.par.2019.Data3$DateTime <- paste(strt.par.2019.Data3$Date, strt.par.2019.Data3$Time, sep="")

strt.par.2019.Data3$DateTime <-  dmy_hms(strt.par.2019.Data3$DateTime)
strt.par.2019.Data3$DateTime <- force_tz(strt.par.2019.Data3$DateTime, "America/Anchorage")

#Calibrate logger 11620 to LICOR
strt.par.2019.Data3$CalibratedValue <- strt.par.2019.Data3$CalibratedValue * 0.032


strt.par.2019.Data2 <- strt.par.2019.Data2 %>% filter(DateTime < "2019-08-01 00:00:00")

strt.par.2019.Data3 <- strt.par.2019.Data3 %>% filter(DateTime >= "2019-08-01 00:00:00" & DateTime <= "2019-09-01 00:00:00")



strt.par.2019.Data <- rbind(strt.par.2019.Data2, strt.par.2019.Data3, strt.par.2019.Data)



#### FRCH 2019 ####
PAR.2019.url <- "https://drive.google.com/drive/u/1/folders/11kWuwCF6pTXYolwYnxcsX6OcYyQeF35z"
PAR_19.prt1 <- drive_get(as_id(PAR.2019.url))
frch_par_glist <- drive_ls(PAR_19.prt1, pattern = "191010_11615_FRCH.CSV")
walk(frch_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch.par.2019.Data <- read.csv("191010_11615_FRCH.CSV",
                               skip = 8, header = FALSE)
frch.par.2019.Data <- frch.par.2019.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
frch.par.2019.Data$DateTime <- paste(frch.par.2019.Data$Date, frch.par.2019.Data$Time, sep="")

frch.par.2019.Data$DateTime <-  dmy_hms(frch.par.2019.Data$DateTime)
frch.par.2019.Data$DateTime <- force_tz(frch.par.2019.Data$DateTime, "America/Anchorage")

#Calibrate logger 11615 to LICOR
frch.par.2019.Data$CalibratedValue <- frch.par.2019.Data$CalibratedValue * 0.031







##### 2020 #####

#### POKE 2020 ####
PAR.2020.url <- "https://drive.google.com/drive/u/1/folders/1udve7khOM2EX0l8BZQK3yehb2HUbwFtR"
PAR_2020.prt1 <- drive_get(as_id(PAR.2020.url))
poke_par_glist <- drive_ls(PAR_2020.prt1, pattern = "11619_002_002_POKE_EndOfSeason.CSV")
walk(poke_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke.par.2020.Data <- read.csv("11619_002_002_POKE_EndOfSeason.CSV",
                               skip = 9, header = FALSE)
poke.par.2020.Data <- poke.par.2020.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
poke.par.2020.Data$DateTime <- paste(poke.par.2020.Data$Date, poke.par.2020.Data$Time, sep="")

poke.par.2020.Data$DateTime <-  dmy_hms(poke.par.2020.Data$DateTime)
poke.par.2020.Data$DateTime <- force_tz(poke.par.2020.Data$DateTime, "America/Anchorage")

#Calibrate logger 11619 to LICOR
poke.par.2020.Data$CalibratedValue <- poke.par.2020.Data$CalibratedValue * 0.035


#### VAUL 2020 ####
PAR.2020.url <- "https://drive.google.com/drive/u/1/folders/1udve7khOM2EX0l8BZQK3yehb2HUbwFtR"
PAR_2020.prt1 <- drive_get(as_id(PAR.2020.url))
vaul_par_glist <- drive_ls(PAR_2020.prt1, pattern = "11616_005_002_VAUL_EndOfSeason.CSV")
walk(vaul_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul.par.2020.Data <- read.csv("11616_005_002_VAUL_EndOfSeason.CSV",
                               skip = 9, header = FALSE)
vaul.par.2020.Data <- vaul.par.2020.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
vaul.par.2020.Data$DateTime <- paste(vaul.par.2020.Data$Date, vaul.par.2020.Data$Time, sep="")

vaul.par.2020.Data$DateTime <-  dmy_hms(vaul.par.2020.Data$DateTime)
vaul.par.2020.Data$DateTime <- force_tz(vaul.par.2020.Data$DateTime, "America/Anchorage")

#Calibrate logger 11616 to LICOR
vaul.par.2020.Data$CalibratedValue <- vaul.par.2020.Data$CalibratedValue * 0.032



#### MOOS 2020 ####
PAR.2020.url <- "https://drive.google.com/drive/u/1/folders/1udve7khOM2EX0l8BZQK3yehb2HUbwFtR"
PAR_2020.prt1 <- drive_get(as_id(PAR.2020.url))
moos_par_glist <- drive_ls(PAR_2020.prt1, pattern = "11617_004_002_MOOS_EndOfSeason.CSV")
walk(moos_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos.par.2020.Data <- read.csv("11617_004_002_MOOS_EndOfSeason.CSV",
                               skip = 9, header = FALSE)
moos.par.2020.Data <- moos.par.2020.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
moos.par.2020.Data$DateTime <- paste(moos.par.2020.Data$Date, moos.par.2020.Data$Time, sep="")

moos.par.2020.Data$DateTime <-  dmy_hms(moos.par.2020.Data$DateTime)
moos.par.2020.Data$DateTime <- force_tz(moos.par.2020.Data$DateTime, "America/Anchorage")

#Calibrate logger 11617 to LICOR
moos.par.2020.Data$CalibratedValue <- moos.par.2020.Data$CalibratedValue * 0.037 



#### STRT 2020 ####
PAR.2020.url <- "https://drive.google.com/drive/u/1/folders/1udve7khOM2EX0l8BZQK3yehb2HUbwFtR"
PAR_2020.prt1 <- drive_get(as_id(PAR.2020.url))
strt_par_glist <- drive_ls(PAR_2020.prt1, pattern = "11620_001_002_STRT_EndOfSeason.CSV")
walk(strt_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt.par.2020.Data <- read.csv("11620_001_002_STRT_EndOfSeason.CSV",
                               skip = 9, header = FALSE)
strt.par.2020.Data <- strt.par.2020.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
strt.par.2020.Data$DateTime <- paste(strt.par.2020.Data$Date, strt.par.2020.Data$Time, sep="")

strt.par.2020.Data$DateTime <-  dmy_hms(strt.par.2020.Data$DateTime)
strt.par.2020.Data$DateTime <- force_tz(strt.par.2020.Data$DateTime, "America/Anchorage")

#Calibrate logger 11620 to LICOR
strt.par.2020.Data$CalibratedValue <- strt.par.2020.Data$CalibratedValue * 0.036



#### FRCH 2020 ####
PAR.2020.url <- "https://drive.google.com/drive/u/1/folders/1udve7khOM2EX0l8BZQK3yehb2HUbwFtR"
PAR_2020.prt1 <- drive_get(as_id(PAR.2020.url))
frch_par_glist <- drive_ls(PAR_2020.prt1, pattern = "11615_003_002_FRCH_2_EndOfSeason.CSV")
walk(frch_par_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch.par.2020.Data <- read.csv("11615_003_002_FRCH_2_EndOfSeason.CSV",
                               skip = 9, header = FALSE)
frch.par.2020.Data <- frch.par.2020.Data %>%
  dplyr::rename(ScanNumber = V1, Date = V2, Time = V3, RawValue = V4, CalibratedValue = V5)

#Fix Date Time
frch.par.2020.Data$DateTime <- paste(frch.par.2020.Data$Date, frch.par.2020.Data$Time, sep="")

frch.par.2020.Data$DateTime <-  dmy_hms(frch.par.2020.Data$DateTime)
frch.par.2020.Data$DateTime <- force_tz(frch.par.2020.Data$DateTime, "America/Anchorage")

#Calibrate logger 11615 to LICOR
frch.par.2020.Data$CalibratedValue <- frch.par.2020.Data$CalibratedValue * 0.031




###### 2021 #####
PAR.2021.url <- "https://drive.google.com/drive/u/1/folders/1EPjHLDmfbCo5n12AKj7QpN2vXRCPQtg5"
PAR_2021.prt1 <- drive_get(as_id(PAR.2021.url))
par2021_glist <- drive_ls(PAR_2021.prt1, pattern = "all.dates.par.2021.csv")
walk(par2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
par2021.Data <- read.csv("all.dates.par.2021.csv",
                         skip = 0, header = TRUE)


# Sort into sites
poke.par2021.Data <- par2021.Data %>% filter(site == "poke")
vaul.par2021.Data <- par2021.Data %>% filter(site == "vaul")
strt.par2021.Data <- par2021.Data %>% filter(site == "strt")
moos.par2021.Data <- par2021.Data %>% filter(site == "moos")
frch.par2021.Data <- par2021.Data %>% filter(site == "frch")

poke.par2021.Data <- poke.par2021.Data %>%
  dplyr::rename(RawValue = V5)
vaul.par2021.Data <- vaul.par2021.Data %>%
  dplyr::rename(RawValue = V5)
strt.par2021.Data <- strt.par2021.Data %>%
  dplyr::rename(RawValue = V5)
moos.par2021.Data <- moos.par2021.Data %>%
  dplyr::rename(RawValue = V5)
frch.par2021.Data <- frch.par2021.Data %>%
  dplyr::rename(RawValue = V5)

poke.par2021.Data$DateTime <- as.POSIXct(poke.par2021.Data$DateTime)
vaul.par2021.Data$DateTime <- as.POSIXct(vaul.par2021.Data$DateTime)
strt.par2021.Data$DateTime <- as.POSIXct(strt.par2021.Data$DateTime)
moos.par2021.Data$DateTime <- as.POSIXct(moos.par2021.Data$DateTime)
frch.par2021.Data$DateTime <- as.POSIXct(frch.par2021.Data$DateTime)

#Calibrate loggers to LICOR
poke.par2021.Data$Calibrated.Value <- poke.par2021.Data$Calibrated.Value * 0.035

vaul.par2021.Data$Calibrated.Value <- vaul.par2021.Data$Calibrated.Value * 0.032

strt.par2021.Data$Calibrated.Value <- strt.par2021.Data$Calibrated.Value * 0.036

moos.par2021.Data$Calibrated.Value <- moos.par2021.Data$Calibrated.Value * 0.037 

frch.par2021.Data$Calibrated.Value <- frch.par2021.Data$Calibrated.Value * 0.031




#### Combine all years ####

#POKE
poke.par2021.Data <- poke.par2021.Data %>%
  select(Calibrated.Value, DateTime)

poke.par.2020.Data <- poke.par.2020.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

poke.par.2019.Data <- poke.par.2019.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

poke.combinded.par <- rbind(poke.par.2019.Data, poke.par.2020.Data, poke.par2021.Data)

write.csv(poke.combinded.par,here("outputs/poke.combinded.par.csv"), row.names = FALSE)


tiff("Plots/Poke_PAR_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(poke.combinded.par$DateTime, poke.combinded.par$Calibrated.Value, main = "Poke PAR", ylab = "PAR (Âµmol of photons m-2 s-1)", xlab = "date")
dev.off()

#VAUL
vaul.par2021.Data <- vaul.par2021.Data %>%
  select(Calibrated.Value, DateTime)

vaul.par.2020.Data <- vaul.par.2020.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

vaul.par.2019.Data <- vaul.par.2019.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

vaul.combinded.par <- rbind(vaul.par.2019.Data, vaul.par.2020.Data, vaul.par2021.Data)

write.csv(vaul.combinded.par,here("outputs/vaul.combinded.par.csv"), row.names = FALSE)

tiff("Plots/Vaul_PAR_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(vaul.combinded.par$DateTime, vaul.combinded.par$Calibrated.Value, main = "Vaul PAR", ylab = "PAR (Âµmol of photons m-2 s-1)", xlab = "date")
dev.off()

#STRT
strt.par2021.Data <- strt.par2021.Data %>%
  select(Calibrated.Value, DateTime)

strt.par.2020.Data <- strt.par.2020.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

strt.par.2019.Data <- strt.par.2019.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

strt.combinded.par <- rbind(strt.par.2019.Data, strt.par.2020.Data, strt.par2021.Data)

write.csv(strt.combinded.par,here("outputs/strt.combinded.par.csv"), row.names = FALSE)


tiff("Plots/Strt_PAR_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(strt.combinded.par$DateTime, strt.combinded.par$Calibrated.Value, main = "Strt PAR", ylab = "PAR (Âµmol of photons m-2 s-1)", xlab = "date")
dev.off()



#MOOS
moos.par2021.Data <- moos.par2021.Data %>%
  select(Calibrated.Value, DateTime)

moos.par.2020.Data <- moos.par.2020.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

moos.par.2019.Data <- moos.par.2019.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

moos.combinded.par <- rbind(moos.par.2019.Data, moos.par.2020.Data, moos.par2021.Data)

write.csv(moos.combinded.par,here("outputs/moos.combinded.par.csv"), row.names = FALSE)


tiff("Plots/Moos_PAR_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(moos.combinded.par$DateTime, moos.combinded.par$Calibrated.Value, main = "Moos PAR", ylab = "PAR (Âµmol of photons m-2 s-1)", xlab = "date")
dev.off()


#FRCH
frch.par2021.Data <- frch.par2021.Data %>%
  select(Calibrated.Value, DateTime)

frch.par.2020.Data <- frch.par.2020.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

frch.par.2019.Data <- frch.par.2019.Data %>%
  select(CalibratedValue, DateTime) %>% dplyr::rename(Calibrated.Value = CalibratedValue)

frch.combinded.par <- rbind(frch.par.2019.Data, frch.par.2020.Data, frch.par2021.Data)

write.csv(frch.combinded.par,here("outputs/frch.combinded.par.csv"), row.names = FALSE)


tiff("Plots/Frch_PAR_all_years.tiff", compression = "lzw", width = 1500, height =1000)
plot(frch.combinded.par$DateTime, frch.combinded.par$Calibrated.Value, main = "Frch PAR", ylab = "PAR (Âµmol of photons m-2 s-1)", xlab = "date")
dev.off()


############################# DEPTH #################################

##### Stitch Depth #####
#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(data.table)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)

#### 2019 ####

#All PT data...
PT.2019.url <- "https://drive.google.com/drive/u/1/folders/1VdtpYHtfxSqp2DRyWTCu4NorvQ5bx_i4"
pt.19.1 <- drive_get(as_id(PT.2019.url))
pt.19_glist <- drive_ls(pt.19.1, pattern = "all.pt.2019.csv")
walk(pt.19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
pt.2019.Data <- read.csv("all.pt.2019.csv",
                         skip = 0, header = TRUE)


#separate out into individual sites to create a mean PT depth 

frch.data1 <- pt.2019.Data %>% filter(Site == "FRCH1")
frch.data2 <- pt.2019.Data %>% filter(Site == "FRCH2")
frch.2019.pt <- inner_join(frch.data1, frch.data2, by = "DateTime")
frch.2019.pt$DateTime <- as.POSIXct(paste(frch.2019.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")

frch.2019.pt$AvgAbsDepth <- (frch.2019.pt$AbsPTDepth.x + frch.2019.pt$AbsPTDepth.y)/2


frch.2019.pt <- mutate(frch.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.y, AvgAbsDepth))

frch.2019.pt <- mutate(frch.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.x, AvgAbsDepth))



poke.data1 <- pt.2019.Data %>% filter(Site == "POKE1")
poke.data2 <- pt.2019.Data %>% filter(Site == "POKE2")
poke.2019.pt <- inner_join(poke.data1, poke.data2, by = "DateTime")
poke.2019.pt$DateTime <- as.POSIXct(paste(poke.2019.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.2019.pt$AvgAbsDepth <- (poke.2019.pt$AbsPTDepth.x + poke.2019.pt$AbsPTDepth.y)/2


poke.2019.pt <- mutate(poke.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.y, AvgAbsDepth))

poke.2019.pt <- mutate(poke.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.x, AvgAbsDepth))

#remove beaver dam points as per jake did in his discharge REPO


strt.data1 <- pt.2019.Data %>% filter(Site == "STRT1")
strt.data2 <- pt.2019.Data %>% filter(Site == "STRT2")
strt.data2$DateTime <- as.POSIXct(paste(strt.data2$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.data2$DateTime <- as.character(strt.data2$DateTime)
strt.2019.pt <- merge(strt.data2, strt.data1, by = "DateTime", all = TRUE)
strt.data2$DateTime <- as.POSIXct(strt.data2$DateTime)
strt.2019.pt$AvgAbsDepth <- (strt.2019.pt$AbsPTDepth.x + strt.2019.pt$AbsPTDepth.y)/2


strt.2019.pt <- mutate(strt.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.y, AvgAbsDepth))

strt.2019.pt <- mutate(strt.2019.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, AbsPTDepth.x, AvgAbsDepth))

#MOOS and VAUL do not have a second PT in 2019
moos.data1 <- pt.2019.Data %>% filter(Site == "MOOS1")
moos.data1$DateTime <- as.POSIXct(paste(moos.data1$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.2019.pt <- moos.data1



vaul.data1 <- pt.2019.Data %>% filter(Site == "VAUL1")
vaul.data1$DateTime <- as.POSIXct(paste(vaul.data1$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
vaul.2019.pt <- vaul.data1




##### 2020 #####


PT.2020.url <- "https://drive.google.com/drive/u/1/folders/1xYaOxYwRJQmYt0qOzahZMmTZRKW3lTVX"
pt.2020.1 <- drive_get(as_id(PT.2020.url))
pt.2020_glist <- drive_ls(pt.2020.1, pattern = "all.pt.raw.csv")
walk(pt.2020_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
pt.2020.Data <- read.csv("all.pt.raw.csv",
                         skip = 0, header = TRUE)

pt.2020.Data <- pt.2020.Data %>% filter(Year == "2020")



#separate out into individual sites to create a mean PT depth 

frch.data1.2020 <- pt.2020.Data %>% filter(Site == "FRCH1")
frch.data2.2020 <- pt.2020.Data %>% filter(Site == "FRCH2")
frch.2020.pt <- inner_join(frch.data1.2020, frch.data2.2020, by = "DateTime")
frch.2020.pt$DateTime <- as.POSIXct(paste(frch.2020.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")

frch.2020.pt$AvgAbsDepth <- (frch.2020.pt$WaterLevel.x + frch.2020.pt$WaterLevel.y)/2


frch.2020.pt <- mutate(frch.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

frch.2020.pt <- mutate(frch.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))



poke.data1.2020 <- pt.2020.Data %>% filter(Site == "POKE1")
poke.data2.2020 <- pt.2020.Data %>% filter(Site == "POKE2")
poke.2020.pt <- inner_join(poke.data1.2020, poke.data2.2020, by = "DateTime")
poke.2020.pt$DateTime <- as.POSIXct(paste(poke.2020.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.2020.pt$AvgAbsDepth <- (poke.2020.pt$WaterLevel.x + poke.2020.pt$WaterLevel.y)/2


poke.2020.pt <- mutate(poke.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

poke.2020.pt <- mutate(poke.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))



strt.data1.2020 <- pt.2020.Data %>% filter(Site == "STRT1")
strt.data2.2020 <- pt.2020.Data %>% filter(Site == "STRT2")
strt.2020.pt <- inner_join(strt.data1.2020, strt.data2.2020, by = "DateTime")
strt.2020.pt$DateTime <- as.POSIXct(paste(strt.2020.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.2020.pt$AvgAbsDepth <- (strt.2020.pt$WaterLevel.x + strt.2020.pt$WaterLevel.y)/2


strt.2020.pt <- mutate(strt.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

strt.2020.pt <- mutate(strt.2020.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))





moos.data1.2020 <- pt.2020.Data %>% filter(Site == "MOOS1")
moos.data1$DateTime <- as.POSIXct(paste(moos.data1$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.2020.pt <- moos.data1.2020



vaul.data1.2020 <- pt.2020.Data %>% filter(Site == "VAUL1")
vaul.data1.2020$DateTime <- as.POSIXct(vaul.data1.2020$DateTime)
vaul.2020.pt <- vaul.data1.2020

vaul.2020.pt$AvgAbsDepth <- vaul.2020.pt$WaterLevel


###### 2021 #####

#VAUL 
VAUL_PT_2021.url <- "https://drive.google.com/drive/u/1/folders/1F80dynCpIo87e5EalwjNprze5UnLiomX"
vaul_pt.2021.1 <- drive_get(as_id(VAUL_PT_2021.url))
vaul.pt2021_glist <- drive_ls(vaul_pt.2021.1, pattern = "vaul.pt.2021.csv")
walk(vaul.pt2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul_PT_2021.Data <- read.csv("vaul.pt.2021.csv",
                              skip = 0, header = TRUE)


vaul.2021.pt <- vaul_PT_2021.Data
# 
# vaul.data1.2021 <- vaul_PT_2021.Data %>% filter(Site == "VAUL1")
# vaul.data2.2021 <- vaul_PT_2021.Data %>% filter(Site == "VAUL2")
# vaul.2021.pt <- inner_join(vaul.data1.2021, vaul.data2.2021, by = "DateTime")
# vaul.2021.pt$DateTime <- as.POSIXct(paste(vaul.2021.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
# vaul.2021.pt$AvgAbsDepth <- (vaul.2021.pt$WaterLevel.x + vaul.2021.pt$WaterLevel.y)/2
# 
# 
# vaul.2021.pt <- mutate(vaul.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))
# 
# vaul.2021.pt <- mutate(vaul.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))




#POKE

POKE_PT_2021.url <- "https://drive.google.com/drive/u/1/folders/1rOGiMGGMYzOoDcNQoJATxHARqR8Y1F1m"
poke_pt.2021.1 <- drive_get(as_id(POKE_PT_2021.url))
poke.pt2021_glist <- drive_ls(poke_pt.2021.1, pattern = "poke.pt.2021.csv")
walk(poke.pt2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke_PT_2021.Data <- read.csv("poke.pt.2021.csv",
                              skip = 0, header = TRUE)

poke.data1.2021 <- poke_PT_2021.Data %>% filter(Site == "POKE1")
poke.data2.2021 <- poke_PT_2021.Data %>% filter(Site == "POKE2")
poke.2021.pt <- inner_join(poke.data1.2021, poke.data2.2021, by = "DateTime")
poke.2021.pt$DateTime <- as.POSIXct(paste(poke.2021.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.2021.pt$AvgAbsDepth <- (poke.2021.pt$WaterLevel.x + poke.2021.pt$WaterLevel.y)/2


poke.2021.pt <- mutate(poke.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

poke.2021.pt <- mutate(poke.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))



#FRCH

FRCH_PT_2021.url <- "https://drive.google.com/drive/u/1/folders/1pCn5m6WKsJv3ZzuWDvBr6iAp05bsGOWC"
frch_pt.2021.1 <- drive_get(as_id(FRCH_PT_2021.url))
frch.pt2021_glist <- drive_ls(frch_pt.2021.1, pattern = "frch.pt.2021.csv")
walk(frch.pt2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch_PT_2021.Data <- read.csv("frch.pt.2021.csv",
                              skip = 0, header = TRUE)

frch.data1.2021 <- frch_PT_2021.Data %>% filter(Site == "FRCH1")
frch.data2.2021 <- frch_PT_2021.Data %>% filter(Site == "FRCH2")
frch.2021.pt <- inner_join(frch.data1.2021, frch.data2.2021, by = "DateTime")
frch.2021.pt$DateTime <- as.POSIXct(paste(frch.2021.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")

frch.2021.pt$AvgAbsDepth <- (frch.2021.pt$WaterLevel.x + frch.2021.pt$WaterLevel.y)/2


frch.2021.pt <- mutate(frch.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

frch.2021.pt <- mutate(frch.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))




#MOOS

MOOS_PT_2021.url <- "https://drive.google.com/drive/u/1/folders/1Q14HB4khayh09dbTfFWGqHrkKaG1wXyN"
moos_pt.2021.1 <- drive_get(as_id(MOOS_PT_2021.url))
moos.pt2021_glist <- drive_ls(moos_pt.2021.1, pattern = "moos.pt.2021.csv")
walk(moos.pt2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos_PT_2021.Data <- read.csv("moos.pt.2021.csv",
                              skip = 0, header = TRUE)

moos.data1.2021 <- moos_PT_2021.Data %>% filter(Site == "MOOS1")
moos.data2.2021 <- moos_PT_2021.Data %>% filter(Site == "MOOS2")
moos.2021.pt <- inner_join(moos.data1.2021, moos.data2.2021, by = "DateTime")
moos.2021.pt$DateTime <- as.POSIXct(paste(moos.2021.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.2021.pt$AvgAbsDepth <- (moos.2021.pt$WaterLevel.x + moos.2021.pt$WaterLevel.y)/2


moos.2021.pt <- mutate(moos.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

moos.2021.pt <- mutate(moos.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))


#STRT

STRT_PT_2021.url <- "https://drive.google.com/drive/u/1/folders/1-om0nU42U8fNmeWtBrhM8WQTbGqBW8RN"
strt_pt.2021.1 <- drive_get(as_id(STRT_PT_2021.url))
strt.pt2021_glist <- drive_ls(strt_pt.2021.1, pattern = "strt.pt.2021.csv")
walk(strt.pt2021_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt_PT_2021.Data <- read.csv("strt.pt.2021.csv",
                              skip = 0, header = TRUE)

strt.data1.2021 <- strt_PT_2021.Data %>% filter(Site == "STRT1")
strt.data2.2021 <- strt_PT_2021.Data %>% filter(Site == "STRT2")
strt.2021.pt <- inner_join(strt.data1.2021, strt.data2.2021, by = "DateTime")
strt.2021.pt$DateTime <- as.POSIXct(paste(strt.2021.pt$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.2021.pt$AvgAbsDepth <- (strt.2021.pt$WaterLevel.x + strt.2021.pt$WaterLevel.x)/2

strt.2021.pt$AvgAbsDepth <- (strt.2021.pt$WaterLevel.x + strt.2021.pt$WaterLevel.y)/2


strt.2021.pt <- mutate(strt.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.y, AvgAbsDepth))

strt.2021.pt <- mutate(strt.2021.pt, AvgAbsDepth = ifelse(is.na(AvgAbsDepth) == TRUE, WaterLevel.x, AvgAbsDepth))



#MY METHOD



# Poke 2019:

#download flowmeter data
WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
WR.19.1 <- drive_get(as_id(WR_19.url))
poke.wr19_glist <- drive_ls(WR.19.1, pattern = "poke_2019_flowmeter_Q_for_R_JAA.csv")
walk(poke.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke_WR_19.Data <- read.csv("poke_2019_flowmeter_Q_for_R_JAA.csv",
                            skip = 1, header = TRUE, na.strings=c("","NA","blank"))

poke_WR_19.Data <- poke_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))

poke_WR_19.Data <- poke_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))


poke_WR_19.Data$datetimeAK <- as.POSIXct(paste(poke_WR_19.Data$Date, poke_WR_19.Data$Time), format="%m/%d/%Y %H:%M")


poke_WR_19.Data <- poke_WR_19.Data %>%
  select(Depth..cm., datetimeAK)

Poke_depth_19_WR <- ddply(na.omit(poke_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_19)


Poke_depth_19_WR <- setDT(Poke_depth_19_WR)

Poke_depth_19_WR <- Poke_depth_19_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

poke.2019.pt <- poke.2019.pt %>%
  dplyr::rename(datetimeAK = DateTime)

poke.2019.pt <- setDT(poke.2019.pt)



poke.2019.pt <- poke.2019.pt %>%
  mutate(across(c(AvgAbsDepth),
                ~ifelse(datetimeAK >= "2019-08-26 02:00:00" & datetimeAK <= "2019-09-08 12:15:00", NA, .)))






setDT(Poke_depth_19_WR)
setDT(poke.2019.pt)

poke.2019.pt$datetimeAK1 <- poke.2019.pt$datetimeAK

setkey( poke.2019.pt, datetimeAK )
setkey( Poke_depth_19_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_poke19 <- poke.2019.pt[ Poke_depth_19_WR, roll = "nearest" ]

rounded.dates_poke19_WR_PT <- rounded.dates_poke19 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_poke19_WR_PT$meanDepth <- rounded.dates_poke19_WR_PT$meanDepth /100

poke_pt_wr_graph <- ggplot(rounded.dates_poke19_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
poke_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/poke_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


poke19_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_poke19_WR_PT)

summary(poke19_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_poke19_WR_PT)
abline(poke19_depth_mod)

#extract slope of model and develop rating curve
poke.2019.pt$RatingCurveDepth <- poke19_depth_mod$coefficients[1]+(poke19_depth_mod$coefficients[2])*poke.2019.pt$AvgAbsDepth




# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   dplyr::rename(datetimeAK_old = datetimeAK)
# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   dplyr::rename(datetimeAK = datetimeAK1)
# 
# rounded.dates_poke19 <- rounded.dates_poke19 %>%
#   select(meanDepth, datetimeAK)
# 
# Poke.2019.pt_WR.Depth <- merge(poke.2019.pt, rounded.dates_poke19, by = "datetimeAK", all = TRUE)
# Poke.2019.pt_WR.Depth$meanDepth1 <- Poke.2019.pt_WR.Depth$meanDepth
# 
# testmod <- lm(meanDepth ~ datetimeAK, Poke.2019.pt_WR.Depth)
# 
# summary(testmod)
# 
# Poke.2019.pt_WR.Depth <- Poke.2019.pt_WR.Depth %>% 
#   mutate(predictedDepth = predict(testmod, .)) %>%
#   # Replace NA with pred in var1
#   mutate(meanDepth = ifelse(is.na(meanDepth), predictedDepth, meanDepth))
# 
# 
# plot(Poke.2019.pt_WR.Depth$AbsPTDepth , Poke.2019.pt_WR.Depth$predictedDepth)
# 
# 
# 
# 
# 
# 
# 
# 
# 

# # Vaul 2019:

#download flowmeter data
WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
WR.19.1 <- drive_get(as_id(WR_19.url))
vaul.wr19_glist <- drive_ls(WR.19.1, pattern = "vaul_2019_flowmeter_Q_for_R_JAA.csv")
walk(vaul.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul_WR_19.Data <- read.csv("vaul_2019_flowmeter_Q_for_R_JAA.csv",
                            skip = 1, header = TRUE, na.strings=c("","NA","blank"))

vaul_WR_19.Data <- vaul_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))

vaul_WR_19.Data <- vaul_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))


vaul_WR_19.Data$datetimeAK <- as.POSIXct(paste(vaul_WR_19.Data$Date, vaul_WR_19.Data$Time), format="%m/%d/%Y %H:%M")


vaul_WR_19.Data <- vaul_WR_19.Data %>%
  select(Depth..cm., datetimeAK)

Vaul_depth_19_WR <- ddply(na.omit(vaul_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_19)


Vaul_depth_19_WR <- setDT(Vaul_depth_19_WR)

Vaul_depth_19_WR <- Vaul_depth_19_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

vaul.2019.pt <- vaul.2019.pt %>%
  dplyr::rename(datetimeAK = DateTime)

vaul.2019.pt <- setDT(vaul.2019.pt)

setDT(Vaul_depth_19_WR)
setDT(vaul.2019.pt)

vaul.2019.pt$datetimeAK1 <- vaul.2019.pt$datetimeAK

setkey( vaul.2019.pt, datetimeAK )
setkey( Vaul_depth_19_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_vaul19 <- vaul.2019.pt[ Vaul_depth_19_WR, roll = "nearest" ]

rounded.dates_vaul19_WR_PT <- rounded.dates_vaul19 %>%
  select(datetimeAK, AbsPTDepth, meanDepth)

#convert to meters
rounded.dates_vaul19_WR_PT$meanDepth <- rounded.dates_vaul19_WR_PT$meanDepth /100

vaul_pt_wr_graph <- ggplot(rounded.dates_vaul19_WR_PT, aes(AbsPTDepth, meanDepth)) +
  geom_point()
# Add regression line
vaul_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/vaul_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


vaul19_depth_mod <- lm(meanDepth~AbsPTDepth, data = rounded.dates_vaul19_WR_PT)

summary(vaul19_depth_mod)

plot(meanDepth~AbsPTDepth, data = rounded.dates_vaul19_WR_PT)
abline(vaul19_depth_mod)

#extract slope of model and develop rating curve
vaul.2019.pt$RatingCurveDepth <-vaul19_depth_mod$coefficients[1]+(vaul19_depth_mod$coefficients[2])*vaul.2019.pt$AbsPTDepth


# # Moos 2019:

#download flowmeter data
WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
WR.19.1 <- drive_get(as_id(WR_19.url))
moos.wr19_glist <- drive_ls(WR.19.1, pattern = "moos_2019_flowmeter_Q_for_R_JAA.csv")
walk(moos.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos_WR_19.Data <- read.csv("moos_2019_flowmeter_Q_for_R_JAA.csv",
                            skip = 1, header = TRUE, na.strings=c("","NA","blank"))

moos_WR_19.Data <- moos_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))

moos_WR_19.Data <- moos_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))


moos_WR_19.Data$datetimeAK <- as.POSIXct(paste(moos_WR_19.Data$Date, moos_WR_19.Data$Time), format="%m/%d/%Y %H:%M")


moos_WR_19.Data <- moos_WR_19.Data %>%
  select(Depth..cm., datetimeAK)

Moos_depth_19_WR <- ddply(na.omit(moos_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_19)


Moos_depth_19_WR <- setDT(Moos_depth_19_WR)

Moos_depth_19_WR <- Moos_depth_19_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

moos.2019.pt <- moos.2019.pt %>%
  dplyr::rename(datetimeAK = DateTime)

moos.2019.pt <- moos.2019.pt %>%
  dplyr::rename(AvgAbsDepth = AbsPTDepth)

moos.2019.pt <- setDT(moos.2019.pt)

setDT(Moos_depth_19_WR)
setDT(moos.2019.pt)

moos.2019.pt$datetimeAK1 <- moos.2019.pt$datetimeAK

setkey( moos.2019.pt, datetimeAK )
setkey( Moos_depth_19_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_moos19 <- moos.2019.pt[ Moos_depth_19_WR, roll = "nearest" ]

rounded.dates_moos19_WR_PT <- rounded.dates_moos19 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_moos19_WR_PT$meanDepth <- rounded.dates_moos19_WR_PT$meanDepth /100

moos_pt_wr_graph <- ggplot(rounded.dates_moos19_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
moos_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/moos_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


moos19_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_moos19_WR_PT)

summary(moos19_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_moos19_WR_PT)
abline(moos19_depth_mod)

#extract slope of model and develop rating curve
moos.2019.pt$RatingCurveDepth <-moos19_depth_mod$coefficients[1]+(moos19_depth_mod$coefficients[2])*moos.2019.pt$AvgAbsDepth



# # Frch 2019:

#download flowmeter data
WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
WR.19.1 <- drive_get(as_id(WR_19.url))
frch.wr19_glist <- drive_ls(WR.19.1, pattern = "Frch_2019_flowmeter_Q_for_R_JAA.csv")
walk(frch.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch_WR_19.Data <- read.csv("Frch_2019_flowmeter_Q_for_R_JAA.csv",
                            skip = 1, header = TRUE, na.strings=c("","NA","blank"))

frch_WR_19.Data <- frch_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))

frch_WR_19.Data <- frch_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))


frch_WR_19.Data$datetimeAK <- as.POSIXct(paste(frch_WR_19.Data$Date, frch_WR_19.Data$Time), format="%m/%d/%Y %H:%M")


frch_WR_19.Data <- frch_WR_19.Data %>%
  select(Depth..cm., datetimeAK)

Frch_depth_19_WR <- ddply(na.omit(frch_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_19)


Frch_depth_19_WR <- setDT(Frch_depth_19_WR)

Frch_depth_19_WR <- Frch_depth_19_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

frch.2019.pt <- frch.2019.pt %>%
  dplyr::rename(datetimeAK = DateTime)

frch.2019.pt <- frch.2019.pt %>%
  dplyr::rename(AvgAbsDepth = AbsPTDepth)

frch.2019.pt <- setDT(frch.2019.pt)

setDT(Frch_depth_19_WR)
setDT(frch.2019.pt)

frch.2019.pt$datetimeAK1 <- frch.2019.pt$datetimeAK

setkey( frch.2019.pt, datetimeAK )
setkey( Frch_depth_19_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_frch19 <- frch.2019.pt[ Frch_depth_19_WR, roll = "nearest" ]

rounded.dates_frch19_WR_PT <- rounded.dates_frch19 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_frch19_WR_PT$meanDepth <- rounded.dates_frch19_WR_PT$meanDepth /100

frch_pt_wr_graph <- ggplot(rounded.dates_frch19_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
frch_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/frch_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


frch19_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_frch19_WR_PT)

summary(frch19_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_frch19_WR_PT)
abline(frch19_depth_mod)

#extract slope of model and develop rating curve
frch.2019.pt$RatingCurveDepth <-frch19_depth_mod$coefficients[1]+(frch19_depth_mod$coefficients[2])*frch.2019.pt$AvgAbsDepth


# # Strt 2019:

#download flowmeter data
WR_19.url <- "https://drive.google.com/drive/u/1/folders/1bm62_JO1dKrFPyUCz8E88K5q7IHElXPP"
WR.19.1 <- drive_get(as_id(WR_19.url))
strt.wr19_glist <- drive_ls(WR.19.1, pattern = "STRT_2019_flowmeter_Q_for_R_JAA.csv")
walk(strt.wr19_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt_WR_19.Data <- read.csv("STRT_2019_flowmeter_Q_for_R_JAA.csv",
                            header = TRUE, na.strings=c("","NA","blank"))

strt_WR_19.Data <- strt_WR_19.Data %>% tidyr::fill(Date, .direction = ("down"))

strt_WR_19.Data <- strt_WR_19.Data %>% tidyr::fill(Time, .direction = ("down"))


strt_WR_19.Data$datetimeAK <- as.POSIXct(paste(strt_WR_19.Data$Date, strt_WR_19.Data$Time), format="%m/%d/%Y %H:%M")


strt_WR_19.Data <- strt_WR_19.Data %>%
  select(Depth..cm., datetimeAK)

Strt_depth_19_WR <- ddply(na.omit(strt_WR_19.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_19)


Strt_depth_19_WR <- setDT(Strt_depth_19_WR)

Strt_depth_19_WR <- Strt_depth_19_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

strt.2019.pt <- strt.2019.pt %>%
  dplyr::rename(datetimeAK = DateTime)

strt.2019.pt <- strt.2019.pt %>%
  dplyr::rename(AvgAbsDepth = AbsPTDepth)

strt.2019.pt <- setDT(strt.2019.pt)

setDT(Strt_depth_19)
setDT(strt.2019.pt)

strt.2019.pt$datetimeAK <- as.POSIXct(strt.2019.pt$datetimeAK)

strt.2019.pt$datetimeAK1 <- strt.2019.pt$datetimeAK

setkey( strt.2019.pt, datetimeAK )
setkey( Strt_depth_19_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_strt19 <- strt.2019.pt[ Strt_depth_19_WR, roll = "nearest" ]

rounded.dates_strt19_WR_PT <- rounded.dates_strt19 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_strt19_WR_PT$meanDepth <- rounded.dates_strt19_WR_PT$meanDepth /100

strt_pt_wr_graph <- ggplot(rounded.dates_strt19_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
strt_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/strt_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


strt19_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_strt19_WR_PT)

summary(strt19_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_strt19_WR_PT)
abline(strt19_depth_mod)

#extract slope of model and develop rating curve
strt.2019.pt$RatingCurveDepth <-strt19_depth_mod$coefficients[1]+(strt19_depth_mod$coefficients[2])*strt.2019.pt$AvgAbsDepth





#### 2020 ####

# Poke 2020:

#download flowmeter data
WR_20_poke.url <- "https://drive.google.com/drive/u/1/folders/1S2L8Qg08AIhQo1ZdKdaxlJliz4bi1ttr"
WR.20_poke.1 <- drive_get(as_id(WR_20_poke.url))
poke.wr20_glist <- drive_ls(WR.20_poke.1, pattern = "R_Flowmeter Q calculation_POKE_for_R_JAA.csv")
walk(poke.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke_WR_20.Data <- read.csv("R_Flowmeter Q calculation_POKE_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


poke_WR_20.Data <- poke_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


poke_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(poke_WR_20.Data$Ã¯..Date), poke_WR_20.Data$Time), format="%y%m%d %H:%M")

poke_WR_20.Data <- poke_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

poke_WR_20.Data <- poke_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Poke_depth_20_WR <- ddply(na.omit(poke_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_20)


Poke_depth_20_WR <- setDT(Poke_depth_20_WR)

Poke_depth_20_WR <- Poke_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

poke.2020.pt <- poke.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

poke.2020.pt <- setDT(poke.2020.pt)

setDT(Poke_depth_20_WR)
setDT(poke.2020.pt)

poke.2020.pt$datetimeAK1 <- poke.2020.pt$datetimeAK

setkey( poke.2020.pt, datetimeAK )
setkey( Poke_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_poke20 <- poke.2020.pt[ Poke_depth_20_WR, roll = "nearest" ]

rounded.dates_poke20_WR_PT <- rounded.dates_poke20 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_poke20_WR_PT$meanDepth <- rounded.dates_poke20_WR_PT$meanDepth /100

poke_pt_wr_graph <- ggplot(rounded.dates_poke20_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
poke_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/poke_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


poke20_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_poke20_WR_PT)

summary(poke20_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_poke20_WR_PT)
abline(poke20_depth_mod)

#extract slope of model and develop rating curve
poke.2020.pt$RatingCurveDepth <- poke20_depth_mod$coefficients[1]+ (poke20_depth_mod$coefficients[2])*poke.2020.pt$AvgAbsDepth






# Vaul 2020:

#download flowmeter data
WR_20_vaul.url <- "https://drive.google.com/drive/u/1/folders/1l-QIICuviZvugbNGrvoLfkCDgo1HyDMg"
WR.20_vaul.1 <- drive_get(as_id(WR_20_vaul.url))
vaul.wr20_glist <- drive_ls(WR.20_vaul.1, pattern = "R_Flowmeter Q calculation_VAUL_for_R_JAA.csv")
walk(vaul.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul_WR_20.Data <- read.csv("R_Flowmeter Q calculation_VAUL_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


vaul_WR_20.Data <- vaul_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


vaul_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(vaul_WR_20.Data$Ã¯..Date), vaul_WR_20.Data$Time), format="%y%m%d %H:%M")

vaul_WR_20.Data <- vaul_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

vaul_WR_20.Data <- vaul_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Vaul_depth_20_WR <- ddply(na.omit(vaul_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_20)


Vaul_depth_20_WR <- setDT(Vaul_depth_20_WR)

Vaul_depth_20_WR <- Vaul_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

vaul.2020.pt <- vaul.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

vaul.2020.pt <- setDT(vaul.2020.pt)

setDT(Vaul_depth_20)
setDT(vaul.2020.pt)

vaul.2020.pt$datetimeAK1 <- vaul.2020.pt$datetimeAK

setkey( vaul.2020.pt, datetimeAK )
setkey( Vaul_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_vaul20 <- vaul.2020.pt[ Vaul_depth_20_WR, roll = "nearest" ]

rounded.dates_vaul20_WR_PT <- rounded.dates_vaul20 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_vaul20_WR_PT$meanDepth <- rounded.dates_vaul20_WR_PT$meanDepth /100

vaul_pt_wr_graph <- ggplot(rounded.dates_vaul20_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
vaul_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/vaul_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


vaul20_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_vaul20_WR_PT)

summary(vaul20_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_vaul20_WR_PT)
abline(vaul20_depth_mod)

#extract slope of model and develop rating curve
vaul.2020.pt$RatingCurveDepth <- vaul20_depth_mod$coefficients[1]+ (vaul20_depth_mod$coefficients[2])*vaul.2020.pt$AvgAbsDepth




# Moos 2020:

#download flowmeter data
WR_20_moos.url <- "https://drive.google.com/drive/u/1/folders/1O28nv-6gsmC_xsAwUFRjjouY9hS29FtK"
WR.20_moos.1 <- drive_get(as_id(WR_20_moos.url))
moos.wr20_glist <- drive_ls(WR.20_moos.1, pattern = "R_Flowmeter Q calculation_MOOS_for_R_JAA.csv")
walk(moos.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos_WR_20.Data <- read.csv("R_Flowmeter Q calculation_MOOS_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


moos_WR_20.Data <- moos_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


moos_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(moos_WR_20.Data$Ã¯..Date), moos_WR_20.Data$Time), format="%y%m%d %H:%M")

moos_WR_20.Data <- moos_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

moos_WR_20.Data <- moos_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Moos_depth_20_WR <- ddply(na.omit(moos_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_20)


Moos_depth_20_WR <- setDT(Moos_depth_20_WR)

Moos_depth_20_WR <- Moos_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

moos.2020.pt <- moos.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

moos.2020.pt <- setDT(moos.2020.pt)

setDT(Moos_depth_20)
setDT(moos.2020.pt)

moos.2020.pt$datetimeAK <- as.POSIXct(moos.2020.pt$datetimeAK)

moos.2020.pt$datetimeAK1 <- moos.2020.pt$datetimeAK


setkey( moos.2020.pt, datetimeAK )
setkey( Moos_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_moos20 <- moos.2020.pt[ Moos_depth_20_WR, roll = "nearest" ]

rounded.dates_moos20_WR_PT <- rounded.dates_moos20 %>%
  select(datetimeAK, WaterLevel, meanDepth)

#convert to meters
rounded.dates_moos20_WR_PT$meanDepth <- rounded.dates_moos20_WR_PT$meanDepth /100

moos_pt_wr_graph <- ggplot(rounded.dates_moos20_WR_PT, aes(WaterLevel, meanDepth)) +
  geom_point()
# Add regression line
moos_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/moos_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


moos20_depth_mod <- lm(meanDepth~WaterLevel, data = rounded.dates_moos20_WR_PT)

summary(moos20_depth_mod)

plot(meanDepth~WaterLevel, data = rounded.dates_moos20_WR_PT)
abline(moos20_depth_mod)

#extract slope of model and develop rating curve
moos.2020.pt$RatingCurveDepth <- moos20_depth_mod$coefficients[1]+ (moos20_depth_mod$coefficients[2])*moos.2020.pt$WaterLevel




# Frch 2020:

#download flowmeter data
WR_20_frch.url <- "https://drive.google.com/drive/u/1/folders/1tlcGKOm11j4nPqgBeTa1Hj6DFTrbZTvy"
WR.20_frch.1 <- drive_get(as_id(WR_20_frch.url))
frch.wr20_glist <- drive_ls(WR.20_frch.1, pattern = "R_Flowmeter Q calculation_FRCH_for_R_JAA.csv")
walk(frch.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch_WR_20.Data <- read.csv("R_Flowmeter Q calculation_FRCH_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


frch_WR_20.Data <- frch_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


frch_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(frch_WR_20.Data$Date), frch_WR_20.Data$Time), format="%y%m%d %H:%M")

frch_WR_20.Data <- frch_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

frch_WR_20.Data <- frch_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Frch_depth_20_WR <- ddply(na.omit(frch_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_20)


Frch_depth_20_WR <- setDT(Frch_depth_20_WR)

Frch_depth_20_WR <- Frch_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

frch.2020.pt <- frch.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

frch.2020.pt <- setDT(frch.2020.pt)

setDT(Frch_depth_20)
setDT(frch.2020.pt)

frch.2020.pt$datetimeAK <- as.POSIXct(frch.2020.pt$datetimeAK)

frch.2020.pt$datetimeAK1 <- frch.2020.pt$datetimeAK


setkey( frch.2020.pt, datetimeAK )
setkey( Frch_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_frch20 <- frch.2020.pt[ Frch_depth_20_WR, roll = "nearest" ]

rounded.dates_frch20_WR_PT <- rounded.dates_frch20 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_frch20_WR_PT$meanDepth <- rounded.dates_frch20_WR_PT$meanDepth /100

frch_pt_wr_graph <- ggplot(rounded.dates_frch20_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
frch_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/frch_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


frch20_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_frch20_WR_PT)

summary(frch20_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_frch20_WR_PT)
abline(frch20_depth_mod)

#extract slope of model and develop rating curve
frch.2020.pt$RatingCurveDepth <- frch20_depth_mod$coefficients[1]+ (frch20_depth_mod$coefficients[2])*frch.2020.pt$AvgAbsDepth




# Moos 2020:

#download flowmeter data
WR_20_moos.url <- "https://drive.google.com/drive/u/1/folders/1O28nv-6gsmC_xsAwUFRjjouY9hS29FtK"
WR.20_moos.1 <- drive_get(as_id(WR_20_moos.url))
moos.wr20_glist <- drive_ls(WR.20_moos.1, pattern = "R_Flowmeter Q calculation_MOOS_for_R_JAA.csv")
walk(moos.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos_WR_20.Data <- read.csv("R_Flowmeter Q calculation_MOOS_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


moos_WR_20.Data <- moos_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


moos_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(moos_WR_20.Data$Ã¯..Date), moos_WR_20.Data$Time), format="%y%m%d %H:%M")

moos_WR_20.Data <- moos_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

moos_WR_20.Data <- moos_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Moos_depth_20_WR <- ddply(na.omit(moos_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_20)


Moos_depth_20_WR <- setDT(Moos_depth_20_WR)

Moos_depth_20_WR <- Moos_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

moos.2020.pt <- moos.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

moos.2020.pt <- setDT(moos.2020.pt)

setDT(Moos_depth_20)
setDT(moos.2020.pt)

moos.2020.pt$datetimeAK <- as.POSIXct(moos.2020.pt$datetimeAK)

moos.2020.pt$datetimeAK1 <- moos.2020.pt$datetimeAK


setkey( moos.2020.pt, datetimeAK )
setkey( Moos_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_moos20 <- moos.2020.pt[ Moos_depth_20_WR, roll = "nearest" ]

rounded.dates_moos20_WR_PT <- rounded.dates_moos20 %>%
  select(datetimeAK, WaterLevel, meanDepth)

#convert to meters
rounded.dates_moos20_WR_PT$meanDepth <- rounded.dates_moos20_WR_PT$meanDepth /100

moos_pt_wr_graph <- ggplot(rounded.dates_moos20_WR_PT, aes(WaterLevel, meanDepth)) +
  geom_point()
# Add regression line
moos_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/moos_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


moos20_depth_mod <- lm(meanDepth~WaterLevel, data = rounded.dates_moos20_WR_PT)

summary(moos20_depth_mod)

plot(meanDepth~WaterLevel, data = rounded.dates_moos20_WR_PT)
abline(moos20_depth_mod)

#extract slope of model and develop rating curve
moos.2020.pt$RatingCurveDepth <- moos20_depth_mod$coefficients[1]+ (moos20_depth_mod$coefficients[2])*moos.2020.pt$WaterLevel




# Strt 2020:

#download flowmeter data
WR_20_strt.url <- "https://drive.google.com/drive/u/1/folders/1x_E4gaPvjRLDcrM8lN2ao4_o0bzdMBrb"
WR.20_strt.1 <- drive_get(as_id(WR_20_strt.url))
strt.wr20_glist <- drive_ls(WR.20_strt.1, pattern = "R_Flowmeter Q calculation_STRT_for_R_JAA.csv")
walk(strt.wr20_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt_WR_20.Data <- read.csv("R_Flowmeter Q calculation_STRT_for_R_JAA.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


strt_WR_20.Data <- strt_WR_20.Data %>% tidyr::fill(Time, .direction = ("down"))


strt_WR_20.Data$datetimeAK <- as.POSIXct(paste(as.character(strt_WR_20.Data$Ã¯..Date), strt_WR_20.Data$Time), format="%y%m%d %H:%M")

strt_WR_20.Data <- strt_WR_20.Data %>%
  dplyr::rename(Depth..cm. = Depth)

strt_WR_20.Data <- strt_WR_20.Data %>%
  select(Depth..cm., datetimeAK)

Strt_depth_20_WR <- ddply(na.omit(strt_WR_20.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_20)


Strt_depth_20_WR <- setDT(Strt_depth_20_WR)

Strt_depth_20_WR <- Strt_depth_20_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

strt.2020.pt <- strt.2020.pt %>%
  dplyr::rename(datetimeAK = DateTime)

strt.2020.pt <- setDT(strt.2020.pt)

setDT(Strt_depth_20)
setDT(strt.2020.pt)

strt.2020.pt$datetimeAK <- as.POSIXct(strt.2020.pt$datetimeAK)

strt.2020.pt$datetimeAK1 <- strt.2020.pt$datetimeAK


setkey( strt.2020.pt, datetimeAK )
setkey( Strt_depth_20_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_strt20 <- strt.2020.pt[ Strt_depth_20_WR, roll = "nearest" ]

rounded.dates_strt20_WR_PT <- rounded.dates_strt20 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_strt20_WR_PT$meanDepth <- rounded.dates_strt20_WR_PT$meanDepth /100

strt_pt_wr_graph <- ggplot(rounded.dates_strt20_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
strt_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/strt_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


strt20_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_strt20_WR_PT)

summary(strt20_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_strt20_WR_PT)
abline(strt20_depth_mod)

#extract slope of model and develop rating curve
strt.2020.pt$RatingCurveDepth <- strt20_depth_mod$coefficients[1]+ (strt20_depth_mod$coefficients[2])*strt.2020.pt$AvgAbsDepth

#Curve is being skewed by a single point in november, maybe due to ice or other conditions. Plot below is without that point. It appears to be an outlier.

rounded.dates_strt20_WR_PT_2 <- rounded.dates_strt20_WR_PT[-c(9), ]

strt20_depth_mod2 <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_strt20_WR_PT_2)


strt_pt_wr_graph2 <- ggplot(rounded.dates_strt20_WR_PT_2, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
strt_pt_wr_graph2 + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/strt_pt_wr_graph2.png", width = 15, height = 10, units = "cm", scale = 1.3)


strt20_depth_mod2 <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_strt20_WR_PT_2)

summary(strt20_depth_mod2)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_strt20_WR_PT_2)
abline(strt20_depth_mod2)

#extract slope of model and develop rating curve
strt.2020.pt$RatingCurveDepth2 <- strt20_depth_mod2$coefficients[1]+ (strt20_depth_mod2$coefficients[2])*strt.2020.pt$AvgAbsDepth


#add original back in to compare

strt.2020.pt$RatingCurveDepth <- strt20_depth_mod$coefficients[1]+ (strt20_depth_mod$coefficients[2])*strt.2020.pt$AvgAbsDepth

#it is bad. use original
strt.2020.pt$RatingCurveDepth <- strt.2020.pt$RatingCurveDepth2


#### 2021 ####

# Poke 2021:

#download flowmeter data
WR_21_poke.url <- "https://drive.google.com/drive/u/1/folders/18z6vSz6SE3DEvUVDyfM8I3gqkGaxQqOl"
WR.21_poke.1 <- drive_get(as_id(WR_21_poke.url))
poke.wr21_glist <- drive_ls(WR.21_poke.1, pattern = "R_Flowmeter Q calculation_POKE_for_R_JAA_2021.csv")
walk(poke.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
poke_WR_21.Data <- read.csv("R_Flowmeter Q calculation_POKE_for_R_JAA_2021.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


poke_WR_21.Data <- poke_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))


poke_WR_21.Data$datetimeAK <- as.POSIXct(paste(as.character(poke_WR_21.Data$Ã¯..Date), poke_WR_21.Data$Time), format="%y%m%d %H:%M")

poke_WR_21.Data <- poke_WR_21.Data %>%
  dplyr::rename(Depth..cm. = Depth)

poke_WR_21.Data <- poke_WR_21.Data %>%
  select(Depth..cm., datetimeAK)

Poke_depth_21_WR <- ddply(na.omit(poke_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# poke_wr.lm <- lm(meanDepth~datetimeAK, Poke_depth_21)


Poke_depth_21_WR <- setDT(Poke_depth_21_WR)

Poke_depth_21_WR <- Poke_depth_21_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

poke.2021.pt <- poke.2021.pt %>%
  dplyr::rename(datetimeAK = DateTime)

poke.2021.pt <- setDT(poke.2021.pt)

setDT(Poke_depth_21_WR)
setDT(poke.2021.pt)

poke.2021.pt$datetimeAK1 <- poke.2021.pt$datetimeAK

setkey( poke.2021.pt, datetimeAK )
setkey( Poke_depth_21_WR, datetimeAK )

#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_poke21 <- poke.2021.pt[ Poke_depth_21_WR, roll = "nearest" ]

rounded.dates_poke21_WR_PT <- rounded.dates_poke21 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_poke21_WR_PT$meanDepth <- rounded.dates_poke21_WR_PT$meanDepth /100

poke_pt_wr_graph <- ggplot(rounded.dates_poke21_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
poke_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/poke_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


poke21_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_poke21_WR_PT)

summary(poke21_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_poke21_WR_PT)
abline(poke21_depth_mod)

#extract slope of model and develop rating curve
poke.2021.pt$RatingCurveDepth <- poke21_depth_mod$coefficients[1]+ (poke21_depth_mod$coefficients[2])*poke.2021.pt$AvgAbsDepth



# Vaul 2021:

#download flowmeter data
WR_21_vaul.url <- "https://drive.google.com/drive/u/1/folders/13avby555rryYttGDgO8sKE7umZPmo5uB"
WR.21_vaul.1 <- drive_get(as_id(WR_21_vaul.url))
vaul.wr21_glist <- drive_ls(WR.21_vaul.1, pattern = "R_Flowmeter Q calculation_VAUL_for_R_JAA_2021.csv")
walk(vaul.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
vaul_WR_21.Data <- read.csv("R_Flowmeter Q calculation_VAUL_for_R_JAA_2021.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


vaul_WR_21.Data <- vaul_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))


vaul_WR_21.Data$datetimeAK <- as.POSIXct(paste(as.character(vaul_WR_21.Data$Ã¯..Date), vaul_WR_21.Data$Time), format="%y%m%d %H:%M")

vaul_WR_21.Data <- vaul_WR_21.Data %>%
  dplyr::rename(Depth..cm. = Depth)

vaul_WR_21.Data <- vaul_WR_21.Data %>%
  select(Depth..cm., datetimeAK)

Vaul_depth_21_WR <- ddply(na.omit(vaul_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# vaul_wr.lm <- lm(meanDepth~datetimeAK, Vaul_depth_21)


Vaul_depth_21_WR <- setDT(Vaul_depth_21_WR)

Vaul_depth_21_WR <- Vaul_depth_21_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

vaul.2021.pt <- vaul.2021.pt %>%
  dplyr::rename(datetimeAK = DateTime)

vaul.2021.pt <- setDT(vaul.2021.pt)

setDT(Vaul_depth_21)
setDT(vaul.2021.pt)

vaul.2021.pt$datetimeAK1 <- vaul.2021.pt$datetimeAK

vaul.2021.pt$datetimeAK <- as.POSIXct(vaul.2021.pt$datetimeAK)

vaul.2021.pt$datetimeAK <- as.POSIXct(vaul.2021.pt$datetimeAK)

setkey( vaul.2021.pt, datetimeAK )
setkey( Vaul_depth_21_WR, datetimeAK )



#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_vaul21 <- vaul.2021.pt[Vaul_depth_21_WR, roll = "nearest" ]

rounded.dates_vaul21_WR_PT <- rounded.dates_vaul21 %>%
  select(datetimeAK, WaterLevel, meanDepth)

#convert to meters
rounded.dates_vaul21_WR_PT$meanDepth <- rounded.dates_vaul21_WR_PT$meanDepth /100

vaul_pt_wr_graph <- ggplot(rounded.dates_vaul21_WR_PT, aes(WaterLevel, meanDepth)) +
  geom_point()
# Add regression line
vaul_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/vaul_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


vaul21_depth_mod <- lm(meanDepth~WaterLevel, data = rounded.dates_vaul21_WR_PT)

summary(vaul21_depth_mod)

plot(meanDepth~WaterLevel, data = rounded.dates_vaul21_WR_PT)
abline(vaul21_depth_mod)

#extract slope of model and develop rating curve
vaul.2021.pt$RatingCurveDepth <- vaul21_depth_mod$coefficients[1]+ (vaul21_depth_mod$coefficients[2])*vaul.2021.pt$WaterLevel







# Moos 2021:

#download flowmeter data
WR_21_moos.url <- "https://drive.google.com/drive/u/1/folders/1-S_ixEutlA7RKfrvhi15aIBLrjYjg5O_"
WR.21_moos.1 <- drive_get(as_id(WR_21_moos.url))
moos.wr21_glist <- drive_ls(WR.21_moos.1, pattern = "R_Flowmeter Q calculation_MOOS_for_R_JAA_2021.csv")
walk(moos.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
moos_WR_21.Data <- read.csv("R_Flowmeter Q calculation_MOOS_for_R_JAA_2021.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


moos_WR_21.Data <- moos_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))


moos_WR_21.Data$datetimeAK <- as.POSIXct(paste(as.character(moos_WR_21.Data$Ã¯..Date), moos_WR_21.Data$Time), format="%y%m%d %H:%M")

moos_WR_21.Data <- moos_WR_21.Data %>%
  dplyr::rename(Depth..cm. = Depth)

moos_WR_21.Data <- moos_WR_21.Data %>%
  select(Depth..cm., datetimeAK)

Moos_depth_21_WR <- ddply(na.omit(moos_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# moos_wr.lm <- lm(meanDepth~datetimeAK, Moos_depth_21)


Moos_depth_21_WR <- setDT(Moos_depth_21_WR)

Moos_depth_21_WR <- Moos_depth_21_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

moos.2021.pt <- moos.2021.pt %>%
  dplyr::rename(datetimeAK = DateTime)

moos.2021.pt <- setDT(moos.2021.pt)

setDT(Moos_depth_21)
setDT(moos.2021.pt)

moos.2021.pt$datetimeAK1 <- moos.2021.pt$datetimeAK

moos.2021.pt$datetimeAK <- as.POSIXct(moos.2021.pt$datetimeAK)

moos.2021.pt$datetimeAK <- as.POSIXct(moos.2021.pt$datetimeAK)

setkey( moos.2021.pt, datetimeAK )
setkey( Moos_depth_21_WR, datetimeAK )



#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_moos21 <- moos.2021.pt[Moos_depth_21_WR, roll = "nearest" ]

rounded.dates_moos21_WR_PT <- rounded.dates_moos21 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_moos21_WR_PT$meanDepth <- rounded.dates_moos21_WR_PT$meanDepth /100

moos_pt_wr_graph <- ggplot(rounded.dates_moos21_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
moos_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/moos_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


moos21_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_moos21_WR_PT)

summary(moos21_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_moos21_WR_PT)
abline(moos21_depth_mod)

#extract slope of model and develop rating curve
moos.2021.pt$RatingCurveDepth <- moos21_depth_mod$coefficients[1]+ (moos21_depth_mod$coefficients[2])*moos.2021.pt$AvgAbsDepth





# Frch 2021:

#download flowmeter data
WR_21_frch.url <- "https://drive.google.com/drive/u/1/folders/1MrFabu9Mzuv3v4naPl2-iCFaMj_DjkZG"
WR.21_frch.1 <- drive_get(as_id(WR_21_frch.url))
frch.wr21_glist <- drive_ls(WR.21_frch.1, pattern = "R_Flowmeter_Q_calulation_FRCH_for_R_JAA_2021.csv")
walk(frch.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
frch_WR_21.Data <- read.csv("R_Flowmeter_Q_calulation_FRCH_for_R_JAA_2021.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


frch_WR_21.Data <- frch_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))


frch_WR_21.Data$datetimeAK <- as.POSIXct(paste(as.character(frch_WR_21.Data$Ã¯..Date), frch_WR_21.Data$Time), format="%y%m%d %H:%M")

frch_WR_21.Data <- frch_WR_21.Data %>%
  dplyr::rename(Depth..cm. = Depth)

frch_WR_21.Data <- frch_WR_21.Data %>%
  select(Depth..cm., datetimeAK)

Frch_depth_21_WR <- ddply(na.omit(frch_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# frch_wr.lm <- lm(meanDepth~datetimeAK, Frch_depth_21)


Frch_depth_21_WR <- setDT(Frch_depth_21_WR)

Frch_depth_21_WR <- Frch_depth_21_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

frch.2021.pt <- frch.2021.pt %>%
  dplyr::rename(datetimeAK = DateTime)

frch.2021.pt <- setDT(frch.2021.pt)

setDT(Frch_depth_21)
setDT(frch.2021.pt)

frch.2021.pt$datetimeAK1 <- frch.2021.pt$datetimeAK

frch.2021.pt$datetimeAK <- as.POSIXct(frch.2021.pt$datetimeAK)

frch.2021.pt$datetimeAK <- as.POSIXct(frch.2021.pt$datetimeAK)

setkey( frch.2021.pt, datetimeAK )
setkey( Frch_depth_21_WR, datetimeAK )



#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_frch21 <- frch.2021.pt[Frch_depth_21_WR, roll = "nearest" ]

rounded.dates_frch21_WR_PT <- rounded.dates_frch21 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_frch21_WR_PT$meanDepth <- rounded.dates_frch21_WR_PT$meanDepth /100

frch_pt_wr_graph <- ggplot(rounded.dates_frch21_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
frch_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/frch_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


frch21_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_frch21_WR_PT)

summary(frch21_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_frch21_WR_PT)
abline(frch21_depth_mod)

#extract slope of model and develop rating curve
frch.2021.pt$RatingCurveDepth <- frch21_depth_mod$coefficients[1]+ (frch21_depth_mod$coefficients[2])*frch.2021.pt$AvgAbsDepth






# Strt 2021:

#download flowmeter data
WR_21_strt.url <- "https://drive.google.com/drive/u/1/folders/1LTD4EFX3_Yas0ZCF8rKLl6dxSeZDvkDY"
WR.21_strt.1 <- drive_get(as_id(WR_21_strt.url))
strt.wr21_glist <- drive_ls(WR.21_strt.1, pattern = "R_Flowmeter Q calculation_STRT_for_R_JAA_2021.csv")
walk(strt.wr21_glist$id, ~ drive_download(as_id(.x), overwrite = TRUE))
strt_WR_21.Data <- read.csv("R_Flowmeter Q calculation_STRT_for_R_JAA_2021.csv",
                            skip = 0, header = TRUE, na.strings=c("","NA","blank"))


strt_WR_21.Data <- strt_WR_21.Data %>% tidyr::fill(Time, .direction = ("down"))


strt_WR_21.Data$datetimeAK <- as.POSIXct(paste(as.character(strt_WR_21.Data$Date), strt_WR_21.Data$Time), format="%y%m%d %H:%M")

strt_WR_21.Data <- strt_WR_21.Data %>%
  dplyr::rename(Depth..cm. = Depth)

strt_WR_21.Data <- strt_WR_21.Data %>%
  select(Depth..cm., datetimeAK)

Strt_depth_21_WR <- ddply(na.omit(strt_WR_21.Data), .(datetimeAK), summarize, meanDepth = mean(as.numeric(Depth..cm.)))

# strt_wr.lm <- lm(meanDepth~datetimeAK, Strt_depth_21)


Strt_depth_21_WR <- setDT(Strt_depth_21_WR)

Strt_depth_21_WR <- Strt_depth_21_WR %>%
  dplyr::rename(datetimeAK = datetimeAK)

strt.2021.pt <- strt.2021.pt %>%
  dplyr::rename(datetimeAK = DateTime)

strt.2021.pt <- setDT(strt.2021.pt)

setDT(Strt_depth_21)
setDT(strt.2021.pt)

strt.2021.pt$datetimeAK1 <- strt.2021.pt$datetimeAK

strt.2021.pt$datetimeAK <- as.POSIXct(strt.2021.pt$datetimeAK)

strt.2021.pt$datetimeAK <- as.POSIXct(strt.2021.pt$datetimeAK)

setkey( strt.2021.pt, datetimeAK )
setkey( Strt_depth_21_WR, datetimeAK )



#WR was taken when EXO out of water. round depth point to nearest in data record
rounded.dates_strt21 <- strt.2021.pt[Strt_depth_21_WR, roll = "nearest" ]

rounded.dates_strt21_WR_PT <- rounded.dates_strt21 %>%
  select(datetimeAK, AvgAbsDepth, meanDepth)

#convert to meters
rounded.dates_strt21_WR_PT$meanDepth <- rounded.dates_strt21_WR_PT$meanDepth /100

strt_pt_wr_graph <- ggplot(rounded.dates_strt21_WR_PT, aes(AvgAbsDepth, meanDepth)) +
  geom_point()
# Add regression line
strt_pt_wr_graph + geom_smooth(method = lm) + xlab("Depth (PT)") +ylab ("Depth (WR)")

ggsave("plots/strt_pt_wr_graph.png", width = 15, height = 10, units = "cm", scale = 1.3)


strt21_depth_mod <- lm(meanDepth~AvgAbsDepth, data = rounded.dates_strt21_WR_PT)

summary(strt21_depth_mod)

plot(meanDepth~AvgAbsDepth, data = rounded.dates_strt21_WR_PT)
abline(strt21_depth_mod)

#extract slope of model and develop rating curve
strt.2021.pt$RatingCurveDepth <- strt21_depth_mod$coefficients[1]+ (strt21_depth_mod$coefficients[2])*strt.2021.pt$AvgAbsDepth









#### combine ####

poke.2019.depth <- poke.2019.pt %>%
  select(RatingCurveDepth, datetimeAK)

poke.2020.depth <- poke.2020.pt %>%
  select(RatingCurveDepth, datetimeAK)

poke.2021.depth <- poke.2021.pt %>%
  select(RatingCurveDepth, datetimeAK)

poke.depth <- rbind (poke.2019.depth, poke.2020.depth, poke.2021.depth)




vaul.2019.depth <- vaul.2019.pt %>%
  select(RatingCurveDepth, datetimeAK)

vaul.2020.depth <- vaul.2020.pt %>%
  select(RatingCurveDepth, datetimeAK)

vaul.2020.depth <- vaul.2020.depth %>% filter(datetimeAK <= "2020-10-14 03:45:00")

vaul.2021.depth <- vaul.2021.pt %>%
  select(RatingCurveDepth, datetimeAK)

vaul.depth <- rbind (vaul.2019.depth, vaul.2020.depth, vaul.2021.depth)



moos.2019.depth <- moos.2019.pt %>%
  select(RatingCurveDepth, datetimeAK)

moos.2020.depth <- moos.2020.pt %>%
  select(RatingCurveDepth, datetimeAK)

moos.2020.depth <- moos.2020.depth %>% filter(datetimeAK <= "2020-10-15 08:45:00")



moos.2021.depth <- moos.2021.pt %>%
  select(RatingCurveDepth, datetimeAK)

moos.depth <- rbind (moos.2019.depth, moos.2020.depth, moos.2021.depth)




frch.2019.depth <- frch.2019.pt %>%
  select(RatingCurveDepth, datetimeAK)

frch.2020.depth <- frch.2020.pt %>%
  select(RatingCurveDepth, datetimeAK)

frch.2020.depth <- frch.2020.depth %>% filter(datetimeAK <= "2020-10-15 02:30:00")


frch.2021.depth <- frch.2021.pt %>%
  select(RatingCurveDepth, datetimeAK)

frch.depth <- rbind (frch.2019.depth, frch.2020.depth, frch.2021.depth)



strt.2019.depth <- strt.2019.pt %>%
  select(RatingCurveDepth, datetimeAK)

strt.2020.depth <- strt.2020.pt %>%
  select(RatingCurveDepth, datetimeAK)

strt.2020.depth <- strt.2020.depth %>% filter(datetimeAK <= "2020-10-13 06:30:00")

strt.2021.depth <- strt.2021.pt %>%
  select(RatingCurveDepth, datetimeAK)

strt.depth <- rbind (strt.2019.depth, strt.2020.depth, strt.2021.depth)

########################### INPUT SYNTHESIS AND PLOTS ####################

# Make Figures with data 
#Packages I think I might perhaps maybe need...
library(ggpubr)
library(anytime)
library(googlesheets4)
library(ggpmisc)
library(plyr)

library(dplyr)
library(lubridate)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)

library(zoo)
library(xts)
library(forecast)
library(googledrive)
library(streamMetabolizer)
library(readr)
library(ggpubr)
library(period.apply)
library(here)
#start in DO stitch and other stitch scripts
#run script 1 again if it does not work



##### FRCH ####
#DO and Temp Data
All.years.frch.MESSY

All.years.frch.MESSY <- All.years.frch.MESSY %>%
  select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)

All.years.frch.MESSY$datetimeAK <- as.POSIXct(All.years.frch.MESSY$datetimeAK)


# DO SAT CALCS Summary
All.years.frch.MESSY$DO.sat.EXO = All.years.frch.MESSY$DO.obs /(All.years.frch.MESSY$ODO.Psat/100)


#discharge
FRCH.ALL.Q

FRCH.ALL.Q <- FRCH.ALL.Q %>%
  dplyr::rename(datetimeAK = DateTime)


#already in AKDT
FRCH.ALL.Q$datetimeAK <- as.POSIXct(FRCH.ALL.Q$datetimeAK)

setDT(FRCH.ALL.Q)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

FRCH.ALL.Q <- aggregate(Q ~ datetimeAK, data=FRCH.ALL.Q, FUN=mean)

FRCH.ALL.Q <- FRCH.ALL.Q %>%
  dplyr::rename(discharge = Q)

#air Pressure
frch.ap.data

frch.ap.data <- frch.ap.data %>%
  dplyr::rename(datetimeAK = DateTime)

frch.ap.data$datetimeAK <- as.POSIXct(frch.ap.data$datetimeAK)


#light
frch.combinded.par

frch.combinded.par <- frch.combinded.par %>%
  dplyr::rename(datetimeAK = DateTime)

frch.combinded.par <- frch.combinded.par %>%
  dplyr::rename(light = Calibrated.Value)

frch.combinded.par$datetimeAK <- as.POSIXct(frch.combinded.par$datetimeAK)


#depth rating curve
frch.depth

frch.depth <- frch.depth %>%
  dplyr::rename(depth = RatingCurveDepth)

frch.depth$datetimeAK <- as.POSIXct(frch.depth$datetimeAK)

setDT(frch.depth)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

frch.depth <- aggregate(depth ~ datetimeAK, data=frch.depth, FUN=mean)


#Combine

FRCH.comb <- merge(All.years.frch.MESSY, FRCH.ALL.Q, 
                   # frch.depth, frch.combinded.par,frch.ap.data, 
                   by = "datetimeAK", all = TRUE)
FRCH.comb <- merge(FRCH.comb, frch.depth,
                   # frch.combinded.par,frch.ap.data, 
                   by = "datetimeAK", all = TRUE)
FRCH.comb <- merge(FRCH.comb, frch.combinded.par,
                   # frch.ap.data, 
                   by = "datetimeAK", all = TRUE)
FRCH.comb <- merge(FRCH.comb, frch.ap.data,
                   # , 
                   by = "datetimeAK", all = TRUE)

# FRCH.comb$DO.sat <- calc_DO_sat(FRCH.comb$temp.water, FRCH.comb$air.pressure.mbar, model = "garcia-benson")




FRCH.comb$solar.time <- calc_solar_time(FRCH.comb$datetimeAK,-146.915323)

FRCH.comb <- distinct(FRCH.comb)

FRCH.comb


# #remove outliers (find a better way to do this)
# FRCH.comb <- FRCH.comb[-c(23773,23774)]
# FRCH.comb <- FRCH.comb[-c(29660)]
# FRCH.comb <- FRCH.comb[-c(25015,25016,25017)]

FRCH.comb$DO.sat <- FRCH.comb$DO.sat.EXO

here()

write.csv(FRCH.comb, here("outputs", "frch.comb.csv"))

# ALL YEARS
frch.plot1 <- FRCH.comb %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "French ODO, 2019 - 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
frchPlot2 <- FRCH.comb %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb_2019-2021.pdf", height= 8.5)
ggarrange(frch.plot1, frchPlot2, ncol = 1, nrow = 2)
dev.off()


#2019

#
frch.plot1.19 <- FRCH.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "French ODO, 2019")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
frchPlot2.19 <- FRCH.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2019.pdf", height= 8.5)
ggarrange(frch.plot1.19, frchPlot2.19, ncol = 1, nrow = 2)
dev.off()

#2020

#
frch.plot1.20 <- FRCH.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "French ODO, 2020")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
frchPlot2.20 <- FRCH.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2020.pdf", height= 8.5)
ggarrange(frch.plot1.20, frchPlot2.20, ncol = 1, nrow = 2)
dev.off()

#2021

#
frch.plot1.21 <- FRCH.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "French ODO, 2121")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
frchPlot2.21 <- FRCH.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2021.pdf", height= 8.5)
ggarrange(frch.plot1.21, frchPlot2.21, ncol = 1, nrow = 2)
dev.off()





# ##### FRCH ####
# 
# #FRCH
# #DO and Temp Data
# All.years.frch.MESSY
# 
# All.years.frch.MESSY <- All.years.frch.MESSY %>%
#   select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)
# 
# All.years.frch.MESSY$datetimeAK <- as.POSIXct(All.years.frch.MESSY$datetimeAK)
# 
# #discharge
# FRCH.ALL.Q
# 
# FRCH.ALL.Q <- FRCH.ALL.Q %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# 
# 
# FRCH.ALL.Q$datetimeAK <- as.POSIXct(FRCH.ALL.Q$datetimeAK)
# 
# setDT(FRCH.ALL.Q)[, datetimeAK := datetimeAK[1L], 
#                   by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]
# 
# FRCH.ALL.Q <- aggregate(Q ~ datetimeAK, data=FRCH.ALL.Q, FUN=mean)
# 
# FRCH.ALL.Q <- FRCH.ALL.Q %>%
#   dplyr::rename(discharge = Q)
# 
# #air Pressure
# frch.ap.data
# 
# frch.ap.data <- frch.ap.data %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# frch.ap.data$datetimeAK <- as.POSIXct(frch.ap.data$datetimeAK)
# 
# 
# #light
# frch.combinded.par
# 
# frch.combinded.par <- frch.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# frch.combinded.par <- frch.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# frch.combinded.par$datetimeAK <- as.POSIXct(frch.combinded.par$datetimeAK)
# 
# 
# #depth rating curve
# frch.depth
# 
# frch.depth <- frch.depth %>%
#   dplyr::rename(depth = RatingCurveDepth)
# 
# frch.depth$datetimeAK <- as.POSIXct(frch.depth$datetimeAK)
# 
# setDT(frch.depth)[, datetimeAK := datetimeAK[1L], 
#                   by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]
# 
# frch.depth <- aggregate(depth ~ datetimeAK, data=frch.depth, FUN=mean)
# 
# 
# #Combine
# 
# FRCH.comb <- merge(All.years.frch.MESSY, FRCH.ALL.Q, 
#                    # frch.depth, frch.combinded.par,frch.ap.data, 
#                    by = "datetimeAK", all = TRUE)
# FRCH.comb <- merge(FRCH.comb, frch.depth,
#                    # frch.combinded.par,frch.ap.data, 
#                    by = "datetimeAK", all = TRUE)
# FRCH.comb <- merge(FRCH.comb, frch.combinded.par,
#                    # frch.ap.data, 
#                    by = "datetimeAK", all = TRUE)
# FRCH.comb <- merge(FRCH.comb, frch.ap.data,
#                    # , 
#                    by = "datetimeAK", all = TRUE)
# 
# FRCH.comb$DO.sat <- calc_DO_sat(FRCH.comb$temp.water, FRCH.comb$air.pressure.mbar, model = "garcia-benson")
# 
# FRCH.comb$solar.time <- calc_solar_time(FRCH.comb$datetimeAK,-146.915323)
# 
# FRCH.comb <- distinct(FRCH.comb)
# 
# 
# # ALL YEARS
# frch.plot1 <- FRCH.comb %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2019 - 2021")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
# frchPlot2 <- FRCH.comb %>% 
#   select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb_2019-2021.pdf", height= 8.5)
# ggarrange(frch.plot1, frchPlot2, ncol = 1, nrow = 2)
# dev.off()
# 
# 
# #2019
# 
# #
# frch.plot1.19 <- FRCH.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2019")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
# frchPlot2.19 <- FRCH.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2019.pdf", height= 8.5)
# ggarrange(frch.plot1.19, frchPlot2.19, ncol = 1, nrow = 2)
# dev.off()
# 
# #2020
# 
# #
# frch.plot1.20 <- FRCH.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2020")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
# frchPlot2.20 <- FRCH.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
#   select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2020.pdf", height= 8.5)
# ggarrange(frch.plot1.20, frchPlot2.20, ncol = 1, nrow = 2)
# dev.off()
# 
# #2021
# 
# #
# frch.plot1.21 <- FRCH.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2021")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
# frchPlot2.21 <- FRCH.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/FRCH_comb.2021.pdf", height= 8.5)
# ggarrange(frch.plot1.21, frchPlot2.21, ncol = 1, nrow = 2)
# dev.off()
# 
# 
# 
# 
# 
# 
##### MOOS ####

#MOOS
#DO and Temp Data
All.years.moos.MESSY

All.years.moos.MESSY <- All.years.moos.MESSY %>%
  select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)

All.years.moos.MESSY$datetimeAK <- as.POSIXct(All.years.moos.MESSY$datetimeAK)

#discharge
MOOS.ALL.Q

MOOS.ALL.Q <- MOOS.ALL.Q %>%
  dplyr::rename(datetimeAK = DateTime)



MOOS.ALL.Q$datetimeAK <- as.POSIXct(MOOS.ALL.Q$datetimeAK)

setDT(MOOS.ALL.Q)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

MOOS.ALL.Q <- aggregate(Q ~ datetimeAK, data=MOOS.ALL.Q, FUN=mean)

MOOS.ALL.Q <- MOOS.ALL.Q %>%
  dplyr::rename(discharge = Q)

#air Pressure
moos.ap.data

moos.ap.data <- moos.ap.data %>%
  dplyr::rename(datetimeAK = DateTime)

moos.ap.data$datetimeAK <- as.POSIXct(moos.ap.data$datetimeAK)


#light
moos.combinded.par

moos.combinded.par <- moos.combinded.par %>%
  dplyr::rename(datetimeAK = DateTime)

moos.combinded.par <- moos.combinded.par %>%
  dplyr::rename(light = Calibrated.Value)

moos.combinded.par$datetimeAK <- as.POSIXct(moos.combinded.par$datetimeAK)


#depth rating curve
moos.depth

moos.depth <- moos.depth %>%
  dplyr::rename(depth = RatingCurveDepth)

moos.depth$datetimeAK <- as.POSIXct(moos.depth$datetimeAK)

setDT(moos.depth)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

moos.depth <- aggregate(depth ~ datetimeAK, data=moos.depth, FUN=mean)


#Combine

MOOS.comb <- merge(All.years.moos.MESSY, MOOS.ALL.Q, 
                   # moos.depth, moos.combinded.par,moos.ap.data, 
                   by = "datetimeAK", all = TRUE)
MOOS.comb <- merge(MOOS.comb, moos.depth,
                   # moos.combinded.par,moos.ap.data, 
                   by = "datetimeAK", all = TRUE)
MOOS.comb <- merge(MOOS.comb, moos.combinded.par,
                   # moos.ap.data, 
                   by = "datetimeAK", all = TRUE)
MOOS.comb <- merge(MOOS.comb, moos.ap.data,
                   # , 
                   by = "datetimeAK", all = TRUE)

# DO SAT CALCS Summary
MOOS.comb$DO.sat.EXO = MOOS.comb$DO.obs /(MOOS.comb$ODO.Psat/100)

MOOS.comb$solar.time <- calc_solar_time(MOOS.comb$datetimeAK,-146.915323)

MOOS.comb <- distinct(MOOS.comb)

write.csv(MOOS.comb, here("outputs", "moos.comb.csv"))

# ALL YEARS
moos.plot1 <- MOOS.comb %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Moose ODO, 2019 - 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
moosPlot2 <- MOOS.comb %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/MOOS_comb_2019-2021.pdf", height= 8.5)
ggarrange(moos.plot1, moosPlot2, ncol = 1, nrow = 2)
dev.off()


#2019

#
moos.plot1.19 <- MOOS.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Moose ODO, 2019")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
moosPlot2.19 <- MOOS.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/MOOS_comb.2019.pdf", height= 8.5)
ggarrange(moos.plot1.19, moosPlot2.19, ncol = 1, nrow = 2)
dev.off()

#2020

#
moos.plot1.20 <- MOOS.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Moose ODO, 2020")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
moosPlot2.20 <- MOOS.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/MOOS_comb.2020.pdf", height= 8.5)
ggarrange(moos.plot1.20, moosPlot2.20, ncol = 1, nrow = 2)
dev.off()

#2021

#
moos.plot1.21 <- MOOS.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Moose ODO, 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
moosPlot2.21 <- MOOS.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/MOOS_comb.2021.pdf", height= 8.5)
ggarrange(moos.plot1.21, moosPlot2.21, ncol = 1, nrow = 2)
dev.off()







##### STRT ####

#STRT
#DO and Temp Data
All.years.strt.MESSY

All.years.strt.MESSY <- All.years.strt.MESSY %>%
  select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)

All.years.strt.MESSY$datetimeAK <- as.POSIXct(All.years.strt.MESSY$datetimeAK)

#discharge
STRT.ALL.Q

STRT.ALL.Q <- STRT.ALL.Q %>%
  dplyr::rename(datetimeAK = DateTime)

STRT.ALL.Q <- STRT.ALL.Q %>%
  dplyr::rename(Q = discharge)


STRT.ALL.Q$datetimeAK <- as.POSIXct(STRT.ALL.Q$datetimeAK)

# setDT(STRT.ALL.Q)[, datetimeAK := datetimeAK[1L], 
#                   by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

STRT.ALL.Q <- dplyr::mutate(STRT.ALL.Q, t2 = cut.POSIXt(x = datetimeAK, breaks = "15 mins")) %>% 
  dplyr::group_by(t2) %>% 
  dplyr::summarise(am = mean(Q, na.rm = T))

STRT.ALL.Q <- STRT.ALL.Q %>%
  dplyr::rename(datetimeAK = t2)

STRT.ALL.Q <- STRT.ALL.Q %>%
  dplyr::rename(Q = am)

STRT.ALL.Q <- aggregate(Q ~ datetimeAK, data=STRT.ALL.Q, FUN=mean)

STRT.ALL.Q <- STRT.ALL.Q %>%
  dplyr::rename(discharge = Q)


STRT.ALL.Q$datetimeAK <- as.POSIXct(STRT.ALL.Q$datetimeAK)

#air Pressure
strt.ap.data

strt.ap.data <- strt.ap.data %>%
  dplyr::rename(datetimeAK = DateTime)

strt.ap.data$datetimeAK <- as.POSIXct(strt.ap.data$datetimeAK)


#light
strt.combinded.par

strt.combinded.par <- strt.combinded.par %>%
  dplyr::rename(datetimeAK = DateTime)

strt.combinded.par <- strt.combinded.par %>%
  dplyr::rename(light = Calibrated.Value)

strt.combinded.par$datetimeAK <- as.POSIXct(strt.combinded.par$datetimeAK)

strt.combinded.par$datetimeAK <- lubridate::round_date(strt.combinded.par$datetimeAK, "15 minutes") 



#depth rating curve
strt.depth <- strt.depth %>% filter(datetimeAK >= "2019-05-21 14:45:00")


strt.depth <- strt.depth %>%
  dplyr::rename(depth = RatingCurveDepth)

strt.depth$datetimeAK <- as.POSIXct(strt.depth$datetimeAK)

setDT(strt.depth)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

strt.depth <- aggregate(depth ~ datetimeAK, data=strt.depth, FUN=mean)


#Combine

STRT.comb <- merge(All.years.strt.MESSY, STRT.ALL.Q, 
                   # strt.depth, strt.combinded.par,strt.ap.data, 
                   by = "datetimeAK", all = TRUE)
STRT.comb <- merge(STRT.comb, strt.depth,
                   # strt.combinded.par,strt.ap.data, 
                   by = "datetimeAK", all = TRUE)
STRT.comb <- merge(STRT.comb, strt.combinded.par,
                   # strt.ap.data, 
                   by = "datetimeAK", all = TRUE)

test1 <- strt.ap.data[-c(1)]

STRT.comb <- merge(STRT.comb, test1,
                   # , 
                   by = "datetimeAK", all = TRUE)


# DO SAT CALCS Summary
STRT.comb$DO.sat.EXO = STRT.comb$DO.obs /(STRT.comb$ODO.Psat/100)

STRT.comb$datetimeAK <- as.POSIXct(STRT.comb$datetimeAK) 

STRT.comb$solar.time <- calc_solar_time(STRT.comb$datetimeAK,-146.915323)

STRT.comb$light[STRT.comb$datetimeAK >= '2019-08-23 14:15:00' & STRT.comb$datetimeAK <= '2019-09-17 12:00:00'] <- NA

STRT.comb$datetimeAK <- as.character(STRT.comb$datetimeAK)


light2020formax <- STRT.comb %>% filter(datetimeAK >= '2020-00-00 14:15:00' & datetimeAK <= '2021-00-00 00:00:00')
max(light2020formax$light, na.rm = TRUE)

light2021formax <- STRT.comb %>% filter(STRT.comb$datetimeAK >= '2021-00-00 14:15:00' & STRT.comb$datetimeAK <= '2022-00-00 00:00:00')
max(light2021formax$light, na.rm = TRUE)



STRT.comb$modeled.light <- calc_light(STRT.comb$solar.time, 64.754280, -146.477647, max.PAR = 1932.084)


# STRT.comb$light[STRT.comb$datetimeAK >= '2019-08-23 14:15:00' & STRT.comb$datetimeAK <= '2019-09-17 12:00:00'] <- STRT.comb$modeled.light


STRT.comb.fill.light <- STRT.comb %>% filter(STRT.comb$datetimeAK >= '2019-08-23 14:15:00' & STRT.comb$datetimeAK <= '2019-09-17 12:00:00') %>% 
  mutate(light = coalesce(light,modeled.light))


STRT.comb.1 <- STRT.comb %>% filter(STRT.comb$datetimeAK < '2019-08-23 14:15:00')

STRT.comb.3 <- STRT.comb %>% filter(STRT.comb$datetimeAK > '2019-09-17 12:00:00')

STRT.comb <- rbind(STRT.comb.1, STRT.comb.fill.light, STRT.comb.3)



STRT.comb <- distinct(STRT.comb)

get.wd()
write.csv(STRT.comb, here("outputs", "strt.comb.csv"))


# ALL YEARS
strt.plot1 <- STRT.comb %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Stuart ODO, 2019 - 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
strtPlot2 <- STRT.comb %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/STRT_comb_2019-2021.pdf", height= 8.5)
ggarrange(strt.plot1, strtPlot2, ncol = 1, nrow = 2)
dev.off()


#2019

#
strt.plot1.19 <- STRT.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Stuart ODO, 2019")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
strtPlot2.19 <- STRT.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/STRT_comb.2019.pdf", height= 8.5)
ggarrange(strt.plot1.19, strtPlot2.19, ncol = 1, nrow = 2)
dev.off()

#2020

#
strt.plot1.20 <- STRT.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Stuart ODO, 2020")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
strtPlot2.20 <- STRT.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/STRT_comb.2020.pdf", height= 8.5)
ggarrange(strt.plot1.20, strtPlot2.20, ncol = 1, nrow = 2)
dev.off()

#2021

#
strt.plot1.21 <- STRT.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Stuart ODO, 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
strtPlot2.21 <- STRT.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/STRT_comb.2021.pdf", height= 8.5)
ggarrange(strt.plot1.21, strtPlot2.21, ncol = 1, nrow = 2)
dev.off()



##### POKE ####

#POKE
#DO and Temp Data
All.years.poke.MESSY

All.years.poke.MESSY <- All.years.poke.MESSY %>%
  select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)

All.years.poke.MESSY$datetimeAK <- as.POSIXct(All.years.poke.MESSY$datetimeAK)

#discharge
POKE.ALL.Q

POKE.ALL.Q <- POKE.ALL.Q %>%
  dplyr::rename(datetimeAK = DateTime)



POKE.ALL.Q$datetimeAK <- as.POSIXct(POKE.ALL.Q$datetimeAK)

setDT(POKE.ALL.Q)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

POKE.ALL.Q <- aggregate(Q ~ datetimeAK, data=POKE.ALL.Q, FUN=mean)

POKE.ALL.Q <- POKE.ALL.Q %>%
  dplyr::rename(discharge = Q)

#air Pressure
poke.ap.data

poke.ap.data <- poke.ap.data %>%
  dplyr::rename(datetimeAK = DateTime)

poke.ap.data$datetimeAK <- as.POSIXct(poke.ap.data$datetimeAK)


#light
poke.combinded.par

poke.combinded.par <- poke.combinded.par %>%
  dplyr::rename(datetimeAK = DateTime)

poke.combinded.par <- poke.combinded.par %>%
  dplyr::rename(light = Calibrated.Value)

poke.combinded.par$datetimeAK <- as.POSIXct(poke.combinded.par$datetimeAK)


#depth rating curve
poke.depth

poke.depth <- poke.depth %>%
  dplyr::rename(depth = RatingCurveDepth)

poke.depth$datetimeAK <- as.POSIXct(poke.depth$datetimeAK)

setDT(poke.depth)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

poke.depth <- aggregate(depth ~ datetimeAK, data=poke.depth, FUN=mean)


#Combine

POKE.comb <- merge(All.years.poke.MESSY, POKE.ALL.Q, 
                   # poke.depth, poke.combinded.par,poke.ap.data, 
                   by = "datetimeAK", all = TRUE)
POKE.comb <- merge(POKE.comb, poke.depth,
                   # poke.combinded.par,poke.ap.data, 
                   by = "datetimeAK", all = TRUE)
POKE.comb <- merge(POKE.comb, poke.combinded.par,
                   # poke.ap.data, 
                   by = "datetimeAK", all = TRUE)
POKE.comb <- merge(POKE.comb, poke.ap.data,
                   # , 
                   by = "datetimeAK", all = TRUE)

# DO SAT CALCS Summary
POKE.comb$DO.sat.EXO = POKE.comb$DO.obs /(POKE.comb$ODO.Psat/100)

POKE.comb$solar.time <- calc_solar_time(POKE.comb$datetimeAK,-146.915323)

POKE.comb <- distinct(POKE.comb)

write.csv(POKE.comb, here("outputs", "poke.comb.csv"))

# ALL YEARS
poke.plot1 <- POKE.comb %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Poker ODO, 2019 - 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
pokePlot2 <- POKE.comb %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/POKE_comb_2019-2021.pdf", height= 8.5)
ggarrange(poke.plot1, pokePlot2, ncol = 1, nrow = 2)
dev.off()


#2019

#
poke.plot1.19 <- POKE.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Poker ODO, 2019")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
pokePlot2.19 <- POKE.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/POKE_comb.2019.pdf", height= 8.5)
ggarrange(poke.plot1.19, pokePlot2.19, ncol = 1, nrow = 2)
dev.off()

#2020

#
poke.plot1.20 <- POKE.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Poker ODO, 2020")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
pokePlot2.20 <- POKE.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/POKE_comb.2020.pdf", height= 8.5)
ggarrange(poke.plot1.20, pokePlot2.20, ncol = 1, nrow = 2)
dev.off()

#2021

#
poke.plot1.21 <- POKE.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Poker ODO, 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
pokePlot2.21 <- POKE.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/POKE_comb.2021.pdf", height= 8.5)
ggarrange(poke.plot1.21, pokePlot2.21, ncol = 1, nrow = 2)
dev.off()




##### VAUL ####

#VAUL
#DO and Temp Data
All.years.vaul.MESSY

All.years.vaul.MESSY <- All.years.vaul.MESSY %>%
  select(temp.water, ODO.Psat, ODO.Ploc, DO.obs, datetimeAK)

All.years.vaul.MESSY$datetimeAK <- as.POSIXct(All.years.vaul.MESSY$datetimeAK)

#discharge
VAUL.ALL.Q

VAUL.ALL.Q <- VAUL.ALL.Q %>%
  dplyr::rename(datetimeAK = DateTime)

VAUL.ALL.Q <- VAUL.ALL.Q %>%
  dplyr::rename(Q = discharge)


VAUL.ALL.Q$datetimeAK <- as.POSIXct(VAUL.ALL.Q$datetimeAK)

setDT(VAUL.ALL.Q)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

VAUL.ALL.Q <- aggregate(Q ~ datetimeAK, data=VAUL.ALL.Q, FUN=mean)

VAUL.ALL.Q <- VAUL.ALL.Q %>%
  dplyr::rename(discharge = Q)

#air Pressure
vaul.ap.data

vaul.ap.data <- vaul.ap.data %>%
  dplyr::rename(datetimeAK = DateTime)

vaul.ap.data$datetimeAK <- as.POSIXct(vaul.ap.data$datetimeAK)


#light
vaul.combinded.par

vaul.combinded.par <- vaul.combinded.par %>%
  dplyr::rename(datetimeAK = DateTime)

vaul.combinded.par <- vaul.combinded.par %>%
  dplyr::rename(light = Calibrated.Value)

vaul.combinded.par$datetimeAK <- as.POSIXct(vaul.combinded.par$datetimeAK)


#depth rating curve
vaul.depth

vaul.depth <- vaul.depth %>%
  dplyr::rename(depth = RatingCurveDepth)

vaul.depth$datetimeAK <- as.POSIXct(vaul.depth$datetimeAK)

setDT(vaul.depth)[, datetimeAK := datetimeAK[1L], 
                  by = cumsum(as.POSIXlt(datetimeAK, format = "%m/%d/%Y %H:%M")$min %% 15 == 0)]

vaul.depth <- aggregate(depth ~ datetimeAK, data=vaul.depth, FUN=mean)


#Combine

VAUL.comb <- merge(All.years.vaul.MESSY, VAUL.ALL.Q, 
                   # vaul.depth, vaul.combinded.par,vaul.ap.data, 
                   by = "datetimeAK", all = TRUE)
VAUL.comb <- merge(VAUL.comb, vaul.depth,
                   # vaul.combinded.par,vaul.ap.data, 
                   by = "datetimeAK", all = TRUE)
VAUL.comb <- merge(VAUL.comb, vaul.combinded.par,
                   # vaul.ap.data, 
                   by = "datetimeAK", all = TRUE)
VAUL.comb <- merge(VAUL.comb, vaul.ap.data,
                   # , 
                   by = "datetimeAK", all = TRUE)


VAUL.comb <- distinct(VAUL.comb)

VAUL.comb$solar.time <- calc_solar_time(VAUL.comb$datetimeAK,-146.915323)

# DO SAT CALCS Summary
VAUL.comb$DO.sat.EXO = VAUL.comb$DO.obs /(VAUL.comb$ODO.Psat/100)


VAUL.comb <- distinct(VAUL.comb)

write.csv(VAUL.comb, here("outputs", "vaul.comb.csv"))

# ALL YEARS
vaul.plot1 <- VAUL.comb %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Vault ODO, 2019 - 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge='m^3/sec', air.pressure.mbar = 'mbar')
vaulPlot2 <- VAUL.comb %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/VAUL_comb_2019-2021.pdf", height= 8.5)
ggarrange(vaul.plot1, vaulPlot2, ncol = 1, nrow = 2)
dev.off()


#2019

#
vaul.plot1.19 <- VAUL.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Vault ODO, 2019")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
vaulPlot2.19 <- VAUL.comb %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/VAUL_comb.2019.pdf", height= 8.5)
ggarrange(vaul.plot1.19, vaulPlot2.19, ncol = 1, nrow = 2)
dev.off()

#2020

#
vaul.plot1.20 <- VAUL.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Vault ODO, 2020")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
vaulPlot2.20 <- VAUL.comb %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>%
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light', 'discharge', 'air.pressure.mbar')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/VAUL_comb.2020.pdf", height= 8.5)
ggarrange(vaul.plot1.20, vaulPlot2.20, ncol = 1, nrow = 2)
dev.off()

#2021

#
vaul.plot1.21 <- VAUL.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable') + labs(title = "Vault ODO, 2021")

labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)', discharge= 'm^3/sec', air.pressure.mbar = 'mbar')
vaulPlot2.21 <- VAUL.comb %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
  select(solar.time, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  gather(type, value, depth, temp.water, light, discharge, air.pressure.mbar) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light','discharge', "air.pressure.mbar")),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/VAUL_comb.2021.pdf", height= 8.5)
ggarrange(vaul.plot1.21, vaulPlot2.21, ncol = 1, nrow = 2)
dev.off()


##### OLD CODE #####


# 
# 
# #2019
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_DO.2019.png")
# frch.all %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2019")
# dev.off()
# 
# 
# #2020
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_DO.2020.png")
# frch.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2020")
# dev.off()
# 
# #2021
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_DO.2021.png")
# frch.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "French ODO, 2021")
# dev.off()
# 
# 
# 
# #Moos
# 
# moos.ap.data <- moos.ap.data %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# 
# moos.all <- merge(All.years.moos.MESSY,moos.ap.data, by = "datetimeAK",all = TRUE)
# 
# #rename some 
# moos.all <- moos.all %>%
#   dplyr::rename(temp.water = Temp.C)
# 
# moos.all <- moos.all %>%
#   dplyr::rename(DO.obs = ODO.mgL)
# 
# 
# 
# 
# moos.all$DO.sat <- calc_DO_sat(moos.all$temp.water, moos.all$air.pressure.mbar, model = "garcia-benson")
# 
# 
# moos.all$solar.time <- calc_solar_time(moos.all$datetimeAK,-147.052814)
# 
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_DO.png")
# 
# moos.all %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Moose ODO, 2019 - 2021")
# dev.off()
# #2019
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_DO.2019.png")
# moos.all %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Moose ODO, 2019")
# dev.off()
# 
# 
# #2020
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_DO.2020.png")
# moos.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Moose ODO, 2020")
# dev.off()
# 
# #2021
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_DO.2021.png")
# moos.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Moose ODO, 2021")
# dev.off()
# 
# 
# #Poke
# 
# poke.ap.data <- poke.ap.data %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# 
# poke.all <- merge(All.years.poke.MESSY,poke.ap.data, by = "datetimeAK",)
# 
# #rename some 
# poke.all <- poke.all %>%
#   dplyr::rename(temp.water = Temp.C)
# 
# poke.all <- poke.all %>%
#   dplyr::rename(DO.obs = ODO.mgL)
# 
# 
# 
# 
# poke.all$DO.sat <- calc_DO_sat(poke.all$temp.water, poke.all$air.pressure.mbar, model = "garcia-benson")
# 
# 
# poke.all$solar.time <- calc_solar_time(poke.all$datetimeAK,-147.052814)
# 
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_DO.png")
# 
# poke.all %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Poker ODO, 2019 - 2021")
# dev.off()
# 
# #2019
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_DO.2019.png")
# poke.all %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Poker ODO, 2019")
# dev.off()
# 
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_DO.2020.pdf")
# poke.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Poker ODO, 2020")
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_DO.2021.pdf")
# poke.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Poker ODO, 2021")
# dev.off()
# 
# 
# #Strt
# strt.ap.data <- strt.ap.data %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# 
# strt.all <- merge(All.years.strt.MESSY,strt.ap.data, by = "datetimeAK",all = TRUE)
# 
# #rename some 
# strt.all <- strt.all %>%
#   dplyr::rename(temp.water = Temp.C)
# 
# strt.all <- strt.all %>%
#   dplyr::rename(DO.obs = ODO.mgL)
# 
# 
# 
# 
# strt.all$DO.sat <- calc_DO_sat(strt.all$temp.water, strt.all$air.pressure.mbar, model = "garcia-benson")
# 
# 
# strt.all$solar.time <- calc_solar_time(strt.all$datetimeAK,-147.052814)
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_DO.pdf")
# 
# strt.all %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Strt ODO, 2019 - 2021")
# dev.off()
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_DO.2019.pdf")
# strt.all %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Stuart ODO, 2019")
# dev.off()
# 
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_DO.2020.pdf")
# strt.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Stuart ODO, 2020")
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_DO.2021.pdf")
# strt.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Stuart ODO, 2021")
# dev.off()
# 
# 
# 
# #Vaul
# vaul.ap.data <- vaul.ap.data %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# 
# vaul.all <- merge(All.years.vaul.MESSY,vaul.ap.data, by = "datetimeAK",all = TRUE)
# 
# #rename some 
# vaul.all <- vaul.all %>%
#   dplyr::rename(temp.water = Temp.C)
# 
# vaul.all <- vaul.all %>%
#   dplyr::rename(DO.obs = ODO.mgL)
# 
# vaul.all<- vaul.all[-c(22786),]
# 
# 
# vaul.all$DO.sat <- calc_DO_sat(vaul.all$temp.water, vaul.all$air.pressure.mbar, model = "garcia-benson")
# 
# 
# vaul.all$solar.time <- calc_solar_time(vaul.all$datetimeAK,-147.052814)
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_DO.pdf")
# 
# 
# 
# vaul.all %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Vaul ODO, 2019 - 2021")
# dev.off()
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_DO.2019.pdf")
# vaul.all %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Vault ODO, 2019")
# dev.off()
# 
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_DO.2020.pdf")
# vaul.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Vault ODO, 2020")
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_DO.2021.pdf")
# vaul.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
#   select(solar.time, starts_with('DO')) %>%
#   gather(type, DO.value, starts_with('DO')) %>%
#   mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
#   ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable') + labs(title = "Vault ODO, 2021")
# dev.off()
# 
# 
# 
# 
# ######################################################################
# #Light, Depth, Water temp
# 
# #MOOS
# 
# 
# moos.combinded.par <- moos.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# moos.combinded.par <- moos.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# moos.all <- merge(moos.combinded.par, moos.all,  by = "datetimeAK",all = TRUE)
# 
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_light_temp_depth.pdf")
# 
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# moos.all %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "MOOS, 2019 - 2021")
# 
# dev.off()
# 
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_light_temp_depth.2019.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# moos.all %>% filter(datetimeAK >= "2019-01-01 00:00:00") %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "MOOS, 2019")
# 
# dev.off()
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_light_temp_depth.2020.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# moos.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "MOOS, 2020")
# 
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testMOOS_SM_light_temp_depth.2021.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# moos.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "MOOS, 2021")
# 
# dev.off()
# 
# 
# 
# 
# 
# #FRCH
# 
# 
# frch.combinded.par <- frch.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# frch.combinded.par <- frch.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# frch.all <- merge(frch.combinded.par, frch.all,  by = "datetimeAK", all = TRUE)
# 
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_light_temp_depth.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# frch.all %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "FRCH, 2019 - 2021")
# 
# dev.off()
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_light_temp_depth.2019.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# frch.all %>% filter(datetimeAK >= "2019-01-01 00:00:00") %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "FRCH, 2019")
# 
# dev.off()
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_light_temp_depth.2020.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# frch.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "FRCH, 2020")
# 
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testFRCH_SM_light_temp_depth.2021.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# frch.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "FRCH, 2021")
# 
# dev.off()
# 
# 
# 
# 
# 
# #POKE
# 
# 
# poke.combinded.par <- poke.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# poke.combinded.par <- poke.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# poke.all <- merge(poke.combinded.par, poke.all,  by = "datetimeAK",all = TRUE)
# 
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_light_temp_depth.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# poke.all %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "POKE, 2019 - 2021")
# 
# dev.off()
# 
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_light_temp_depth.2019.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# poke.all %>% filter(datetimeAK >= "2019-01-01 00:00:00") %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "POKE, 2019")
# 
# dev.off()
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_light_temp_depth.2020.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# poke.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "POKE, 2020")
# 
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testPOKE_SM_light_temp_depth.2021.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# poke.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "POKE, 2021")
# 
# dev.off()
# 
# 
# 
# 
# 
# 
# #VAUL
# 
# 
# vaul.combinded.par <- vaul.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# vaul.combinded.par <- vaul.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# vaul.all <- merge(vaul.combinded.par, vaul.all,  by = "datetimeAK",all = TRUE)
# 
# 
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_light_temp_depth.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# vaul.all %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "VAUL, 2019 - 2021")
# 
# dev.off()
# #2019
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_light_temp_depth.2019.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# vaul.all %>% filter(datetimeAK >= "2019-01-01 00:00:00") %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "VAUL, 2019")
# 
# dev.off()
# 
# #2020
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_light_temp_depth.2020.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# vaul.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "VAUL, 2020")
# 
# dev.off()
# 
# #2021
# pdf(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testVAUL_SM_light_temp_depth.2021.pdf")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# vaul.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "VAUL, 2021")
# 
# dev.off()
# 
# 
# 
# #STRT
# 
# 
# strt.combinded.par <- strt.combinded.par %>%
#   dplyr::rename(light = Calibrated.Value)
# 
# strt.combinded.par <- strt.combinded.par %>%
#   dplyr::rename(datetimeAK = DateTime)
# 
# strt.combinded.par$datetimeAK <- lubridate::round_date(strt.combinded.par$datetimeAK, "15 minutes")
# 
# 
# 
# strt.all <- merge(strt.combinded.par, strt.all,  by = "datetimeAK", all = TRUE)
# 
# 
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_light_temp_depth.png")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# strt.all %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "STRT, 2019 - 2021")
# 
# dev.off()
# #2019
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_light_temp_depth.2019.png")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# strt.all %>% filter(datetimeAK >= "2019-01-01 00:00:00") %>% filter(datetimeAK <= "2020-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "STRT, 2019")
# 
# dev.off()
# 
# #2020
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_light_temp_depth.2020.png")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# strt.all %>% filter(datetimeAK >= "2020-01-01 00:00:00") %>% filter(datetimeAK <= "2021-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "STRT, 2020")
# 
# dev.off()
# 
# #2021
# png(file = "C:/Users/jacob/OneDrive - University of Alaska/GitHub/UAF-Metabolism/Plots/testSTRT_SM_light_temp_depth.2021.png")
# 
# labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
# strt.all %>% filter(datetimeAK >= "2021-01-01 00:00:00") %>% filter(datetimeAK <= "2022-01-01 00:00:00") %>% 
#   select(solar.time, depth, temp.water, light) %>%
#   gather(type, value, depth, temp.water, light) %>%
#   mutate(
#     type=ordered(type, levels=c('depth','temp.water','light')),
#     units=ordered(labels[type], unname(labels))) %>%
#   ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
#   facet_grid(units ~ ., scale='free_y') + theme_bw() +
#   scale_color_discrete('variable')+ labs(title = "STRT, 2021")
# 
# dev.off()
# 
# 
# 
# 
# 




